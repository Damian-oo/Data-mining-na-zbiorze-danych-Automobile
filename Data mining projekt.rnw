\documentclass[12pt, a4paper]{article}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  % dodatkowe pakiety LaTeX'a
\usepackage[OT4]{polski}
\usepackage[utf8]{inputenc}
\usepackage[top=2.5cm, bottom=2.5cm, left=2cm, right=2cm]{geometry}
\usepackage{graphicx}
\usepackage{float}
\usepackage[colorlinks=true, linkcolor=blue]{hyperref}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage{indentfirst}

\newcommand{\kb}[1]{\textcolor{red}{#1}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ustawienia globalne

<<ustawienia_globalne, echo=FALSE, warning=FALSE, message=FALSE>>=
library(knitr)
library(latex2exp)
library(data.table)
library(MCMCpack)
library(xtable) #pakiet do tworzenia tabel w formacie LaTeX'a
library(DataExplorer)
library(MASS)
library(dplyr)
library(ggplot2)
library(cowplot)
library(vcd)
library(ggmosaic) 
library(gridExtra)
library(rcompanion) 
library(nnet)
library(ks)
library(klaR)
library(ipred)
library(randomForest)
library(caret)
library(yardstick)
library(factoextra)
library(cluster)
library(e1071)
library(clValid)
library(dbscan)
library(dendextend)
library(FactoMineR)
library(ggpubr)
library(corrplot)
library(patchwork)
library(gplots)
opts_chunk$set(fig.path='figure/', fig.align='center', fig.pos='H',fig.width=5, fig.height=4)
# UWAGA: w razie potrzeby można zmieniać te ustawienia w danym chunk'u!
@
  
  
  \begin{document}
%\SweaveOpts{concordance=TRUE}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  % strona tytulowa
\title{Data Mining\\
Projekt cz. 1}
\author{Damian Lewańczyk \\ album 242999}
\maketitle
\tableofcontents

%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  %
\section{Analiza eksploracyjna}  
\subsection{Opis danych}
%

<<modele_3 , eval=TRUE, echo=FALSE>>=
data <- read.csv("C:/STUDIA/Matematyka ( II stopień )/II semestr/Data mining/ProjektDM/Automobile_data.csv")
#data<- data(auto)
#zamiana "?" na wartości brakujące
data[data=="?"]<-NA
@

Zbiór danych \texttt{automobile data set} złożony jest z $205$ obserwacji (samochodów). Zawiera $25$ różnych zmiennych objaśniających opisujących samochody oraz zmienną objaśnianą \texttt{symboling} - zmienną jakościową, która odpowiada poziomowi ryzyka ubezpieczeniowego samochodu, który odpowiada ich cenie. Jeśli samochód jest bardziej niebezpieczny do ubezpieczenia, ten symbol jest korygowany poprzez jego zwiększenie. Wartości są liczbami naturalnym w zakresie od $-3$ do $+3$. Wartość $+3$ wskazuje, że pojazd jest ryzykowny, a $-3$ wskazuje, że jesteśmy najbardziej skłonni go ubezpieczyć. Zanim przejdziemy do analizy danych zapoznamy się ze zmiennymi. Przedstawimy kolejno każdą z nich podając jej nazwę, typ oraz krótki opis:

\begin{itemize}
\item \textbf{symboling} (zmienna jakościowa, przyjmuje 7 różnych wartości) -  określa poziom ryzyka ryzyka ubezpieczeniowego samochodu
\item \textbf{normalized.losses} (zmienna ilościowa typu ciągłęgo, przyjmuje wartości od 65 do 256) - względna średnia wypłata odszkodowania za ubezpieczony pojazd . Ta wartość jest znormalizowana dla wszystkich samochodów w ramach określonej klasyfikacji (dwudrzwiowe małe, kombi, sportowe/specjalne itp.) i reprezentuje średnią stratę na samochód rocznie
\item \textbf{make} (zmienna jakościowa, przyjmuje 22 różne wartości) - marka auta
\item \textbf{fuel.type} (zmienna jakościowa, przyjmuje 2 różne wartości) - typ paliwa dostarczanego silnikowi
\item \textbf{aspiration} (zmienna jakościowa, przyjmuje 2 różne wartości) - zmienna określająca czy silnik jest wolnossący czy ma doładowanie turbo
\item \textbf{num.of.doors} (zmienna jakościowa, przyjmuje 2 różne wartości) - określa czy auto jest dwudrzwiowe czy czterodrzwiowe (W Polsce czasem zamiennie odpowiednio 3d i 5D)
\item \textbf{body.style} (zmienna jakościowa, przyjmuje 5 różnych wartości) - zmienna określająca typ nadwozia
\item \textbf{drive.wheels} (zmienna jakościowa, przyjmuje 3 różne wartości) - opisuje rodzaj napędu
\item \textbf{engine.location} (zmienna jakościowa, przyjmuje 2 różne wartości) - zmienna określająca lokalizacje silnika
\item \textbf{wheel.base} (zmienna ilościowa typu ciągłęgo, przyjmuje wartości od $86.6$ do $120.9$) - rozstaw osi, czyli odległość między środkami kół poszczególnych osi, mierzona przy symetrycznym ustawieniu kół względem podłużnej osi pojazdu

\item \textbf{length} (zmienna ilościowa typu ciągłęgo, przyjmuje wartości od $141.1$ do $208.1$) - długość pojazdu
\item \textbf{width} (zmienna ilościowa typu ciągłęgo, przyjmuje wartości od $60.3$ do $72.3$) - szerokość pojazdu
\item \textbf{heigth} (zmienna ilościowa typu ciągłęgo, przyjmuje wartości od $47.8$ do $59.8$) - wysokość pojazdu
\item \textbf{curb.weight} (zmienna ilościowa typu ciągłęgo, przyjmuje wartości od $1488$ do $4066$) - masa własna pojazdu czyli bez pasażerów, bagażu itd.
\item \textbf{engine.type} (zmienna jakościowa, przyjmuje 7 różnych wartości) - typ silnika
\item \textbf{num.of.cylinders} (zmienna jakościowa, przyjmuje 7 różnych wartości) - liczba cylindrów w silniku
\item \textbf{engine.size} (zmienna ilościowa typu ciągłego, przyjmuje wartości od $61$ do $326$) - rozmiar silnika.
\item {fuel.system} (zmienna jakościowa, przyjmuje 8 różnych wartości) - rodzaj systemu paliwowego
\item \textbf{bore} (zmienna ilościowa typu ciągłego, przyjmuje wartości od $2.54$ do $3.96$) - średnica cylindra
\item \textbf{stroke} (zmienna ilościowa typu ciągłego, przyjmuje wartości od $2.07$ do $4.17$) - „Długość skoku”, odległość przebyta przez tłok podczas każdego cyklu
\item \textbf{compression.ratio} (zmienna ilościowa typu ciągłego, przyjmuje wartości od $7$ do $23$) - stopień kompresji, czyli stosunek objętości cylindra do objętości komory spalania w~silniku spalinowym przy ich maksymalnej i minimalnej wartości
\item \textbf{horsepower} (zmienna ilościowa typu ciągłego, przyjmuje wartości od $48$ do $288$) - średnica cylindra
\item \textbf{peak.rpm} (zmienna ilościowa typu ciągłego, przyjmuje wartości od $4150$ do $6600$) - moment obrotowy silnika 
\item \textbf{city.mpg} (zmienna ilościowa typu ciągłego, przyjmuje wartości od $13$ do $49$) - zużycie paliwa podczas jazdy w mieście
\item \textbf{highway.mpg} (zmienna ilościowa typu ciągłego, przyjmuje wartości od $16$ do $54$) - zużycie paliwa podczas jazdy na autostradzie
\item \textbf{price} (zmienna ilościowa typu ciągłego, przyjmuje wartości od $5118$ do $45400$) - wartośc pojazdu



\end{itemize}

\subsection{Przypisanie typów zmiennych}

Przypiszemy teraz manualnie typy zmiennych jakościowych (factor) i ilościowych (numeric) odpowiednim zmiennym, ponieważ domyślnie R myli się przy przypisywaniu. Następnie spojrzymy wstępnie na kilka początkowych wartości każdej zmiennej z naszego zbioru danych za pomocą funkcji \texttt{glimpse} z pakietu \textbf{dplyr}.

<<explor_zmienne, eval=TRUE, echo=FALSE>>=
#kolumny, które chcemy, żeby były odczytane jako zmienne jakościowe
factor_kol <- c('symboling','make',
               'fuel.type','aspiration','num.of.doors',
               'body.style','drive.wheels','engine.location',
               'engine.type','num.of.cylinders',
               'fuel.system')
#kolumny, które chcemy, żeby były odczytane jako zmienne ilościowe (liczby naturalne)
int_kol <- c('normalized.losses','horsepower','peak.rpm','city.mpg','highway.mpg',
           'price','curb.weight','engine.size')
#(i liczby rzeczywiste)
num_kol <- c('bore','stroke','compression.ratio','wheel.base','length','width','height')
data <- data %>% mutate_at(factor_kol, factor) %>% 
  mutate_at(int_kol, as.integer) %>% mutate_at(num_kol, as.numeric)
glimpse(data)

@

Następnie dokonamy wstępnego rozeznania w danych za pomocą funkcji \texttt{introduce} i \texttt{plot intro} z pakietu \textbf{DataExplorer}.

<<explor_1, eval=TRUE, echo=FALSE, cache=TRUE>>=
t(introduce(data))
plot_intro(data)
@

Jak widzimy, odpowiednio przypisaliśmy typy zmiennych w \textbf{R}. Jak możemy zauważyć, w naszych danych są wartości brakujące, którymi zajmiemy się nimi w~następnym podrozdziale.

%---------------------------------------------------------------------------------------------------
\subsection{Szukanie i wypełnianie brakujących wartości}
%---------------------------------------------------------------------------------------------------

Na początek, użyjemy funkcji \texttt{plot missing} z pakietu \textbf{DataExplorer}, aby sprawdzić jakie zmienne oraz jaki ich odsetek ma brakujące wartości.

<<explor_NA, eval=TRUE, echo=FALSE, cache=TRUE>>=
plot_missing(data)
@

Możemy też sprawdzić nie względną, a liczbową wartość wartości brakujących dla każdej kolumny:
<<explor_NA2, eval=TRUE, echo=TRUE>>=
apply(data,2,function(x){length(which(is.na(x)))})
@
Zamieniamy wartości $NA$ na konkretne liczby tj. na średnie ze zmiennych ilościowych typu ciągłego, a wartości $NA$ zmiennej jakościowej \texttt{num.of.doors} zamienamy na wartości najczęściej występujące, w tym wypadku będzie to wartość \texttt{four}.
<<replace_NA, eval=TRUE, echo=FALSE, >>=
data[is.na(data$normalized.losses),]$normalized.losses <- round(mean(data[!is.na(data$normalized.losses),]$normalized.losses))
data[is.na(data$horsepower),]$horsepower <- round(mean(data[!is.na(data$horsepower),]$horsepower))
data[is.na(data$bore),]$bore <- round(mean(data[!is.na(data$bore),]$bore), digits=2)
data[is.na(data$stroke),]$stroke <- round(mean(data[!is.na(data$stroke),]$stroke), digits=2)
data[is.na(data$peak.rpm),]$peak.rpm <- round(mean(data[!is.na(data$peak.rpm),]$peak.rpm), digits=2)
data[is.na(data$price),]$price <- round(mean(data[!is.na(data$price),]$price), digits=2)
data[is.na(data$num.of.doors),]$num.of.doors <- "four"

@

\subsection{Wizualizacja danych}

W tym podrozdziale zajmiemy się wizualizacją danych. Na początek zaprezentowane zostaną barploty dla zmiennych jakościowych, które przedstawią częstości występowania poszczególnych wartości dla każdej zmiennej typu factor. Zrobimy to za pomocą funkcji \texttt{plot bar} z pakietu \textbf{DataExplorer}. Widzimy je na rysunkach $1$, $2$ i $3$ poniżej.

<<explor_2, eval=TRUE, echo=FALSE, cache=TRUE,fig.cap="Częstotliwości występowania klas dla zmiennych jakościowych">>=
plot_bar(data, nrow=2, ncol=2, maxcat=30)
@

Na podstawie powyższych wykresów, z modelu usuwamy zmienne \texttt{fuel.type} oraz \texttt{engine.location}, ponieważ występuje w nich za duża dysproporcja między występowaniem klas, przez co nie będą one przekazywać nam praktycznie żadnych informacji. Drugą ważną informacją jest fakt, że nasza jakościowa zmienna objaśniana w ogólnie nie przyjmuje jednej z potencjalnych wartości tj. $-3$, a kolejną wartość tj. $-2$ przyjmuje zaledwie kilka razy. Poza tym, szczególną uwagę trzeba zwrócić na fakt, że jedna ze zmiennych jakościowych - \texttt{make} ma bardzo dużo klas (ponad $20$), co może być problemem przy ewentualnych próbach transformacji takiej zmiennej na numeryczną (np. za pomoca One-hot encoding), przez znaczące zwiększenie wymiaru)

<<explor_delete, eval=TRUE, echo=FALSE, cache=TRUE>>=
data <- data[, c(-4,-9)]
@

Dodatkowo, jest kilka innych zmiennych: \texttt{normalized.losses}, \texttt{engine.type}, \texttt{drive.wheels}, \texttt{fuel.type} i \texttt{aspiration}, które są potencjalnie kandydatami do usunięcia. Zmienna  \texttt{normalized.losses}, bo ma duży odsetek wartości brakujących (które na razie zostały zastąpione wartościami średnimi), a reszta zmiennych - która jest typu jakościowego - z powodu dominacji jednej wartości zmiennej. Ostateczną decyzję podejmiemy po dalszej analizie, czy owe zmienne mogą mieć znaczący wpływ na naszą zmienną objaśnianą  \texttt{symboling}. 
\par
Poniżej, na rysunkach $4$, $5$, $6$ i $7$ przedstawione zostały histogramy dla zmiennych ilościowych. Wygenerowane zostały one za pomocą funkcji \texttt{plot histogram} z pakietu \textbf{DataExplorer}.
<<explor_3, eval=TRUE, echo=FALSE, cache=TRUE, fig.cap="Histogramy dla zmiennych ilościowych">>=
plot_histogram(data, nrow=2, ncol=2, geom_histogram_args = list(bins = 13L))
@
Jak możemy zobaczyć, rozkłady zmiennych ilościowych znacząco różnią się kształtem między sobą. I tak, widzimy że np. zmienne \texttt{length}, \texttt{bore} czy \texttt{stroke} mogą pochodzić z rozkładu bardziej przypominającego rozkład normalny, natomiast rozkłady takich zmiennych jak \texttt{horsepower}, \texttt{price} czy \texttt{engine.size} bardziej przypominają np. rozkład wykładniczy. 
\par
Poniżej, na rysunkach $8$, $9$, $10$ i $11$ dodatkowo wygnerowane zostały estymowane gęstości dla zmiennych ilościowych. Stworzone zostały przy pomocy funkcji \texttt{plot density} z pakietu \textbf{DataExplorer}. Wykresy te potwierdzają nasze obserwacje co do różnych charakterystyk zmiennych numerycznych.
<<explor_4, eval=TRUE, echo=FALSE, cache=TRUE, fig.cap="Estymowane gęstości dla zmiennych ilościowych">>=
plot_density(data, nrow=2, ncol=2)
@




%---------------------------------------------------------------------------------------------------
\subsection{Analiza potencjalnych zależności między zmiennymi}
%---------------------------------------------------------------------------------------------------
\subsubsection {Analiza graficzna zależności między zmienną objaśnianą, a zmiennymi ilościowymi}

Oczywiście najbardziej interesują nas potencjalne zależności między zmienną objaśnianą \texttt{symboling}, a pozostałymi zmiennymi. Dlatego głównie zajmiemy się właśnie nimi, na początek przedstawiając wykresy "pogrupowane" na klasy wartości zmiennej \texttt{symboling}: boxploty dla zmiennych ilościowych oraz wykresy mozaikowe dla zmiennych jakościowych.

Poniżej, na rysunkach $12$, $13$, $14$ i $15$ przedstawione są boxploty dla zmiennych ilościowych pogrupowane wg. wartości zmiennej \texttt{symboling}. Robimy je przy użyciu funkcji \texttt{plot boxplot} z pakietu \textbf{DataExplorer}.
<<explor_bp_symbo, eval=TRUE, echo=FALSE, cache=TRUE, fig.cap="Boxploty dla zmiennych ilościowych ze względu na wartości zmiennej symboling">>=
plot_boxplot(data, by="symboling",  nrow=2, ncol=2)
@
Obserwując boxploty powyżej, możemy stwierdzić, że praktycznie dla każdej zmiennej numerycznej boxploty dla poszczególnych klas zmiennej objaśnianej \texttt{symboling} różnią się od siebie. Najbardziej podobne są dla zmiennej \texttt{compression.ratio}, \texttt{peak.rpm} i \texttt{stroke}.  Widzimy na podstawie boxplotów, że zależności między zmiennymi objaśniającymi, a zmienną \texttt{symboling} są różne. Jednakże najbliżej zależności, którą nazwalibyśmy liniową (biorąc pod uwagę, że zmienna objaśniana ma klasy liczbowe i jest porządkowa) są zmienne: \texttt{length}, \texttt{normalized.losses}, \texttt{wheel.base} i \texttt{height}. Zależności między zmienną objaśnianą, a zmiennymi \texttt{length}, \texttt{wheel.base} i \texttt{height} określającymi fizyczne parametry auta są blizko uznania za "malejące", tzn. wraz ze wzrostem któregokolwiek z tych parametrów, zmienna symboling przyjmuje statystycznie mniejsze wartości czyli auto jest mniej ryzykowne. Natomiast odwrotnie jest w przypadku zmiennej \texttt{normalized.losses}, czyli wartości wypłat za pojazd, gdzie im większe jej wartości, tym większa wartość zmiennej \texttt{symboling}, czyli auto jest potencjalnie bardziej ryzykowne.
\par
Na koniec dodajmy, że z racji tego, że zmienna \texttt{normalized.losses} jest tak istotna, oczywiście nie usuwamy jej z modelu, a wartości brakujące zostają z podmienionymi za nie średnimi z reszty wartości.

\subsubsection{Analiza graficzna zależności między zmienną objaśnianą, a zmiennymi jakościowymi}

\par
Poniżej, na rysunkach \ref{fig:explor_mosaic_symbo_1}, \ref{fig:explor_mosaic_symbo_2}, \ref{fig:explor_mosaic_symbo_3} i \ref{fig:explor_mosaic_symbo_5} przedstawione są wykresy mozaikowe dla zmiennych jakościowch pogrupowane wg. wartości  zmiennej \texttt{symboling}.

<<explor_mosaic_symbo_1, eval=TRUE, echo=FALSE, cache=TRUE, fig.width=8, warning=FALSE, fig.cap="Częstotliwość występowania poszczególnych klas zmiennych jakościowych ze względu na wartości zmiennej symboling">>=

mosa_drive.wheels <- ggplot(data = data) +
  geom_mosaic(aes(x = product(drive.wheels, symboling), fill=drive.wheels)) + 
  labs(y = "", title="Częstość klas drive.wheels") +
  theme(axis.text.y=element_blank(),
        axis.ticks.y=element_blank(),
        axis.text.x = element_text(angle = 0))
        
mosa_fuel.system <- ggplot(data = data) +
  geom_mosaic(aes(x = product(fuel.system, symboling), fill=fuel.system)) + 
  labs(y = "", title="Częstość klas fuel.system") +
  theme(axis.text.y=element_blank(),
        axis.ticks.y=element_blank(),
        axis.text.x = element_text(angle = 0))
grid.arrange(mosa_drive.wheels, mosa_fuel.system, ncol=2)

@

<<explor_mosaic_symbo_2, eval=TRUE, echo=FALSE, cache=TRUE, fig.width=8, fig.cap="Częstotliwość występowania poszczególnych klas zmiennych jakościowych ze względu na wartości zmiennej symboling">>=

mosa_body.style <- ggplot(data = data) +
  geom_mosaic(aes(x = product(body.style, symboling), fill=body.style)) + 
  labs(y = "", title="Częstość klas body.style") +
  theme(axis.text.y=element_blank(),
        axis.ticks.y=element_blank(),
        axis.text.x = element_text(angle = 0))
mosa_num.of.doors <- ggplot(data = data) +
  geom_mosaic(aes(x = product(num.of.doors, symboling), fill=num.of.doors)) + 
  labs(y = "", title="Częstość klas num.of.doors") +
  theme(axis.text.y=element_blank(),
        axis.ticks.y=element_blank(),
        axis.text.x = element_text(angle = 0))
grid.arrange(mosa_body.style, mosa_num.of.doors, ncol=2)

@


<<explor_mosaic_symbo_3, eval=TRUE, echo=FALSE, cache=TRUE, fig.width=8, fig.cap="Częstotliwość występowania poszczególnych klas zmiennych jakościowych ze względu na wartości zmiennej symboling">>=

mosa_aspiration <- ggplot(data = data) +
  geom_mosaic(aes(x = product(aspiration, symboling), fill=aspiration)) + 
  labs(y = "", title="Częstość klas aspiration") +
  theme(axis.text.y=element_blank(),
        axis.ticks.y=element_blank(),
        axis.text.x = element_text(angle = 0))
mosa_engine.type <- ggplot(data = data) +
  geom_mosaic(aes(x = product(engine.type, symboling), fill=engine.type)) + 
  labs(y = "", title="Częstość klas engine.type") +
  theme(axis.text.y=element_blank(),
        axis.ticks.y=element_blank(),
        axis.text.x = element_text(angle = 0))
grid.arrange(mosa_aspiration, mosa_engine.type, ncol=2)


@

Warto zauważyć, że kolory na legendzie są "do góry nogami" względem tego jak poszczególne klasy przedstawione są na wykresach. Jest tak na wszystkich wykresach mozaikowych zaprezentowanych tutaj, ale warto na to zwrócić uwagę szczególnie przy następnym, dotyczącym mark aut: 
<<explor_mosaic_symbo_5, eval=TRUE, echo=FALSE, cache=TRUE, fig.height=10, fig.width=8, fig.cap="Częstotliwość występowania poszczególnych klas zmiennych jakościowych ze względu na wartości zmiennej symboling">>=
mosa_make <- ggplot(data = data) +
  geom_mosaic(aes(x = product(make, symboling), fill=make)) + 
  labs(y = "", title="Częstość klas make") +
  theme(axis.text.y=element_blank(),
        axis.ticks.y=element_blank(),
        axis.text.x = element_text(angle = 0))
mosa_make
@

Na powyższych wykresach jasno widać, że każda zmienna jakościowa ma mniejszy lub większy wpływ na zmienną \texttt{symboling}. Wydaje się bez głębszej analizy, że najmniejszy wpływ ma zmienna \texttt{aspiration}. Zdecydowanie najprostszą do interpretacji jest relacja tej zmiennej ze zmienną \texttt{num.of.doors}. Widzimy, że jeśli auto jest dwudrzwiowe, to wzrasta ryzyko jego ubezpieczenia względem auta czterodrzwiowego. Innym bardzo ciekawym, choć bardzo złożonym wykresem, jest ten ze zmienną \texttt{make}, której liczba klas znacząco utrudnia opis tego wykresu. Możemy zauważyć, bardzo różne rozkłady klas dla poszczególnych wartości zmiennej \texttt{symboling}. Np. wszystkie wartości $-2$ zmiennej \texttt{symboling} są dla marki auta volvo, a reszta volvo ma wartość \texttt{symboling} równą $-1$, natomiast zdecydowana większość aut marki alfa romeo znajduje się w wysokiej grupie ryzyka (\texttt{symboling}=$3$).

\subsubsection{Analiza formalna zależności między zmienną objaśnianą, a zmiennymi ilościowymi}
 
Teraz przejdziemy do bardziej formalnej części analizy zależności. Dla zmiennych ilościowych. tabeli \ref{tab:num_cors} przedstawione zostały wartości odpowiednio $\eta^2$, $\omega^2$ oraz wartości p-value dla testu Kruskala - Walisa. $\eta^2$, $\omega^2$ są typami wielkości efektu \cite{wiki} między zmienną ilościową, a jakościową. Wartości tych współczynników w \textbf{R} zostały obliczone z pomocą funkcji \texttt{anova} oraz \texttt{lm} z~pakietu \textbf{stats} \cite{anovaR}\cite{lmR}. Istnieje wiele różnych interpretacji tych współczynników (od jakiej wartości zmienną możemy uznać za istotną/średnio istotną/ bardzo istotną) - więcej tutaj \cite{eta}, \cite{omega}.  Nam jednakże tak samo bardzo zależy po prostu na uszeregowaniu zmiennych od tych najbardziej istotnych względem zmiennej objaśnianej, do tych najmniej istotnych. Tak samo jeśli chodzi o~wartości p-value dla testu Kruskala-Walisa. Wartości te w \textbf{R} zostały obliczone za pomocą funkcji \texttt{kruskal.test} z pakietu \textbf{stats} \cite{KruskalR}. Test ten nie zakłada normalności rozkładów. Hipotezą zerową jest równość dystrybuant rozkładów w porównywanych populacjach (w naszym wypadku, dla różnych klas zmiennej \texttt{symboling} tzn. im mniejsza p-value tym teoretycznie większa szansa na to, że dystrybuanty rozkładów są różne dla poszczególnych klas, czyli większa szansa na to, że zmienna ilościowa jest w pewien sposób zależna od jakościowej (i na odwrót). Więcej tutaj \cite{Kruskal}. W tabeli poniżej zmienne zostały uszeregowane

<<num_cors_data, results='asis', echo=FALSE, cache=TRUE>>=
# Fit ANOVA model
model <- lm(data$height  ~ factor(data$symboling))
# Perform ANOVA
anova_result <- anova(model)
# Extract effect size (eta-squared or omega-squared)
eta_sq_height <- anova_result$`Sum Sq`[1] / sum(anova_result$`Sum Sq`)
omega_height <- (anova_result$`Sum Sq`[1] - (anova_result$`Df`[1] * anova_result$`Mean Sq`[2])) / (sum(anova_result$`Sum Sq`) + anova_result$`Sum Sq`[1])
kruskal_height <- kruskal.test(data$height ~ data$symboling)$p.value

#----------------------------------------------------------------------
model <- lm(data$normalized.losses  ~ factor(data$symboling))
# Perform ANOVA
anova_result <- anova(model)
# Extract effect size (eta-squared or omega-squared)
eta_sq_normalized_losses <- anova_result$`Sum Sq`[1] / sum(anova_result$`Sum Sq`)
omega_sqnormalized_losses <- (anova_result$`Sum Sq`[1] - (anova_result$`Df`[1] * anova_result$`Mean Sq`[2])) / (sum(anova_result$`Sum Sq`) + anova_result$`Sum Sq`[1])

kruskal_normalized_losses <- kruskal.test(data$normalized.losses ~ data$symboling)$p.value

#-------------------------------------------------------------------------
model <- lm(data$horsepower  ~ factor(data$symboling))
# Perform ANOVA
anova_result <- anova(model)
# Extract effect size (eta-squared or omega-squared)
eta_sq_horsepower <- anova_result$`Sum Sq`[1] / sum(anova_result$`Sum Sq`)
omega_horsepower <- (anova_result$`Sum Sq`[1] - (anova_result$`Df`[1] * anova_result$`Mean Sq`[2])) / (sum(anova_result$`Sum Sq`) + anova_result$`Sum Sq`[1])

kruskal_horsepower <- kruskal.test(data$horsepower ~ data$symboling)$p.value
#--------------------------------------------------------------------
model <- lm(data$peak.rpm  ~ factor(data$symboling))
# Perform ANOVA
anova_result <- anova(model)
# Extract effect size (eta-squared or omega-squared)
eta_sq_peak.rpm <- anova_result$`Sum Sq`[1] / sum(anova_result$`Sum Sq`)
omega_peak.rpm <- (anova_result$`Sum Sq`[1] - (anova_result$`Df`[1] * anova_result$`Mean Sq`[2])) / (sum(anova_result$`Sum Sq`) + anova_result$`Sum Sq`[1])

kruskal_peak.rpm <- kruskal.test(data$peak.rpm ~ data$symboling)$p.value
#--------------------------------------------------------------------
model <- lm(data$city.mpg  ~ factor(data$symboling))
# Perform ANOVA
anova_result <- anova(model)
# Extract effect size (eta-squared or omega-squared)
eta_sq_city.mpg <- anova_result$`Sum Sq`[1] / sum(anova_result$`Sum Sq`)
omega_city.mpg <- (anova_result$`Sum Sq`[1] - (anova_result$`Df`[1] * anova_result$`Mean Sq`[2])) / (sum(anova_result$`Sum Sq`) + anova_result$`Sum Sq`[1])

kruskal_city.mpg <- kruskal.test(data$city.mpg ~ data$symboling)$p.value
#--------------------------------------------------------------------
model <- lm(data$highway.mpg  ~ factor(data$symboling))
# Perform ANOVA
anova_result <- anova(model)
# Extract effect size (eta-squared or omega-squared)
eta_sq_highway.mpg <- anova_result$`Sum Sq`[1] / sum(anova_result$`Sum Sq`)
omega_highway.mpg <- (anova_result$`Sum Sq`[1] - (anova_result$`Df`[1] * anova_result$`Mean Sq`[2])) / (sum(anova_result$`Sum Sq`) + anova_result$`Sum Sq`[1])

kruskal_highway.mpg <- kruskal.test(data$highway.mpg ~ data$symboling)$p.value
#--------------------------------------------------------------------
model <- lm(data$price  ~ factor(data$symboling))
# Perform ANOVA
anova_result <- anova(model)
# Extract effect size (eta-squared or omega-squared)
eta_sq_price <- anova_result$`Sum Sq`[1] / sum(anova_result$`Sum Sq`)
omega_price <- (anova_result$`Sum Sq`[1] - (anova_result$`Df`[1] * anova_result$`Mean Sq`[2])) / (sum(anova_result$`Sum Sq`) + anova_result$`Sum Sq`[1])

kruskal_price <- kruskal.test(data$price ~ data$symboling)$p.value
#--------------------------------------------------------------------
model <- lm(data$curb.weight  ~ factor(data$symboling))
# Perform ANOVA
anova_result <- anova(model)
# Extract effect size (eta-squared or omega-squared)
eta_sq_curb.weight <- anova_result$`Sum Sq`[1] / sum(anova_result$`Sum Sq`)
omega_curb.weight <- (anova_result$`Sum Sq`[1] - (anova_result$`Df`[1] * anova_result$`Mean Sq`[2])) / (sum(anova_result$`Sum Sq`) + anova_result$`Sum Sq`[1])

kruskal_curb.weight <- kruskal.test(data$curb.weight ~ data$symboling)$p.value
#--------------------------------------------------------------------
model <- lm(data$engine.size  ~ factor(data$symboling))
# Perform ANOVA
anova_result <- anova(model)
# Extract effect size (eta-squared or omega-squared)
eta_sq_engine.size <- anova_result$`Sum Sq`[1] / sum(anova_result$`Sum Sq`)
omega_engine.size <- (anova_result$`Sum Sq`[1] - (anova_result$`Df`[1] * anova_result$`Mean Sq`[2])) / (sum(anova_result$`Sum Sq`) + anova_result$`Sum Sq`[1])

kruskal_engine.size <- kruskal.test(data$engine.size ~ data$symboling)$p.value
#--------------------------------------------------------------------
model <- lm(data$width  ~ factor(data$symboling))
# Perform ANOVA
anova_result <- anova(model)
# Extract effect size (eta-squared or omega-squared)
eta_sq_width <- anova_result$`Sum Sq`[1] / sum(anova_result$`Sum Sq`)
omega_width <- (anova_result$`Sum Sq`[1] - (anova_result$`Df`[1] * anova_result$`Mean Sq`[2])) / (sum(anova_result$`Sum Sq`) + anova_result$`Sum Sq`[1])

kruskal_width <- kruskal.test(data$width ~ data$symboling)$p.value
#--------------------------------------------------------------------
model <- lm(data$wheel.base  ~ factor(data$symboling))
# Perform ANOVA
anova_result <- anova(model)
# Extract effect size (eta-squared or omega-squared)
eta_sq_wheel.base <- anova_result$`Sum Sq`[1] / sum(anova_result$`Sum Sq`)
omega_wheel.base <- (anova_result$`Sum Sq`[1] - (anova_result$`Df`[1] * anova_result$`Mean Sq`[2])) / (sum(anova_result$`Sum Sq`) + anova_result$`Sum Sq`[1])

kruskal_wheel.base <- kruskal.test(data$wheel.base ~ data$symboling)$p.value
#--------------------------------------------------------------------
model <- lm(data$bore  ~ factor(data$symboling))
# Perform ANOVA
anova_result <- anova(model)
# Extract effect size (eta-squared or omega-squared)
eta_sq_bore <- anova_result$`Sum Sq`[1] / sum(anova_result$`Sum Sq`)
omega_bore <- (anova_result$`Sum Sq`[1] - (anova_result$`Df`[1] * anova_result$`Mean Sq`[2])) / (sum(anova_result$`Sum Sq`) + anova_result$`Sum Sq`[1])

kruskal_bore <- kruskal.test(data$bore ~ data$symboling)$p.value
#--------------------------------------------------------------------
model <- lm(data$compression.ratio  ~ factor(data$symboling))
# Perform ANOVA
anova_result <- anova(model)
# Extract effect size (eta-squared or omega-squared)
eta_sq_compression.ratio <- anova_result$`Sum Sq`[1] / sum(anova_result$`Sum Sq`)
omega_compression.ratio <- (anova_result$`Sum Sq`[1] - (anova_result$`Df`[1] * anova_result$`Mean Sq`[2])) / (sum(anova_result$`Sum Sq`) + anova_result$`Sum Sq`[1])

kruskal_compression.ratio <- kruskal.test(data$compression.ratio ~ data$symboling)$p.value
#--------------------------------------------------------------------
model <- lm(data$stroke  ~ factor(data$symboling))
# Perform ANOVA
anova_result <- anova(model)
# Extract effect size (eta-squared or omega-squared)
eta_sq_stroke <- anova_result$`Sum Sq`[1] / sum(anova_result$`Sum Sq`)
omega_stroke <- (anova_result$`Sum Sq`[1] - (anova_result$`Df`[1] * anova_result$`Mean Sq`[2])) / (sum(anova_result$`Sum Sq`) + anova_result$`Sum Sq`[1])

kruskal_stroke <- kruskal.test(data$stroke ~ data$symboling)$p.value
#--------------------------------------------------------------------
model <- lm(data$length  ~ factor(data$symboling))
# Perform ANOVA
anova_result <- anova(model)
# Extract effect size (eta-squared or omega-squared)
eta_sq_length <- anova_result$`Sum Sq`[1] / sum(anova_result$`Sum Sq`)
omega_length <- (anova_result$`Sum Sq`[1] - (anova_result$`Df`[1] * anova_result$`Mean Sq`[2])) / (sum(anova_result$`Sum Sq`) + anova_result$`Sum Sq`[1])

kruskal_length <- kruskal.test(data$length ~ data$symboling)$p.value


num_cors <- data.frame(c("height","normalized.losses","horsepower", "peak.rpm", "city.mpg", "highway.mpg", "price", 
            "curb.weight", "engine.size", "width", "wheel.base", "bore", "compression.ratio", "stroke"  , "length"),  
 c(eta_sq_height, eta_sq_normalized_losses,eta_sq_horsepower, eta_sq_peak.rpm, eta_sq_city.mpg, eta_sq_highway.mpg,eta_sq_price, eta_sq_curb.weight, eta_sq_engine.size, eta_sq_width, eta_sq_wheel.base, eta_sq_bore,
 eta_sq_compression.ratio, eta_sq_stroke, eta_sq_length), 
 c(omega_height, omega_sqnormalized_losses, omega_horsepower, omega_peak.rpm, omega_city.mpg, omega_highway.mpg,omega_price, omega_curb.weight, omega_engine.size, omega_width, omega_wheel.base, omega_bore, omega_compression.ratio, omega_stroke, omega_length),  
 c(kruskal_height, kruskal_normalized_losses, kruskal_horsepower, kruskal_peak.rpm, kruskal_city.mpg,  kruskal_highway.mpg, kruskal_price, kruskal_curb.weight, kruskal_engine.size, kruskal_width, kruskal_wheel.base, kruskal_bore, kruskal_compression.ratio, kruskal_stroke, kruskal_length))
                    
colnames(num_cors) <- c("Zmienna ilościowa", "$\\eta$", "omega squared", "kruskal p value")
num_cors <- num_cors[order(num_cors[[2]], decreasing = TRUE),]

tab_num_cors <- xtable(num_cors,
               digits = c(3,3,3,3,-2), 
               row.names = TRUE, 
               caption = "Porównanie współczynników dla zmiennych ilościowych", 
               label = "tab:num_cors")

print(tab_num_cors,type = "latex", table.placement = "H")
@

Jak możemy zauważyc w tabeli powyżej, hierarchia zmiennych jest dokładnie taka sama dla współczynników $\eta^2$, $\omega^2$ oraz bardzo podobna dla wartości p-value (tylko, że tam rosnąco zamiast malejąco). Co więcej możemy stwierdzić, że wyniki w tabeli prowadzą do bardzo podobnych wniosków co analiza graficzna jeśli chodzi o analizę hierarchii zależności między zmiennymi ilościowymi, a zmienną \texttt{symboling} tzn. te same zmienne (\texttt{wheel.base}, \texttt{height}, \texttt{length}, \texttt{normalized.losses}) są w grupie najbardziej istotnych i te same zmienne (\texttt{compression.ratio}, \texttt{stroke}) są w grupie najmniej istotnych. 

\subsubsection{Analiza formalna zależności między zmienną objaśnianą, a zmiennymi jakościowymi}

Natomiast dla porównania miary związku między jakościową zmienną objaśnianą, a innymi zmiennymi jakosciowymi użyliśmy współczynnika V Craméra \cite{cramerV}. W tym celu zastosowaliśmy funkcję \texttt{cramerV} z pakietu \textbf{rcompanion} \cite{cramerVR}. Współczynnik ten przyjmuje wartości od $0$ do $1$, przy czym im większa jego wartość, tym większy związek między poszczególnymi zmiennymi. Współczynniki zostały uszeregowane od największego i przedstawione w tabeli \ref{tab:VCram}.

<<V_cramer_table, results="asis", echo=FALSE>>=
factor_V_Cramer <- data.frame(c("make", "body.style", "aspiration", "num.of.doors", "drive.wheels", 
                            "engine.type", "num.of.cylinders", "fuel.system"), 
                          c(cramerV(table(data$symboling, data$make)),
                            cramerV(table(data$symboling, data$body.style)),
                            cramerV(table(data$symboling, data$aspiration)),
                            cramerV(table(data$symboling, data$num.of.doors)),
                            cramerV(table(data$symboling, data$drive.wheels)),
                            cramerV(table(data$symboling, data$engine.type)),
                            cramerV(table(data$symboling, data$num.of.cylinders)),
                            cramerV(table(data$symboling, data$fuel.system))
                            ))
colnames(factor_V_Cramer) <- c("Zmienna jakościowa", "Współczynnik V Cramera")
factor_V_Cramer <- factor_V_Cramer[order(factor_V_Cramer[[2]], decreasing = TRUE),]
 
tab_V_Cramer <- xtable(factor_V_Cramer,
               digits = 3, 
               row.names = TRUE, 
               caption = "Wartości V Cram", 
               label = "tab:VCram")

print(tab_V_Cramer,type = "latex", table.placement = "H")
@
Jak możemy zauważyć powyżej, również w przypadku zmiennych jakościowych analiza formalna prowadzi do podobnych wniosków co analiza graficzna, mianowicie zmienna \texttt{num.of.doors} faktycznie ma zdecydowanie największą wartość współczynnika, natomiast druga w tej hierarchii zmienna \texttt{make} również ma współczynnik zdecydowanie większy od pozostałych. Dodatkowo możemy zaobserwować, że przypuszczenie o tym, że zmienna \texttt{aspiration} jest mało istotna jest potwierdzone przez jej współczynnik V Cramera, i tego jak blisko najmniejszej wartości się znajduje.

\subsubsection{Zależności między resztą zmiennych}

Poniżej, na rysunku \ref{fig:explor_7}\ zamieszczona zotała tablica korelacji między wszystkimi zmiennymi ilościowymi z mapą ciepła. Stworzona została ona przy pomocy funkcji \texttt{plot corelation} z~pakietu \textbf{DataExplorer}.
<<explor_7, eval=TRUE, echo=FALSE, cache=TRUE, fig.height=7, fig.width=7, fig.cap="Tabela korelacji między zmiennymi ilościowymi">>=
plot_correlation(na.omit(data), type = "continuous")
@

Jak widzimy powyżej, między zmiennymi ilościowymi istnieje bardzo dużo silnych korelacji, najsilniej skorelowane są zmienne dotyczące spalania paliwa w mieście i na autostradzie, dodatkowo widzimy dużo korelacji o wartości bezwzględnej przekraczającej $0.8$, a jeszcze więcej wartości większych od $0.7$. Ponadto możemy stwierdzić, że najmniej skorelowanymi z resztą zmiennych są \texttt{compression.ratio}, \texttt{stroke} i \texttt{normalized.losses} 

Ponadto stworzone zostało kilka scatterplotów między różnymi parami zmiennych ilościowych. Zostały one przedstawione na rysunkach \ref{fig:explor_scatt1}, \ref{fig:explor_scatt2}, \ref{fig:explor_scatt3} i \ref{fig:explor_scatt4}.
%
<<explor_scatt1, eval=TRUE, echo=FALSE, cache=TRUE, fig.cap="Porównanie zależności między zmiennymi engine.size i price">>=

ggplot(data = data,aes(x=price, y=engine.size)) + 
  geom_point()
@

<<explor_scatt2, eval=TRUE, echo=FALSE, cache=TRUE, fig.cap="Porównanie zależności między zmiennymi horsepower i price">>=
ggplot(data = data,aes(x=price, y=horsepower)) + 
  geom_point()
@

<<explor_scatt3, eval=TRUE, echo=FALSE, cache=TRUE, fig.cap="Porównanie zależności między zmiennymi ehorsepower i highway.mpg">>=
ggplot(data = data,aes(x=horsepower, y=highway.mpg)) + 
  geom_point()+labs(title="horsepower vs highway.mpg")
@

<<explor_scatt4, eval=TRUE, echo=FALSE, cache=TRUE, fig.cap="Porównanie zależności między zmiennymi engine.size i city.mpg">>=
ggplot(data = data,aes(x=horsepower, y=city.mpg)) + 
  geom_point()

@

Na podstawie wykresów powyżej, możemy potwierdzić kilka wartości liczbowych z tablicy korelacji \ref{fig:explor_7}. Dwa pierwsze wykresy, czyli \ref{fig:explor_scatt1}, \ref{fig:explor_scatt2} przedstawiające odpowiednio zależności między ceną, a rozmiarem silnika i ceną, a mocą silnika potwiewrdzają obliczone wartości korelacji - $0.86$ i $0.76$ odpowiednio. Widzimy, że faktycznie wraz ze wzrostem ceny wartości obu tych zmiennych mają tendencję rosnącą. Natomiast jeśli chodzi o wykresy \ref{fig:explor_scatt3} i \ref{fig:explor_scatt4}, przedstawiające zależności między liczbą koni mechanicznych a spalaniem paliwa przez auto na autostradzie oraz w mieście, one również potwierdzają obliczone wartości korelacji, które wynosiły odpowiednio $-0.77$ i $-0.8$. Widzimy, że wraz ze wzrostem liczby koni mechannicznych oba typy spalania mają tendencję spadkową.

Poniżej, na rysunku \ref{fig:explor_dens} przedstawiony został wykres porównujący estymowane gęstości zmiennej ilościowej \texttt{engine.size} ze względu na klasy zmiennej jakościowej \texttt{body.style}. Wykres ten pokazuje, że istnieją różnice dla rozkładów rozmiaru silnika w zależności od rodzaju nadwozia.

<<explor_dens, eval=TRUE, echo=FALSE, cache=TRUE, fig.cap="Porównanie gęstości zmiennej engine.size ze względu na wartości zmiennej body.style" >>=
filter_bs <- data %>% filter(body.style %in% c('sedan', 'hatchback' ,'wagon', 'hardtop', 'convertible'))
ggplot(data = filter_bs,
       aes(x=engine.size, fill=body.style)) + geom_density(alpha=0.4)
@

\section{Klasyfikacja zmiennej objaśnianej}

Na poczatek, stworzymy podzbiór naszych danych złożony tylko ze zmiennych ilościowych oraz zmiennej objaśnianej \texttt{symboling}. Tworzymy go na potrzeby niektórych modeli, które nie mogą przyjmować zmiennych jakościowych.
<<explor_lda, eval=TRUE, echo=TRUE>>=
data_num <- data[c("symboling", int_kol, num_kol)]
@


\subsection{KNN}

Na samym starcie zaimplementujemy metodę k-najbliższych sąsiadów dla $k=3$, $k=5$, $k=7$, $k=9$, $k=11$, $k=13$, $k=15$, $k=19$, $k=25$   oraz dla następujących podzbiorów zmiennych:
\begin{itemize}
\item wszystkie zmienne numeryczne
\item $8$ wybranych najbardziej istotnych zmiennych numerycznych: \texttt{normalized.losses}, \texttt{height}, \texttt{length}, \texttt{wheel.base}, \texttt{curb.weight}, \texttt{bore}, \texttt{city.mpg} i \texttt{highway.mpg}
\item $4$ wybrane najbardziej istotne zmienne numeryczne: \texttt{normalized.losses}, \texttt{height}, \texttt{length}, \texttt{wheel.base}
\end{itemize}
\par
Do tego celu użyjemy funkcji \texttt{ipredknn} z pakietu \textbf{ipred}. Zbiór treningowy będzie obejmował $0.7$ rozmiaru całej próbki, naszą metryką będzie dokładność, a całą procedurę powtórzymy $100$ razy, żeby uśrednić otrzymane rezultaty, a także sprawdzić rozrzut otrzymanych rezultatów.


<<klasyf_KNN_sym, eval=TRUE, echo=FALSE, cache=TRUE>>=

n <- dim(data_num)[1]

KNN.accuracy_all_k3 <- vector()
KNN.accuracy8_k3 <- vector()
KNN.accuracy4_k3 <- vector()

KNN.accuracy_all_k5 <- vector()
KNN.accuracy8_k5 <- vector()
KNN.accuracy4_k5 <- vector()

KNN.accuracy_all_k7 <- vector()
KNN.accuracy8_k7 <- vector()
KNN.accuracy4_k7 <- vector()

KNN.accuracy_all_k9 <- vector()
KNN.accuracy8_k9 <- vector()
KNN.accuracy4_k9 <- vector()

KNN.accuracy_all_k11 <- vector()
KNN.accuracy8_k11 <- vector()
KNN.accuracy4_k11 <- vector()

KNN.accuracy_all_k13 <- vector()
KNN.accuracy8_k13 <- vector()
KNN.accuracy4_k13 <- vector()

KNN.accuracy_all_k15 <- vector()
KNN.accuracy8_k15 <- vector()
KNN.accuracy4_k15 <- vector()

KNN.accuracy_all_k19 <- vector()
KNN.accuracy8_k19 <- vector()
KNN.accuracy4_k19 <- vector()

KNN.accuracy_all_k25 <- vector()
KNN.accuracy8_k25 <- vector()
KNN.accuracy4_k25 <- vector()
for (i in 1:100){
# losujemy obiekty do zbioru uczącego i testowego
learning.set.index <- sample(1:n,0.7*n)

learning.set <- data_num[learning.set.index,]
test.set     <- data_num[-learning.set.index,]
etykietki.rzecz <- test.set$symboling
n.test <- dim(test.set)[1]

#---------------------------------------------------DLA k=3--------------------------------------------------
# budujemy model
model.knn.1 <- ipredknn(symboling ~ ., data=learning.set, k=3)
etykietki.rzecz <- test.set$symboling

etykietki.prog <- predict(model.knn.1,test.set,type="class")
# tablica kontyngencji
(wynik.tablica <- table(etykietki.prog,etykietki.rzecz))
# błąd klasyfikacji
accuracy <- (n.test - sum(diag(wynik.tablica))) / n.test

KNN.accuracy_all_k3 <- append(KNN.accuracy_all_k3, accuracy)
                                
#---------------------------------------------------------------

model.knn.1 <- ipredknn(symboling ~ normalized.losses + height + length + wheel.base + curb.weight + bore +city.mpg +
                          highway.mpg, data=learning.set, k=3)

etykietki.prog <- predict(model.knn.1,test.set,type="class")

# tablica kontyngencji
(wynik.tablica <- table(etykietki.prog,etykietki.rzecz))

# błąd klasyfikacji
accuracy <- (n.test - sum(diag(wynik.tablica))) / n.test
KNN.accuracy8_k3 <- append(KNN.accuracy8_k3, accuracy)
#------------------------------------------------------------------
model.knn.1 <- ipredknn(symboling ~ normalized.losses + height + length + wheel.base, data=learning.set, k=3)
etykietki.prog <- predict(model.knn.1,test.set,type="class")

# tablica kontyngencji
(wynik.tablica <- table(etykietki.prog,etykietki.rzecz))

# błąd klasyfikacji
accuracy <- (n.test - sum(diag(wynik.tablica))) / n.test
KNN.accuracy4_k3 <- append(KNN.accuracy4_k3, accuracy)
#---------------------------------------------------DLA k=5--------------------------------------------------
# budujemy model
model.knn.1 <- ipredknn(symboling ~ ., data=learning.set, k=5)

etykietki.prog <- predict(model.knn.1,test.set,type="class")
# tablica kontyngencji
wynik.tablica <- table(etykietki.prog,etykietki.rzecz)
# błąd klasyfikacji
accuracy <- (n.test - sum(diag(wynik.tablica))) / n.test
KNN.accuracy_all_k5 <- append(KNN.accuracy_all_k5, accuracy)
#---------------------------------------------------------------

model.knn.1 <- ipredknn(symboling ~ normalized.losses + height + length + wheel.base + curb.weight + bore +city.mpg +
                          highway.mpg, data=learning.set, k=5)

etykietki.prog <- predict(model.knn.1,test.set,type="class")

# tablica kontyngencji
(wynik.tablica <- table(etykietki.prog,etykietki.rzecz))

# błąd klasyfikacji
accuracy <- (n.test - sum(diag(wynik.tablica))) / n.test
KNN.accuracy8_k5 <- append(KNN.accuracy8_k5, accuracy)
#------------------------------------------------------------------
model.knn.1 <- ipredknn(symboling ~ normalized.losses + height + length + wheel.base, data=learning.set, k=5)

etykietki.prog <- predict(model.knn.1,test.set,type="class")

# tablica kontyngencji
(wynik.tablica <- table(etykietki.prog,etykietki.rzecz))

# błąd klasyfikacji
accuracy <- (n.test - sum(diag(wynik.tablica))) / n.test
KNN.accuracy4_k5 <- append(KNN.accuracy4_k5, accuracy)
#---------------------------------------------------DLA k=7--------------------------------------------------
# budujemy model
model.knn.1 <- ipredknn(symboling ~ ., data=learning.set, k=7)

etykietki.prog <- predict(model.knn.1,test.set,type="class")
# tablica kontyngencji
(wynik.tablica <- table(etykietki.prog,etykietki.rzecz))
# błąd klasyfikacji
accuracy <- (n.test - sum(diag(wynik.tablica))) / n.test
KNN.accuracy_all_k7 <- append(KNN.accuracy_all_k7, accuracy)
#---------------------------------------------------------------

model.knn.1 <- ipredknn(symboling ~ normalized.losses + height + length + wheel.base + curb.weight + bore +city.mpg +
                          highway.mpg, data=learning.set, k=7)

etykietki.prog <- predict(model.knn.1,test.set,type="class")

# tablica kontyngencji
(wynik.tablica <- table(etykietki.prog,etykietki.rzecz))

# błąd klasyfikacji
accuracy <- (n.test - sum(diag(wynik.tablica))) / n.test
KNN.accuracy8_k7 <- append(KNN.accuracy8_k7, accuracy)
#------------------------------------------------------------------
model.knn.1 <- ipredknn(symboling ~ normalized.losses + height + length + wheel.base, data=learning.set, k=7)

etykietki.prog <- predict(model.knn.1,test.set,type="class")

# tablica kontyngencji
(wynik.tablica <- table(etykietki.prog,etykietki.rzecz))

# błąd klasyfikacji
accuracy <- (n.test - sum(diag(wynik.tablica))) / n.test
KNN.accuracy4_k7 <- append(KNN.accuracy4_k7, accuracy)
#---------------------------------------------------DLA k=9--------------------------------------------------
# budujemy model
model.knn.1 <- ipredknn(symboling ~ ., data=learning.set, k=9)

etykietki.prog <- predict(model.knn.1,test.set,type="class")
# tablica kontyngencji
(wynik.tablica <- table(etykietki.prog,etykietki.rzecz))
# błąd klasyfikacji
accuracy <- (n.test - sum(diag(wynik.tablica))) / n.test
KNN.accuracy_all_k9 <- append(KNN.accuracy_all_k9, accuracy)
#---------------------------------------------------------------

model.knn.1 <- ipredknn(symboling ~ normalized.losses + height + length + wheel.base + curb.weight + bore +city.mpg +
                          highway.mpg, data=learning.set, k=9)

etykietki.prog <- predict(model.knn.1,test.set,type="class")

# tablica kontyngencji
(wynik.tablica <- table(etykietki.prog,etykietki.rzecz))

# błąd klasyfikacji
accuracy <- (n.test - sum(diag(wynik.tablica))) / n.test
KNN.accuracy8_k9 <- append(KNN.accuracy8_k9, accuracy)
#------------------------------------------------------------------
model.knn.1 <- ipredknn(symboling ~ normalized.losses + height + length + wheel.base, data=learning.set, k=9)

etykietki.prog <- predict(model.knn.1,test.set,type="class")

# tablica kontyngencji
(wynik.tablica <- table(etykietki.prog,etykietki.rzecz))

# błąd klasyfikacji
accuracy <- (n.test - sum(diag(wynik.tablica))) / n.test
KNN.accuracy4_k9 <- append(KNN.accuracy4_k9, accuracy)
#---------------------------------------------------DLA k=11--------------------------------------------------
# budujemy model
model.knn.1 <- ipredknn(symboling ~ ., data=learning.set, k=11)

etykietki.prog <- predict(model.knn.1,test.set,type="class")
# tablica kontyngencji
(wynik.tablica <- table(etykietki.prog,etykietki.rzecz))
# błąd klasyfikacji
accuracy <- (n.test - sum(diag(wynik.tablica))) / n.test
KNN.accuracy_all_k11 <- append(KNN.accuracy_all_k11, accuracy)
#---------------------------------------------------------------

model.knn.1 <- ipredknn(symboling ~ normalized.losses + height + length + wheel.base + curb.weight + bore +city.mpg +
                          highway.mpg, data=learning.set, k=11)

etykietki.prog <- predict(model.knn.1,test.set,type="class")

# tablica kontyngencji
(wynik.tablica <- table(etykietki.prog,etykietki.rzecz))

# błąd klasyfikacji
accuracy <- (n.test - sum(diag(wynik.tablica))) / n.test
KNN.accuracy8_k11 <- append(KNN.accuracy8_k11, accuracy)
#------------------------------------------------------------------
model.knn.1 <- ipredknn(symboling ~ normalized.losses + height + length + wheel.base, data=learning.set, k=11)

etykietki.prog <- predict(model.knn.1,test.set,type="class")

# tablica kontyngencji
(wynik.tablica <- table(etykietki.prog,etykietki.rzecz))

# błąd klasyfikacji
accuracy <- (n.test - sum(diag(wynik.tablica))) / n.test
KNN.accuracy4_k11 <- append(KNN.accuracy4_k11, accuracy)
#---------------------------------------------------DLA k=13--------------------------------------------------
# budujemy model
model.knn.1 <- ipredknn(symboling ~ ., data=learning.set, k=13)

etykietki.prog <- predict(model.knn.1,test.set,type="class")
# tablica kontyngencji
(wynik.tablica <- table(etykietki.prog,etykietki.rzecz))
# błąd klasyfikacji
accuracy <- (n.test - sum(diag(wynik.tablica))) / n.test
KNN.accuracy_all_k13 <- append(KNN.accuracy_all_k13, accuracy)
#---------------------------------------------------------------

model.knn.1 <- ipredknn(symboling ~ normalized.losses + height + length + wheel.base + curb.weight + bore +city.mpg +
                          highway.mpg, data=learning.set, k=13)

etykietki.prog <- predict(model.knn.1,test.set,type="class")

# tablica kontyngencji
(wynik.tablica <- table(etykietki.prog,etykietki.rzecz))

# błąd klasyfikacji
accuracy <- (n.test - sum(diag(wynik.tablica))) / n.test
KNN.accuracy8_k13 <- append(KNN.accuracy8_k13, accuracy)
#------------------------------------------------------------------
model.knn.1 <- ipredknn(symboling ~ normalized.losses + height + length + wheel.base, data=learning.set, k=13)

etykietki.prog <- predict(model.knn.1,test.set,type="class")

# tablica kontyngencji
(wynik.tablica <- table(etykietki.prog,etykietki.rzecz))

# błąd klasyfikacji
accuracy <- (n.test - sum(diag(wynik.tablica))) / n.test

KNN.accuracy4_k13 <- append(KNN.accuracy4_k13, accuracy)
#---------------------------------------------------DLA k=15--------------------------------------------------
# budujemy model
model.knn.1 <- ipredknn(symboling ~ ., data=learning.set, k=15)

etykietki.prog <- predict(model.knn.1,test.set,type="class")
# tablica kontyngencji
wynik.tablica <- table(etykietki.prog,etykietki.rzecz)
# błąd klasyfikacji
accuracy <- (n.test - sum(diag(wynik.tablica))) / n.test
KNN.accuracy_all_k15 <- append(KNN.accuracy_all_k15, accuracy)
#---------------------------------------------------------------

model.knn.1 <- ipredknn(symboling ~ normalized.losses + height + length + wheel.base + curb.weight + bore +city.mpg +
                          highway.mpg, data=learning.set, k=15)

etykietki.prog <- predict(model.knn.1,test.set,type="class")

# tablica kontyngencji
wynik.tablica <- table(etykietki.prog,etykietki.rzecz)

# błąd klasyfikacji
accuracy <- (n.test - sum(diag(wynik.tablica))) / n.test
KNN.accuracy8_k15 <- append(KNN.accuracy8_k15, accuracy)
#------------------------------------------------------------------
model.knn.1 <- ipredknn(symboling ~ normalized.losses + height + length + wheel.base, data=learning.set, k=11)

etykietki.prog <- predict(model.knn.1,test.set,type="class")

# tablica kontyngencji
(wynik.tablica <- table(etykietki.prog,etykietki.rzecz))

# błąd klasyfikacji
accuracy <- (n.test - sum(diag(wynik.tablica))) / n.test
KNN.accuracy4_k15 <- append(KNN.accuracy4_k15, accuracy)
#----------------------------------------------DLA k=19--------------------------------------------------
# budujemy model
model.knn.1 <- ipredknn(symboling ~ ., data=learning.set, k=19)

etykietki.prog <- predict(model.knn.1,test.set,type="class")
# tablica kontyngencji
wynik.tablica <- table(etykietki.prog,etykietki.rzecz)
# błąd klasyfikacji
accuracy <- (n.test - sum(diag(wynik.tablica))) / n.test
KNN.accuracy_all_k19 <- append(KNN.accuracy_all_k19, accuracy)
#---------------------------------------------------------------

model.knn.1 <- ipredknn(symboling ~ normalized.losses + height + length + wheel.base + curb.weight + bore +city.mpg +
                          highway.mpg, data=learning.set, k=19)

etykietki.prog <- predict(model.knn.1,test.set,type="class")

# tablica kontyngencji
wynik.tablica <- table(etykietki.prog,etykietki.rzecz)

# błąd klasyfikacji
accuracy <- (n.test - sum(diag(wynik.tablica))) / n.test
KNN.accuracy8_k19 <- append(KNN.accuracy8_k19, accuracy)
#------------------------------------------------------------------
model.knn.1 <- ipredknn(symboling ~ normalized.losses + height + length + wheel.base, data=learning.set, k=11)

etykietki.prog <- predict(model.knn.1,test.set,type="class")

# tablica kontyngencji
(wynik.tablica <- table(etykietki.prog,etykietki.rzecz))

# błąd klasyfikacji
accuracy <- (n.test - sum(diag(wynik.tablica))) / n.test
KNN.accuracy4_k19 <- append(KNN.accuracy4_k19, accuracy)
#---------------------------------------------------DLA k=25--------------------------------------------------
# budujemy model
model.knn.1 <- ipredknn(symboling ~ ., data=learning.set, k=25)

etykietki.prog <- predict(model.knn.1,test.set,type="class")
# tablica kontyngencji
wynik.tablica <- table(etykietki.prog,etykietki.rzecz)
# błąd klasyfikacji
accuracy <- (n.test - sum(diag(wynik.tablica))) / n.test
KNN.accuracy_all_k25 <- append(KNN.accuracy_all_k25, accuracy)
#---------------------------------------------------------------

model.knn.1 <- ipredknn(symboling ~ normalized.losses + height + length + wheel.base + curb.weight + bore +city.mpg +
                          highway.mpg, data=learning.set, k=25)

etykietki.prog <- predict(model.knn.1,test.set,type="class")

# tablica kontyngencji
wynik.tablica <- table(etykietki.prog,etykietki.rzecz)

# błąd klasyfikacji
accuracy <- (n.test - sum(diag(wynik.tablica))) / n.test
KNN.accuracy8_k25 <- append(KNN.accuracy8_k25, accuracy)
#------------------------------------------------------------------
model.knn.1 <- ipredknn(symboling ~ normalized.losses + height + length + wheel.base, data=learning.set, k=11)

etykietki.prog <- predict(model.knn.1,test.set,type="class")

# tablica kontyngencji
(wynik.tablica <- table(etykietki.prog,etykietki.rzecz))

# błąd klasyfikacji
accuracy <- (n.test - sum(diag(wynik.tablica))) / n.test
KNN.accuracy4_k25 <- append(KNN.accuracy4_k25, accuracy)

}

knn_means <- data.frame(rep(c(3,5,7,9,11,13,15,19,25),3), c(rep("Wszystkie zmienne",9), rep("8 zmiennych",9), rep("4 zmienne",9)),
                        c(mean(KNN.accuracy_all_k3), mean(KNN.accuracy_all_k5),  mean(KNN.accuracy_all_k7), 
                          mean(KNN.accuracy_all_k9),  mean(KNN.accuracy_all_k11),  mean(KNN.accuracy_all_k13),  
                          mean(KNN.accuracy_all_k15), mean(KNN.accuracy_all_k19), mean(KNN.accuracy_all_k25), mean(KNN.accuracy8_k3), mean(KNN.accuracy8_k5),  mean(KNN.accuracy8_k7), 
                          mean(KNN.accuracy8_k9),  mean(KNN.accuracy8_k11),  mean(KNN.accuracy8_k13),  
                          mean(KNN.accuracy8_k15), mean(KNN.accuracy8_k19),  mean(KNN.accuracy8_k25), mean(KNN.accuracy4_k3), mean(KNN.accuracy4_k5),  mean(KNN.accuracy4_k7), 
                          mean(KNN.accuracy4_k9),  mean(KNN.accuracy4_k11),  mean(KNN.accuracy4_k13),  
                          mean(KNN.accuracy4_k15), mean(KNN.accuracy4_k19), mean(KNN.accuracy4_k25)))
colnames(knn_means) <- c("k","cat","Dokładność")                        


@

Na rysunku \ref{fig:klasyf_KNN_wykres_1} przedstawione zostało porównanie średnich między różnymi wybranymi podzbiorami zmiennych dla każdego z wybranych $k$.

<<klasyf_KNN_wykres_1, eval=TRUE, echo=FALSE, cache=TRUE, fig.cap="Porównanie średnich dokładności dla różnych wyborów cech">>=
ggplot(knn_means, aes(x=k, y=Dokładność, color =cat))+
  geom_point()+
  geom_line()+
  scale_x_continuous( breaks = c(3,5,7,9,11,13,15,19,25))
@
Jak możemy zaobserwować powyżej, niezależnie od wybranej wartości $k$, rezultaty zawsze okazywały się jednoznaczne - im więcej zmiennych, tym lepiej dla metody $KNN$ tzn. lepsze mediany dokładności otrzymaliśmy, czyli tak samo jak w przypadku średnich z rysunku \ref{fig:klasyf_KNN_wykres_1}. Ponadto widzimy, że dla każdego z wybranych podzbiorów zmiennych, wartość optymalna $k$~jest inna. Dla wszystkich zmiennych jest to $k=5$, dla podzbioru zawierającego $8$ zmiennych - $k=19$, a dla podzbioru z czterema zmiennymi - $k=13$. Dodatkowo widzimy, że dla dowolnego $k$ dokładność największa jest dla wszystkich zmiennych, a najmniejsza dla podzbioru $4$~zmiennych, zmieniają się tylko różnice między posczególnymi wyborami cech.
\par

Na rysunku \ref{fig:klasyf_KNN_wykres_2} w formie boxplotów zostały przedstawione rezultaty naszych symulacji. Czerwone kropki odpowiadają wartościom odpowiednich średnich.


<<klasyf_KNN_wykres_2, eval=TRUE, echo=FALSE, cache=TRUE, fig.width=8, fig.height=11.4, fig.cap="Porównanie dokładności metody KNN dla różnych k i różnych wyborów zmiennych">>=
plot_knn3 <- ggplot() + 
  geom_boxplot(aes(x="Wszystkie zmienne", y=KNN.accuracy_all_k3)) + 
  geom_boxplot(aes(x="8 zmiennych", y=KNN.accuracy8_k3)) + 
  geom_boxplot(aes(x= "4 zmienne", y=KNN.accuracy4_k3)) +
  geom_point(aes(x="Wszystkie zmienne", y=mean(KNN.accuracy_all_k3) ), size=2, color="red"  )+
  geom_point(aes(x="8 zmiennych", y=mean(KNN.accuracy8_k3) ), size=2, color="red"  )+
  geom_point(aes(x="4 zmienne", y=mean(KNN.accuracy4_k3) ), size=2, color="red"  )+ 
  ggtitle("Porównanie dokładności KNN, k=3") + 
  ylab("Dokładność") + 
  xlab("")

plot_knn5 <-  ggplot() + 
   geom_boxplot(aes(x="Wszystkie zmienne", y=KNN.accuracy_all_k5)) + 
   geom_boxplot(aes(x="8 zmiennych", y=KNN.accuracy8_k5)) + 
   geom_boxplot(aes(x= "4 zmienne", y=KNN.accuracy4_k5)) +
   geom_point(aes(x="Wszystkie zmienne", y=mean(KNN.accuracy_all_k5) ), size=2, color="red"  )+
   geom_point(aes(x="8 zmiennych", y=mean(KNN.accuracy8_k5) ), size=2, color="red"  )+
   geom_point(aes(x="4 zmienne", y=mean(KNN.accuracy4_k5) ), size=2, color="red"  )+ 
   ggtitle("Porównanie dokładności KNN, k=5") + 
   ylab("Dokładność") + 
   xlab("")
 
plot_knn7 <-  ggplot() + 
   geom_boxplot(aes(x="Wszystkie zmienne", y=KNN.accuracy_all_k7)) + 
   geom_boxplot(aes(x="8 zmiennych", y=KNN.accuracy8_k7)) + 
   geom_boxplot(aes(x= "4 zmienne", y=KNN.accuracy4_k7)) +
   geom_point(aes(x="Wszystkie zmienne", y=mean(KNN.accuracy_all_k7) ), size=2, color="red"  )+
   geom_point(aes(x="8 zmiennych", y=mean(KNN.accuracy8_k7) ), size=2, color="red"  )+
   geom_point(aes(x="4 zmienne", y=mean(KNN.accuracy4_k7) ), size=2, color="red"  )+ 
   ggtitle("Porównanie dokładności KNN, k=7") + 
   ylab("Dokładność") + 
   xlab("")
 

 
plot_knn9 <-  ggplot() + 
   geom_boxplot(aes(x="Wszystkie zmienne", y=KNN.accuracy_all_k9)) + 
   geom_boxplot(aes(x="8 zmiennych", y=KNN.accuracy8_k9)) + 
   geom_boxplot(aes(x= "4 zmienne", y=KNN.accuracy4_k9)) +
   geom_point(aes(x="Wszystkie zmienne", y=mean(KNN.accuracy_all_k9) ), size=2, color="red"  )+
   geom_point(aes(x="8 zmiennych", y=mean(KNN.accuracy8_k9) ), size=2, color="red"  )+
   geom_point(aes(x="4 zmienne", y=mean(KNN.accuracy4_k9) ), size=2, color="red"  )+ 
   ggtitle("Porównanie dokładności KNN, k=9") + 
   ylab("Dokładność") + 
   xlab("")
 
plot_knn11 <-  ggplot() + 
   geom_boxplot(aes(x="Wszystkie zmienne", y=KNN.accuracy_all_k11)) + 
   geom_boxplot(aes(x="8 zmiennych", y=KNN.accuracy8_k11)) + 
   geom_boxplot(aes(x= "4 zmienne", y=KNN.accuracy4_k11)) +
   geom_point(aes(x="Wszystkie zmienne", y=mean(KNN.accuracy_all_k11) ), size=2, color="red"  )+
   geom_point(aes(x="8 zmiennych", y=mean(KNN.accuracy8_k11) ), size=2, color="red"  )+
   geom_point(aes(x="4 zmienne", y=mean(KNN.accuracy4_k11) ), size=2, color="red"  )+ 
   ggtitle("Porównanie dokładności KNN, k=11") +
   
   ylab("Dokładność") + 
   xlab("")
 
plot_knn13 <-  ggplot() + 
   geom_boxplot(aes(x="Wszystkie zmienne", y=KNN.accuracy_all_k13)) + 
   geom_boxplot(aes(x="8 zmiennych", y=KNN.accuracy8_k13)) + 
   geom_boxplot(aes(x= "4 zmienne", y=KNN.accuracy4_k13)) +
   ggtitle("Porównanie dokładności KNN, k=13") + 
   geom_point(aes(x="Wszystkie zmienne", y=mean(KNN.accuracy_all_k13) ), size=2, color="red"  )+
   geom_point(aes(x="8 zmiennych", y=mean(KNN.accuracy8_k13) ), size=2, color="red"  )+
   geom_point(aes(x="4 zmienne", y=mean(KNN.accuracy4_k13) ), size=2, color="red"  )+ 
   ylab("Dokładność") + 
   xlab("")
 
plot_knn15 <-  ggplot() + 
   geom_boxplot(aes(x="Wszystkie zmienne", y=KNN.accuracy_all_k15)) + 
   geom_boxplot(aes(x="8 zmiennych", y=KNN.accuracy8_k15)) + 
   geom_boxplot(aes(x= "4 zmienne", y=KNN.accuracy4_k15)) +
   ggtitle("Porównanie dokładności KNN, k=15") + 
   geom_point(aes(x="Wszystkie zmienne", y=mean(KNN.accuracy_all_k15) ), size=2, color="red"  )+
   geom_point(aes(x="8 zmiennych", y=mean(KNN.accuracy8_k15) ), size=2, color="red"  )+
   geom_point(aes(x="4 zmienne", y=mean(KNN.accuracy4_k15) ), size=2, color="red"  )+ 
   ylab("Dokładność") + 
   xlab("")
 
plot_knn19 <-   ggplot() + 
   geom_boxplot(aes(x="Wszystkie zmienne", y=KNN.accuracy_all_k19)) + 
   geom_boxplot(aes(x="8 zmiennych", y=KNN.accuracy8_k19)) + 
   geom_boxplot(aes(x= "4 zmienne", y=KNN.accuracy4_k19)) +
   geom_point(aes(x="Wszystkie zmienne", y=mean(KNN.accuracy_all_k19) ), size=2, color="red"  )+
   geom_point(aes(x="8 zmiennych", y=mean(KNN.accuracy8_k19) ), size=2, color="red"  )+
   geom_point(aes(x="4 zmienne", y=mean(KNN.accuracy4_k19) ), size=2, color="red"  )+ 
   ggtitle("Porównanie dokładności KNN, k=19") + 
   ylab("Dokładność") + 
   xlab("")
  
plot_knn25 <-   ggplot() + 
   geom_boxplot(aes(x="Wszystkie zmienne", y=KNN.accuracy_all_k25)) + 
   geom_boxplot(aes(x="8 zmiennych", y=KNN.accuracy8_k25)) + 
   geom_boxplot(aes(x= "4 zmienne", y=KNN.accuracy4_k25)) +
   geom_point(aes(x="Wszystkie zmienne", y=mean(KNN.accuracy_all_k25) ), size=2, color="red"  )+
   geom_point(aes(x="8 zmiennych", y=mean(KNN.accuracy8_k25) ), size=2, color="red"  )+
   geom_point(aes(x="4 zmienne", y=mean(KNN.accuracy4_k25) ), size=2, color="red"  )+  
   ggtitle("Porównanie dokładności KNN, k=25") + 
   ylab("Dokładność") + 
   xlab("")
  
  grid.arrange(plot_knn3, plot_knn5, plot_knn7, plot_knn9, plot_knn11, plot_knn13, plot_knn15,
               plot_knn19, plot_knn25, ncol=2, nrow=5)
@

Jak możemy zaobserwować na rysunkach powyżej, modele KNN mają bardzo zbliżone rozrzuty niezależnie od wybranego $k$ oraz podzbioru cech. Przeważnie są one największe dla podzbioru $4$ zmiennych, ale nie są to duże różnice. Na boxplotach widzimy też bardzo mało wartości odstających, co może świadczyć o stabilności tej metody.


\subsection{Lasy losowe}
Kolejną metodą klasyfikacji użytą przez nas będą lasy losowe. Dużą zaletą tej metody jest fakt, że potrafi ona uzwględniać zarówno zmienne ilościowe, jak i jakościowe - porządkowe oraz nominalne - i to bez potrzeby ich transformacji na ich numeryczne wersje. 

\par Przez następujący błąd:
<<klasyf_RF_blad, eval=TRUE, echo=FALSE, cache=TRUE>>=
print("Error: One or more factor levels in the outcome has no data: '-2' ")
@
usuwamy z modelu wiersze z wartością zmiennej \texttt{symboling} równej $-2$ (oraz usuwamy tenże level z tej zmiennej).


Na początku stworzymy jeden model z pomocą lasów losowych. Zbiór treniningowy będzie miał wielkość równą $0.7$ rozmiaru naszych danych. Do zbudowania modelu posłużymy się funkcją \texttt{trainControl} z pakietu \textbf{caret} z $5$-krotną walidacją krzyżową oraz funkcją \texttt{randomForest} z pakietu \textbf{randomForest} ze standardową dla tej funkcji liczbą drzew równej $500$.
<<klasyf_RF_sym_1, eval=TRUE, echo=FALSE, cache=TRUE>>=
learning.set.index <- sample(1:n,0.7*n)
testing.set.index <- 1:n
testing.set.index <- testing.set.index[-learning.set.index]
learning.set_data <- data[learning.set.index, ]
testing.set_data <- data[-learning.set.index, ]

train_ctrl <- trainControl(method="cv", # type of resampling in this case Cross-Validated
                           number=5, # number of folds
                           search = "random") # we are performing a "random
           
model_rf <- randomForest(symboling ~ .,
                  data = learning.set_data,
                  method = "rf", # this will use the randomForest::randomForest function
                  metric = "Accuracy", #  metric should be optimized for 
                  trControl = train_ctrl,
                  # options to be passed to randomForest
                  ntree = 500,
                  keep.forest=TRUE,
                  importance=TRUE) 
@

<<klasyf_RF_plot__, eval=TRUE, echo=FALSE, cache=TRUE, fig.width=8, fig.height=6, fig.keep='none'>>=
oobData <- as.data.table(plot(model_rf))
oobData[, trees := .I]
oobData2 = melt(oobData, id.vars = "trees")
setnames(oobData2, "value", "error")
@

Na rysunku \ref{fig:klasyf_RF_plot1} zilustrowane zostały błędy w zależności od ilości drzew lasu losowego dla każdej z klas zmiennej \texttt{symboling} oraz błąd OOB czyli średni błąd tylko z tych danych, które nie zostały wylosowane do zbioru treningowego. 
<<klasyf_RF_plot1, eval=TRUE, echo=FALSE, cache=TRUE, fig.width=8, fig.height=6, warning=FALSE, fig.cap="Błedy dla poszczególnych klas w zależności od ilości drzew">>=
ggplot(data = oobData2, aes(x = trees, y = error, color = variable)) + geom_line(size=0.8) 
@

Na rysunku powyżej widzimy, że od pewnego momentu to jest ok. $ntrees=120$ wszystkie błędy, a tym samym wartości dokładności stabilizują się i nie zmieniają się wraz z dodaniem dodatkowych drzewek. Dlatego też będzie to maksymalna liczba drzew dla których będziemy budować i porównywać modele. Jednakże widzimy, że już od dużo mniejszej wartości tego parametru, ok. $20-30$ wartośći błędów, zmieniają się o względnie niewiele dla większości leveli naszej objaśnianej zmiennej jakościowej.

\par
Dodatkowo, model lasu losowego ma tą zaletę, że możemy przy jego pomocy zrobić ranking wszystkich zmiennych wg. ich istotności dla model (warto zwrócić uwagę na fakt, że ranking będzie obejmował na raz zmienne jakościowe i ilościowe). Na rysunku \ref{fig:klasyf_RF_plot2} poniżej przedstawione zostały dwie takie miary. Pierwsza z nich bazuje na sprawdzeniu jak bardzo obniży się dokładność jeśli daną zmienną wykluczymy z modelu, natomiast druga miara okreśła średni spadek czystości przez podziały danej zmiennej. Jeśli zmienna jest użyteczna, ma tendencję do dzielenia mieszanych węzłów z etykietami na węzły czysto pojedynczej klasy \cite{Gini}, jednakże jest to dla nas mniej ważna miara.
<<klasyf_RF_plot2, eval=TRUE, echo=FALSE, cache=TRUE, fig.width=6, fig.height=8, fig.cap="Ranking istoności zmiennych">>=
randomForest::varImpPlot(model_rf)
@
Na rysunku powyżej widzimy ranking istotności wszystkich zmiennych, w szczególności zajmiemy się rankingiem po lewej stronie, opisującym potencjalne spadki dokładności przy usuwaniu zmiennych z modelu. Możemy zaobserwować, że najbardziej istotna jest zmienna \texttt{make}, a~najmniej \texttt{aspiration}. Ponadto, widzimy, że ranking ten potwierdza nasze wnioski z rozdziału $1.5$ dotyczące istotności zmienych. Może nie dokładnie odwzorowuje, ale zmienne, które uznaliśmy, że są w grupie najbardziej istotnych, tak samo są i w tej hierarchii. Podobna sytuacja ze zmiennymi najmniej istotnymi.


\par
Poniżej przedstawiamy wartości częstotliwości występowania odpowiednich klas zmiennej \texttt{symboling} po usunięciu z niej klasy $-2$.

<<klasyf_RF_PETLA, eval=TRUE, echo=FALSE, cache=TRUE>>=

data_RF <- data[!(data$symboling==-2),]
data_RF$symboling <- droplevels(data_RF$symboling) #usunięcie z levela factora wartości -2
table(data_RF$symboling)
n <- dim(data_RF)[1]

prop<-0.7

RF.accuracy_120_all_5 <- vector()
RF.accuracy_60_all_5 <- vector()
RF.accuracy_20_all_5 <- vector()
RF.accuracy_1_all_5 <- vector()

time_120_all_5 <- 0
time_60_all_5 <- 0
time_20_all_5 <- 0
time_1_all_5 <- 0

RF.accuracy_120_17_5 <- vector()
RF.accuracy_60_17_5 <- vector()
RF.accuracy_20_17_5 <- vector()
RF.accuracy_1_17_5 <- vector()

time_120_17_5 <- 0
time_60_17_5 <- 0
time_20_17_5 <- 0
time_1_17_5 <- 0

RF.accuracy_120_11_5 <- vector()
RF.accuracy_60_11_5 <- vector()
RF.accuracy_20_11_5 <- vector()
RF.accuracy_1_11_5 <- vector()

time_120_11_5 <- 0
time_60_11_5 <- 0
time_20_11_5 <- 0
time_1_11_5 <- 0

RF.accuracy_120_5_5 <- vector()
RF.accuracy_60_5_5 <- vector()
RF.accuracy_20_5_5 <- vector()
RF.accuracy_1_5_5 <- vector()
prop<-0.7

time_120_5_5 <- 0
time_60_5_5 <- 0
time_20_5_5 <- 0
time_1_5_5 <- 0

for(i in 1:100){
  tic <- Sys.time()
  learning.set.index <- sample(1:n,prop*n)
  testing.set.index <- 1:n
  testing.set.index <- testing.set.index[-learning.set.index]
  learning.set_data <- data_RF[learning.set.index, ]
  testing.set_data <- data_RF[-learning.set.index, ]
  
  train_ctrl <- trainControl(method="cv", # type of resampling in this case Cross-Validated
                             number=5, # number of folds
                             search = "random", # we are performing a "random
  )
  
  model_rf <- randomForest(symboling ~ .,
                           data = learning.set_data,
                           method = "rf", # this will use the randomForest::randomForest function
                           metric = "Accuracy", # which metric should be optimized for 
                           trControl = train_ctrl,
                           # options to be passed to randomForest
                           ntree = 120,
                           keep.forest=TRUE,
                           importance=TRUE) 
  
  probs <- predict(model_rf, testing.set_data, 'prob')
  class <- predict(model_rf, testing.set_data, 'response')
  test.scored <- cbind(testing.set_data, probs, class)
  cm <- conf_mat(test.scored, truth = symboling, class)
  
  test_accuracy <- sum(diag(cm$table))/length(testing.set.index)
  RF.accuracy_120_all_5 <- append(RF.accuracy_120_all_5, test_accuracy)
  
  toc <- Sys.time()
  time_120_all_5 <- time_120_all_5+(toc-tic)
 
  tic <- Sys.time()
  
  train_ctrl <- trainControl(method="cv", # type of resampling in this case Cross-Validated
                             number=5, # number of folds
                             search = "random", # we are performing a "random
  )
  
  model_rf <- randomForest(symboling ~ .,
                           data = learning.set_data,
                           method = "rf", # this will use the randomForest::randomForest function
                           metric = "Accuracy", # which metric should be optimized for 
                           trControl = train_ctrl,
                           # options to be passed to randomForest
                           ntree = 60,
                           keep.forest=TRUE,
                           importance=TRUE) 
  
  probs <- predict(model_rf, testing.set_data, 'prob')
  class <- predict(model_rf, testing.set_data, 'response')
  test.scored <- cbind(testing.set_data, probs, class)
  cm <- conf_mat(test.scored, truth = symboling, class)
  
  test_accuracy <- sum(diag(cm$table))/length(testing.set.index)
  RF.accuracy_60_all_5 <- append(RF.accuracy_60_all_5, test_accuracy)
  
  toc <- Sys.time()
  time_60_all_5 <- time_60_all_5+ (toc-tic)
  
  tic <- Sys.time()
  
  
  train_ctrl <- trainControl(method="cv", # type of resampling in this case Cross-Validated
                             number=5, # number of folds
                             search = "random", # we are performing a "random
  )
  
  model_rf <- randomForest(symboling ~ .,
                           data = learning.set_data,
                           method = "rf", # this will use the randomForest::randomForest function
                           metric = "Accuracy", # which metric should be optimized for 
                           trControl = train_ctrl,
                           # options to be passed to randomForest
                           ntree = 20,
                           keep.forest=TRUE,
                           importance=TRUE) 
  
  probs <- predict(model_rf, testing.set_data, 'prob')
  class <- predict(model_rf, testing.set_data, 'response')
  test.scored <- cbind(testing.set_data, probs, class)
  cm <- conf_mat(test.scored, truth = symboling, class)
  
  test_accuracy <- sum(diag(cm$table))/length(testing.set.index)
  RF.accuracy_20_all_5 <- append(RF.accuracy_20_all_5, test_accuracy)
  
  toc <- Sys.time()
  time_20_all_5 <- time_20_all_5+(toc-tic)
  
  tic <- Sys.time()
  prop<-0.7
  
  
  train_ctrl <- trainControl(method="cv", # type of resampling in this case Cross-Validated
                             number=5, # number of folds
                             search = "random", # we are performing a "random
  )
  
  model_rf <- randomForest(symboling ~ .,
                           data = learning.set_data,
                           method = "rf", # this will use the randomForest::randomForest function
                           metric = "Accuracy", # which metric should be optimized for 
                           trControl = train_ctrl,
                           # options to be passed to randomForest
                           ntree = 1,
                           keep.forest=TRUE,
                           importance=TRUE) 
  
  probs <- predict(model_rf, testing.set_data, 'prob')
  class <- predict(model_rf, testing.set_data, 'response')
  test.scored <- cbind(testing.set_data, probs, class)
  cm <- conf_mat(test.scored, truth = symboling, class)
  
  test_accuracy <- sum(diag(cm$table))/length(testing.set.index)
  RF.accuracy_1_all_5 <- append(RF.accuracy_1_all_5, test_accuracy)
  
  toc <- Sys.time()
  time_1_all_5 <- time_1_all_5+(toc-tic)


  tic <- Sys.time()
  train_ctrl <- trainControl(method="cv", # type of resampling in this case Cross-Validated
                             number=5, # number of folds
                             search = "random", # we are performing a "random
  )
  
  model_rf <- randomForest(symboling ~ make+wheel.base+normalized.losses+height+width+curb.weight+bore+length+num.of.doors+
                             highway.mpg+price+engine.size+city.mpg+body.style+horsepower+stroke+compression.ratio,
                           data = learning.set_data,
                           method = "rf", # this will use the randomForest::randomForest function
                           metric = "Accuracy", # which metric should be optimized for 
                           trControl = train_ctrl,
                           # options to be passed to randomForest
                           ntree = 120,
                           keep.forest=TRUE,
                           importance=TRUE) 
  
  probs <- predict(model_rf, testing.set_data, 'prob')
  class <- predict(model_rf, testing.set_data, 'response')
  test.scored <- cbind(testing.set_data, probs, class)
  cm <- conf_mat(test.scored, truth = symboling, class)
  
  test_accuracy <- sum(diag(cm$table))/length(testing.set.index)
  RF.accuracy_120_17_5 <- append(RF.accuracy_120_17_5, test_accuracy)
  
  toc <- Sys.time()
  time_120_17_5 <- time_120_17_5+(toc-tic)
  
  tic <- Sys.time()
  
  train_ctrl <- trainControl(method="cv", # type of resampling in this case Cross-Validated
                             number=5, # number of folds
                             search = "random", # we are performing a "random
  )
  
  model_rf <- randomForest(symboling ~ make+wheel.base+normalized.losses+height+width+curb.weight+bore+length+num.of.doors+
                             highway.mpg+price+engine.size+city.mpg+body.style+horsepower+stroke+compression.ratio,
                           data = learning.set_data,
                           method = "rf", # this will use the randomForest::randomForest function
                           metric = "Accuracy", # which metric should be optimized for 
                           trControl = train_ctrl,
                           # options to be passed to randomForest
                           ntree = 60,
                           keep.forest=TRUE,
                           importance=TRUE) 
  
  probs <- predict(model_rf, testing.set_data, 'prob')
  class <- predict(model_rf, testing.set_data, 'response')
  test.scored <- cbind(testing.set_data, probs, class)
  cm <- conf_mat(test.scored, truth = symboling, class)
  
  test_accuracy <- sum(diag(cm$table))/length(testing.set.index)
  RF.accuracy_60_17_5 <- append(RF.accuracy_60_17_5, test_accuracy)

  toc <- Sys.time()
  time_60_17_5 <- time_60_17_5+ (toc-tic)
  
  tic <- Sys.time()
  
  
  train_ctrl <- trainControl(method="cv", # type of resampling in this case Cross-Validated
                             number=5, # number of folds
                             search = "random", # we are performing a "random
  )
  
  model_rf <- randomForest(symboling ~ make+wheel.base+normalized.losses+height+width+curb.weight+bore+length+num.of.doors+
                             highway.mpg+price+engine.size+city.mpg+body.style+horsepower+stroke+compression.ratio,
                           data = learning.set_data,
                           method = "rf", # this will use the randomForest::randomForest function
                           metric = "Accuracy", # which metric should be optimized for 
                           trControl = train_ctrl,
                           # options to be passed to randomForest
                           ntree = 20,
                           keep.forest=TRUE,
                           importance=TRUE) 
  
  probs <- predict(model_rf, testing.set_data, 'prob')
  class <- predict(model_rf, testing.set_data, 'response')
  test.scored <- cbind(testing.set_data, probs, class)
  cm <- conf_mat(test.scored, truth = symboling, class)
  
  test_accuracy <- sum(diag(cm$table))/length(testing.set.index)
  RF.accuracy_20_17_5 <- append(RF.accuracy_20_17_5, test_accuracy)
  
  toc <- Sys.time()
  time_20_17_5 <- time_20_17_5+(toc-tic)
  
  tic <- Sys.time()
  prop<-0.7
  
  
  train_ctrl <- trainControl(method="cv", # type of resampling in this case Cross-Validated
                             number=5, # number of folds
                             search = "random", # we are performing a "random
  )
  
  model_rf <- randomForest(symboling ~ make+wheel.base+normalized.losses+height+width+curb.weight+bore+length+num.of.doors+
                             highway.mpg+price+engine.size+city.mpg+body.style+horsepower+stroke+compression.ratio,
                           data = learning.set_data,
                           method = "rf", # this will use the randomForest::randomForest function
                           metric = "Accuracy", # which metric should be optimized for 
                           trControl = train_ctrl,
                           # options to be passed to randomForest
                           ntree = 1,
                           keep.forest=TRUE,
                           importance=TRUE) 
  
  probs <- predict(model_rf, testing.set_data, 'prob')
  class <- predict(model_rf, testing.set_data, 'response')
  test.scored <- cbind(testing.set_data, probs, class)
  cm <- conf_mat(test.scored, truth = symboling, class)
  
  test_accuracy <- sum(diag(cm$table))/length(testing.set.index)
  RF.accuracy_1_17_5 <- append(RF.accuracy_1_17_5, test_accuracy)
  
  toc <- Sys.time()
  time_1_17_5 <- time_1_17_5+(toc-tic)

  tic <- Sys.time()
  train_ctrl <- trainControl(method="cv", # type of resampling in this case Cross-Validated
                             number=5, # number of folds
                             search = "random", # we are performing a "random
  )
  
  model_rf <- randomForest(symboling ~ make+wheel.base+normalized.losses+height+width+curb.weight+bore+length+num.of.doors+
                             highway.mpg+price,
                           data = learning.set_data,
                           method = "rf", # this will use the randomForest::randomForest function
                           metric = "Accuracy", # which metric should be optimized for 
                           trControl = train_ctrl,
                           # options to be passed to randomForest
                           ntree = 120,
                           keep.forest=TRUE,
                           importance=TRUE) 
  
  probs <- predict(model_rf, testing.set_data, 'prob')
  class <- predict(model_rf, testing.set_data, 'response')
  test.scored <- cbind(testing.set_data, probs, class)
  cm <- conf_mat(test.scored, truth = symboling, class)
  
  test_accuracy <- sum(diag(cm$table))/length(testing.set.index)
  RF.accuracy_120_11_5 <- append(RF.accuracy_120_11_5, test_accuracy)
  
  toc <- Sys.time()
  time_120_11_5 <- time_120_11_5+(toc-tic)
  
  tic <- Sys.time()
  
  train_ctrl <- trainControl(method="cv", # type of resampling in this case Cross-Validated
                             number=5, # number of folds
                             search = "random", # we are performing a "random
  )
  
  model_rf <- randomForest(symboling ~ make+wheel.base+normalized.losses+height+width+curb.weight+bore+length+num.of.doors+
                             highway.mpg+price,
                           data = learning.set_data,
                           method = "rf", # this will use the randomForest::randomForest function
                           metric = "Accuracy", # which metric should be optimized for 
                           trControl = train_ctrl,
                           # options to be passed to randomForest
                           ntree = 60,
                           keep.forest=TRUE,
                           importance=TRUE) 
  
  probs <- predict(model_rf, testing.set_data, 'prob')
  class <- predict(model_rf, testing.set_data, 'response')
  test.scored <- cbind(testing.set_data, probs, class)
  cm <- conf_mat(test.scored, truth = symboling, class)
  
  test_accuracy <- sum(diag(cm$table))/length(testing.set.index)
  RF.accuracy_60_11_5 <- append(RF.accuracy_60_11_5, test_accuracy)
  
  toc <- Sys.time()
  time_60_11_5 <- time_60_11_5+ (toc-tic)
  
  tic <- Sys.time()
  
  
  train_ctrl <- trainControl(method="cv", # type of resampling in this case Cross-Validated
                             number=5, # number of folds
                             search = "random", # we are performing a "random
  )
  
  model_rf <- randomForest(symboling ~ make+wheel.base+normalized.losses+height+width+curb.weight+bore+length+num.of.doors+
                             highway.mpg+price,
                           data = learning.set_data,
                           method = "rf", # this will use the randomForest::randomForest function
                           metric = "Accuracy", # which metric should be optimized for 
                           trControl = train_ctrl,
                           # options to be passed to randomForest
                           ntree = 20,
                           keep.forest=TRUE,
                           importance=TRUE) 
  
  probs <- predict(model_rf, testing.set_data, 'prob')
  class <- predict(model_rf, testing.set_data, 'response')
  test.scored <- cbind(testing.set_data, probs, class)
  cm <- conf_mat(test.scored, truth = symboling, class)
  
  test_accuracy <- sum(diag(cm$table))/length(testing.set.index)
  RF.accuracy_20_11_5 <- append(RF.accuracy_20_11_5, test_accuracy)
  
  toc <- Sys.time()
  time_20_11_5 <- time_20_11_5+(toc-tic)
  
  
  tic <- Sys.time()
  prop<-0.7
  
  
  train_ctrl <- trainControl(method="cv", # type of resampling in this case Cross-Validated
                             number=5, # number of folds
                             search = "random", # we are performing a "random
  )
  
  model_rf <- randomForest(symboling ~ make+wheel.base+normalized.losses+height+width+curb.weight+bore+length+num.of.doors+
                             highway.mpg+price,
                           data = learning.set_data,
                           method = "rf", # this will use the randomForest::randomForest function
                           metric = "Accuracy", # which metric should be optimized for 
                           trControl = train_ctrl,
                           # options to be passed to randomForest
                           ntree = 1,
                           keep.forest=TRUE,
                           importance=TRUE) 
  
  probs <- predict(model_rf, testing.set_data, 'prob')
  class <- predict(model_rf, testing.set_data, 'response')
  test.scored <- cbind(testing.set_data, probs, class)
  cm <- conf_mat(test.scored, truth = symboling, class)
  
  test_accuracy <- sum(diag(cm$table))/length(testing.set.index)
  RF.accuracy_1_11_5 <- append(RF.accuracy_1_11_5, test_accuracy)
  
  toc <- Sys.time()
  time_1_11_5 <- time_1_11_5+(toc-tic)
  

  tic <- Sys.time()
  train_ctrl <- trainControl(method="cv", # type of resampling in this case Cross-Validated
                             number=5, # number of folds
                             search = "random", # we are performing a "random
  )
  
  model_rf <- randomForest(symboling ~ make+wheel.base+normalized.losses+height+width,
                           data = learning.set_data,
                           method = "rf", # this will use the randomForest::randomForest function
                           metric = "Accuracy", # which metric should be optimized for 
                           trControl = train_ctrl,
                           # options to be passed to randomForest
                           ntree = 120,
                           keep.forest=TRUE,
                           importance=TRUE) 
  
  probs <- predict(model_rf, testing.set_data, 'prob')
  class <- predict(model_rf, testing.set_data, 'response')
  test.scored <- cbind(testing.set_data, probs, class)
  cm <- conf_mat(test.scored, truth = symboling, class)
  
  test_accuracy <- sum(diag(cm$table))/length(testing.set.index)
  RF.accuracy_120_5_5 <- append(RF.accuracy_120_5_5, test_accuracy)
  
  toc <- Sys.time()
  time_120_5_5 <- time_120_5_5+(toc-tic)
  
  
  tic <- Sys.time()
  
  train_ctrl <- trainControl(method="cv", # type of resampling in this case Cross-Validated
                             number=5, # number of folds
                             search = "random", # we are performing a "random
  )
  
  model_rf <- randomForest(symboling ~ make+wheel.base+normalized.losses+height+width,
                           data = learning.set_data,
                           method = "rf", # this will use the randomForest::randomForest function
                           metric = "Accuracy", # which metric should be optimized for 
                           trControl = train_ctrl,
                           # options to be passed to randomForest
                           ntree = 60,
                           keep.forest=TRUE,
                           importance=TRUE) 
  
  probs <- predict(model_rf, testing.set_data, 'prob')
  class <- predict(model_rf, testing.set_data, 'response')
  test.scored <- cbind(testing.set_data, probs, class)
  cm <- conf_mat(test.scored, truth = symboling, class)
  
  test_accuracy <- sum(diag(cm$table))/length(testing.set.index)
  RF.accuracy_60_5_5 <- append(RF.accuracy_60_5_5, test_accuracy)
  
  toc <- Sys.time()
  time_60_5_5 <- time_60_5_5+ (toc-tic)
  

  tic <- Sys.time()
  
  
  train_ctrl <- trainControl(method="cv", # type of resampling in this case Cross-Validated
                             number=5, # number of folds
                             search = "random", # we are performing a "random
  )
  
  model_rf <- randomForest(symboling ~ make+wheel.base+normalized.losses+height+width,
                           data = learning.set_data,
                           method = "rf", # this will use the randomForest::randomForest function
                           metric = "Accuracy", # which metric should be optimized for 
                           trControl = train_ctrl,
                           # options to be passed to randomForest
                           ntree = 20,
                           keep.forest=TRUE,
                           importance=TRUE) 
  
  probs <- predict(model_rf, testing.set_data, 'prob')
  class <- predict(model_rf, testing.set_data, 'response')
  test.scored <- cbind(testing.set_data, probs, class)
  cm <- conf_mat(test.scored, truth = symboling, class)
  
  test_accuracy <- sum(diag(cm$table))/length(testing.set.index)
  RF.accuracy_20_5_5 <- append(RF.accuracy_20_5_5, test_accuracy)
  
  toc <- Sys.time()
  time_20_5_5 <- time_20_5_5+(toc-tic)
  
  tic <- Sys.time()
  prop<-0.7
  
  
  train_ctrl <- trainControl(method="cv", # type of resampling in this case Cross-Validated
                             number=5, # number of folds
                             search = "random", # we are performing a "random
  )
  
  model_rf <- randomForest(symboling ~ make+wheel.base+normalized.losses+height+width,
                           data = learning.set_data,
                           method = "rf", # this will use the randomForest::randomForest function
                           metric = "Accuracy", # which metric should be optimized for 
                           trControl = train_ctrl,
                           # options to be passed to randomForest
                           ntree = 1,
                           keep.forest=TRUE,
                           importance=TRUE) 
  
  probs <- predict(model_rf, testing.set_data, 'prob')
  class <- predict(model_rf, testing.set_data, 'response')
  test.scored <- cbind(testing.set_data, probs, class)
  cm <- conf_mat(test.scored, truth = symboling, class)
  
  test_accuracy <- sum(diag(cm$table))/length(testing.set.index)
  RF.accuracy_1_5_5 <- append(RF.accuracy_1_5_5, test_accuracy)
  
  toc <- Sys.time()
  time_1_5_5 <- time_1_5_5+(toc-tic)
}

df_RF_trees <- cbind.data.frame( rep("23",400),c(rep("ntrees=1",100), rep("ntrees=20",100), rep("ntrees=60",100), rep("ntrees=120",100)),
                                 c(RF.accuracy_1_all_5, RF.accuracy_20_all_5, RF.accuracy_60_all_5, RF.accuracy_120_all_5))
colnames(df_RF_trees) <- c("Liczba zmiennych","ntrees", "Dokladnosc")

df_RF_trees_17 <- cbind.data.frame( rep("17",400), c(rep("ntrees=1",100), rep("ntrees=20",100), rep("ntrees=60",100), rep("ntrees=120",100)),
                                    c(RF.accuracy_1_17_5, RF.accuracy_20_17_5, RF.accuracy_60_17_5, RF.accuracy_120_17_5))
colnames(df_RF_trees_17) <- c("Liczba zmiennych","ntrees", "Dokladnosc" )

df_RF_trees_11 <- cbind.data.frame( rep("11",400), c(rep("ntrees=1",100), rep("ntrees=20",100), rep("ntrees=60",100), rep("ntrees=120",100)),
                                    c(RF.accuracy_1_11_5, RF.accuracy_20_11_5, RF.accuracy_60_11_5, RF.accuracy_120_11_5))
colnames(df_RF_trees_11) <- c("Liczba zmiennych","ntrees", "Dokladnosc" )

df_RF_trees_5 <- cbind.data.frame( rep("5",400), c(rep("ntrees=1",100), rep("ntrees=20",100), rep("ntrees=60",100), rep("ntrees=120",100)),
                                   c(RF.accuracy_1_5_5, RF.accuracy_20_5_5, RF.accuracy_60_5_5, RF.accuracy_120_5_5))
colnames(df_RF_trees_5) <- c("Liczba zmiennych","ntrees", "Dokladnosc" )


df_RF<-rbind(df_RF_trees, df_RF_trees_17, df_RF_trees_11, df_RF_trees_5)

df_RF$ntrees <- factor(df_RF$ntrees , levels=c("ntrees=1", "ntrees=20", "ntrees=60", "ntrees=120"))
df_RF$`Liczba zmiennych` <- factor(df_RF$`Liczba zmiennych` , levels=c("5", "11", "17", "23"))

df_RF_times <- cbind.data.frame( as.numeric(c(time_120_all_5, time_60_all_5, time_20_all_5, time_1_all_5,
                                              time_120_17_5, time_60_17_5, time_20_17_5, time_1_17_5,
                                              time_120_11_5, time_60_11_5, time_20_11_5, time_1_11_5,
                                              time_120_5_5, time_60_5_5, time_20_5_5, time_1_5_5)),
                                 c(rep("23", 4), rep("17", 4), rep("11", 4), rep("5", 4)),
                                 rep(c("ntrees=120", "ntrees=60", "ntrees=20", "ntrees=1"), 4))

colnames(df_RF_times) <- c("Czas w sekundach", "Liczba zmiennych", "ntrees")
df_RF_times$ntrees <- factor(df_RF_times$ntrees , levels=c("ntrees=1", "ntrees=20", "ntrees=60", "ntrees=120"))
df_RF_times$`Liczba zmiennych` <- factor(df_RF_times$`Liczba zmiennych` , levels=c("5", "11", "17", "23"))
@

<<klasyf_RF_plot_MEANS,eval=TRUE, echo=FALSE, cache=TRUE,>>=
df_RF_means <- cbind.data.frame(  c(mean(RF.accuracy_120_all_5), mean(RF.accuracy_60_all_5), mean(RF.accuracy_20_all_5), mean(RF.accuracy_1_all_5), mean(RF.accuracy_120_17_5), mean(RF.accuracy_60_17_5), mean(RF.accuracy_20_17_5), mean(RF.accuracy_1_17_5),                                              mean(RF.accuracy_120_11_5), mean(RF.accuracy_60_11_5), mean(RF.accuracy_20_11_5), mean(RF.accuracy_1_11_5), mean(RF.accuracy_120_5_5), mean(RF.accuracy_60_5_5), mean(RF.accuracy_20_5_5), mean(RF.accuracy_1_5_5)),
                               c(rep("23", 4), rep("17", 4), rep("11", 4), rep("5", 4)),
                              rep(c("ntrees=120", "ntrees=60", "ntrees=20", "ntrees=1"), 4))

colnames(df_RF_means) <- c("Dokladnosc", "Liczba zmiennych", "ntrees")
df_RF_means$ntrees <- factor(df_RF_means$ntrees , levels=c("ntrees=1", "ntrees=20", "ntrees=60", "ntrees=120"))
df_RF_means$`Liczba zmiennych` <- factor(df_RF_means$`Liczba zmiennych` , levels=c("5", "11", "17", "23"))
@


Poniżej na rysunku \ref{fig:klasyf_RF_plot_ACCURACY} zostały umieszczone boxploty dla dokładności metody lasów losowych pogrupowane ze wzlędu na liczbę użytych drzew w modelu oraz liczbę zmiennych. Różnobarwne kropki na środku każdej z wartości parametru $ntree$ odpowiadają odpowiednim wartościm średnim dla różnych liczb zmiennych. 

<<klasyf_RF_plot_ACCURACY, eval=TRUE, echo=FALSE, cache=TRUE,fig.width=7, fig.height=4, fig.cap="Porównanie dokładności metody lasów losowych dla różnej liczby drzewek i różnych podzbiorów zmiennych",warning=FALSE>>=
ggplot() + 
  geom_boxplot(data = df_RF,
               aes(x = ntrees, y = `Dokladnosc`, 
                   group = interaction(ntrees, `Liczba zmiennych`), 
                   fill = `Liczba zmiennych`))+
  geom_point(data = df_RF_means,
               aes(x = ntrees, y = `Dokladnosc`, 
                   group = interaction(ntrees, `Liczba zmiennych`), 
                   fill = `Liczba zmiennych`, color=`Liczba zmiennych`), colour="black",pch=21, size=1.8)

@
Jak możemy zaobserwować powyżej, jedynie dla wartości $ntrees=1$, czyli dla pojedynczego drzewa, dokładność jest znacząco gorsza, ale i tu plasuje się na poziomie między $0.6$, a $0.7$ co sprawia, że nawet ta wersja wdrożenia metody daje lepsze rezultaty niż niektóre metody (np. $KNN$ czy $LDA$, którą zaraz omówię). Dla pozostałych wartości $ntree$ wszystkie wartości średnie dokładności oscylują koło $0.8$, na oko w przedziale $(0.77, 0.83)$. Jeśli chodzi o wartości średnie dla różnych podzbiorów zmiennych, to możemy stwierdzić, że dla każdej wartości $ntrees$ najgorzej wypada metoda uwzględniająca wszystkie zmienne. Dla $ntrees=1$ zdecydowanie najlepiej działa metoda uwzględniająca najmniej, czyli $5$ zmiennych, dla $ntrees=20$, $ntrees=60$ i $ntrees=120$ podzbiory biorące pod uwagę $5$, $11$ i $17$ zmiennych zwracają bardzo zbliżone rezultaty. Jeśli chodzi o $IQR$, to możemy stwierdzić, że są one większe dla podzbiorów uwzględniających $17$ i $23$ zmienne, niż dla podzbiorów z $5$ i $11$ zmiennymi, ale różnice nie są szczególnie znaczące.

Poniżej na rysunku \ref{fig:klasyf_RF_plot_TIMES} przedstawione zostały nieuśrednione czasy obliczeniowe dla wszystkich badanych liczb drzewek oraz podzbiorów cech. Pamiętajmy, że w symulacji obliczenia powtarzaliśmy $100$ razy.

<<klasyf_RF_plot_TIMES, eval=TRUE, echo=FALSE, cache=TRUE, fig.width=7, fig.height=4, fig.cap="Porównanie czasów obliczeń lasów losowych dla różnej liczby drzewek i różnych podzbiorów zmiennych dla 100 powtórzen w symulacji",warning=FALSE>>=
ggplot() + 
  geom_line(data = df_RF_times,
            aes(x = ntrees, y = `Czas w sekundach`, 
                group =  `Liczba zmiennych`, 
                colour=`Liczba zmiennych`), size=1)+
  geom_point(data = df_RF_times,
             aes(x = ntrees, y = `Czas w sekundach`, 
                 group =  `Liczba zmiennych`, 
                 colour=`Liczba zmiennych`), size=1.5, color='black')
@

Na wykresie powyżej widzimy, że wszystkie czasy obliczeniowe zwiększają się wraz z dodawaniem kolejnych drzewek, co jest jak najbardziej logicznym rezultatem. Dodatkowo - co ciekawe - obserwujemy, że im zmiennych, tym więcej czasu algorytm potrzebował do obliczeń, co na pierwszy rzut oka wydaje się nieoczywiste.




\subsection{LDA}

\par
W tym podrozdziale wykorzystana zostanie liniowa analiza dyskryminacyjna. Z racji charakterystyki tego klasyfikatora, do jego konsturkcji posłużymy się tylko i wyłącznie zmiennymi ilościowymi. Próbowałem przetransformować zmienne jakościowe/ich pewne podzbiory na zmienne numeryczne (one hot encoding), jednak tylko pogarszało to otrzymane rezultaty. Prawdopodobnie przez fakt, zwiększenia $p$ czyli wymiaru danych.

\par
Do tworzenia modeli $LDA$ będziemy posługiwać się funkcją \texttt{lda} z pakietu \textbf{MASS}. Sprawdzimy modele dla:
\begin{itemize}
\item Wszystkich zmiennych numerycznych
\item $8$ zmiennych: \texttt{normalized.losses}, \texttt{height}, \texttt{length}, \texttt{wheel.base}, \texttt{curb.weight}, \texttt{bore}, \texttt{city.mpg}, \texttt{highway.mpg}
\item $4$ zmiennych: \texttt{normalized.losses}, \texttt{height}, \texttt{length}, \texttt{wheel.base}
\end{itemize}
Próbki testowe będą standardowo w naszych badaniach miały $0.7$ wielkości zbioru danych. Badaną metryką będzie dokładność, a nasze obliczenia wykonamy $100$-krotnie, a następnie wyniki uśrednimy.

<<klasyf_LDA_sym, eval=TRUE, echo=FALSE, cache=TRUE, warning=FALSE>>=
LDA.accuracy_all <- vector()
LDA.accuracy8 <- vector()
LDA.accuracy4 <- vector()

for (i in 1:100){

n <- dim(data_num)[1]
prop <- 0.7

data_num <- data[c("symboling", int_kol, num_kol)]
learning.indx <- sample(1:n,prop*n)
learning.set <- data_num[learning.indx,]
test.set <- data_num[-learning.indx,]

# konstrukcja reguly klasyfikacyjnej dla  wszystkich (czyli 4) zmiennych
data_num.lda_all  <- lda(symboling~., data=data_num, subset=learning.indx)
# konstrukcja reguly klasyfikacyjnej dla 8 (wybranych) zmiennych
data_num.lda8  <- lda(symboling~normalized.losses + height + length + wheel.base + curb.weight + bore +city.mpg +
                        highway.mpg, data_num, subset=learning.indx)
#i dla 4
data_num.lda4  <- lda(symboling~normalized.losses + height + length + wheel.base, data_num, subset=learning.indx)
# prognozy dla zbioru testowego
prognozy.lda_all  <-  predict(data_num.lda_all, test.set)
prognozy.lda8  <-  predict(data_num.lda8, test.set)
prognozy.lda4  <-  predict(data_num.lda4, test.set)
# prawdopodobienstwo a posteriori
prognozy.lda_all.prob <- prognozy.lda_all$posterior
prognozy.lda8.prob <- prognozy.lda8$posterior
prognozy.lda4.prob <- prognozy.lda4$posterior
# prognozowane etykietki
etykietki.lda_all <- prognozy.lda_all$class
etykietki.lda8 <- prognozy.lda8$class
etykietki.lda4 <- prognozy.lda4$class

# ocena dokładności klasyfikacji: macierz kontyngencji, błąd klasyfikacji
rzeczywiste <- data_num$symboling[-learning.indx] # rzeczywiste etykietki dla obiektów ze zbioru testowego
(conf.mat.lda_all <- table(etykietki.lda_all,rzeczywiste)) # macierz kontyngencji (Confusion matrix)
(conf.mat.lda8 <- table(etykietki.lda8,rzeczywiste)) # macierz kontyngencji (Confusion matrix)
(conf.mat.lda4 <- table(etykietki.lda4,rzeczywiste)) # macierz kontyngencji (Confusion matrix)

# błąd klasyfikacji na zbiorze testowym
n.test <- dim(test.set)[1]   #liczba obiektow w zbiorze testowym
(blad.lda_all <- (n.test-sum(diag(conf.mat.lda_all))) /n.test)
(blad.lda8 <- (n.test-sum(diag(conf.mat.lda8))) /n.test)
(blad.lda4 <- (n.test-sum(diag(conf.mat.lda4))) /n.test)

LDA.accuracy_all <- append(LDA.accuracy_all, 1-blad.lda_all)
LDA.accuracy8 <- append(LDA.accuracy8, 1-blad.lda8)
LDA.accuracy4 <- append(LDA.accuracy4, 1-blad.lda4)

#print(i)
}
@

Na rysunku \ref{fig:klasyf_LDA_wykres} przedstawione zostały boxploty dla poszczególnych podzbiorów naszych danych. Czerwone punkty odpowiadają odpowiednim wartościom średnim.

<<klasyf_LDA_wykres, eval=TRUE, echo=FALSE, cache=TRUE, fig.cap="Porównanie dokładności klasyfikacji LDA">>=
ggplot() + 
  geom_boxplot(aes(x="Wszystkie zmienne numeryczne", y=LDA.accuracy_all)) + 
  geom_boxplot(aes(x="8 zmiennych", y=LDA.accuracy8)) + 
  geom_boxplot(aes(x= "4 zmienne", y=LDA.accuracy4)) +
  geom_point(aes(x="Wszystkie zmienne numeryczne", y=mean(LDA.accuracy_all) ), size=2.5, color="red"  )+
  geom_point(aes(x="8 zmiennych", y=mean(LDA.accuracy8) ), size=2.5, color="red"  )+
  geom_point(aes(x="4 zmienne", y=mean(LDA.accuracy4) ), size=2.5, color="red"  )+  
  ylab("Dokładność") + 
  xlab("")
@

Na podstawie tych boxplotów, możemy stwierdzić, że przy ocenie dokładności dla metody $LDA$ najlepiej wypadł najmniejszy podzbiór obejmujący tylko 4 zmienne, a najgorzej największy, obejmujący wszystkie zmienne ilościowe. Oprócz tego, widzimy, że rozrzuty dla poszczególnych podzbiorów są porównywalnej wielkości.

\subsection{QDA}


Jeżeli chodzi o metodę QDA, to po pierwszej nieudanej próbie i błędzie dotyczącym jakiejś za małej grupy, usunąłem z danych te wiersze, w których zmienna \texttt{symboling} przyjmuje wartość $-2$ (były $3$ takie przypadki). Mimo usunięcia tych wierszy oraz wartości $-2$ z poziomów zmiennej jakościowej i tego, że po tej modyfikacji zmienna \texttt{symboling} przyjmowała takie wartości z odpowiednią częstością:
<<explor_qda, eval=TRUE, echo=FALSE>>=
data_num_qda <- data_num[!(data_num$symboling==-2),]
data_num_qda$symboling <- droplevels(data_num_qda$symboling) #usunięcie z levela factora wartości -2
table(data_num_qda$symboling)
@
funkcja \texttt{qda} z pakietu \texttt{MASS} dalej zwracała błąd "some group is too small for 'qda' ".


\subsection{Wielomianowa regresja logistyczna}

uwaga: ze względu na wyskakujące ostrzeżenia i wartości odstające, metoda klasyfikacji na bazie wielomianowej regresji logistycznej również wykonana jest na danych z usuniętymi wierszami w których zmienna \texttt{symboling} przymuje wartość $-2$. 
\par Do tworzenia takich modeli użyjemy funkcji \texttt{multinom} z pakietu \textbf{nnet}. Zbudujemy modele dla następujących podbziorów:
\begin{itemize}
\item Wszystkich zmiennych
\item Tylko zmiennych ilościowych
\item $12$ zmiennych: \texttt{make}, \texttt{wheel.base}, \texttt{num.of.doors}, \texttt{normalized.losses}, \texttt{height}, \texttt{length}, \texttt{bore}, \texttt{curb.weight}, \texttt{horsepower}, \texttt{city.mpg}, \texttt{highway.mpg}, \texttt{price}
\item $6$ zmiennych: \texttt{make}, \texttt{wheel.base}, \texttt{num.of.doors}, \texttt{normalized.losses}, \texttt{height}, \texttt{length}
\end{itemize}
Zauważmy, że wybrane podzbiory z $12$ i $6$ zmiennymi są mieszanką zmiennych ilościowych i~jakościowych, oczywiście wybraną mniej więcej wg. hierarchii istotnośmi zmiennych.

<<klasyf_LR_sym, eval=TRUE, echo=FALSE, cache=TRUE>>=
data_all_no2 <- data[!(data$symboling==-2),]
data_all_no2$symboling <- droplevels(data_all_no2$symboling) #usunięcie z levela factora wartości -2
#----------------------------------------------------------------------------------------------
data_num_qda$symboling <- relevel(data_num_qda$symboling, ref=1)

LR.accuracy_allvar <- vector()
LR.accuracy_numericvar <- vector()
LR.accuracy_12var <- vector()
LR.accuracy_6var <- vector()

for (i in 1:100){
n <- dim(data_all_no2)[1]
prop <- 0.7
learning.indx <- sample(1:n,prop*n)
#--------------------------------tylko numeryczne wszystkie -----------------------------------

learning.set <- data_num_qda[learning.indx,]
test.set <- data_num_qda[-learning.indx,]
# dopasowujemy model (ang. multinomial logistic regression)  
model <- multinom(symboling~., data=learning.set, trace=FALSE)
# prognozowanie
pred.lebels <- predict(model, test.set)

# macierz pomyłek
table(pred.lebels, data_num_qda$symboling[-learning.indx])

accuracy <- sum(diag(table(pred.lebels, data_num_qda$symboling[-learning.indx]))) / (n-length(learning.indx))

LR.accuracy_numericvar <- append(LR.accuracy_numericvar, accuracy)

#------- próba ze wszystkimi danym, nienurecznymi też
learning.set <- data_all_no2[learning.indx,]
test.set <- data_all_no2[-learning.indx,]

data_all_no2$symboling <- relevel(data_all_no2$symboling, ref=1)
# dopasowujemy model (ang. multinomial logistic regression)  
model <- multinom(symboling~., data=learning.set, trace=FALSE)

# podstawowe informacje o modelu
#summary(model)

# prognozowanie
pred.lebels <- predict(model, test.set)

# macierz pomyłek
table(pred.lebels, data_all_no2$symboling[-learning.indx])

accuracy <- sum(diag(table(pred.lebels, data_all_no2$symboling[-learning.indx]))) / (n-length(learning.indx))
LR.accuracy_allvar <- append(LR.accuracy_allvar, accuracy)

#--------------------próba z 12 zmiennymi------------------------------
# dopasowujemy model (ang. multinomial logistic regression)  
model <- multinom(symboling~ make + wheel.base + num.of.doors +normalized.losses + height + length +bore+
                    curb.weight + horsepower +city.mpg + highway.mpg + price, data=learning.set, trace=FALSE)
# prognozowanie
pred.lebels <- predict(model, test.set)
# macierz pomyłek
table(pred.lebels, data_all_no2$symboling[-learning.indx])

accuracy <- sum(diag(table(pred.lebels, data_all_no2$symboling[-learning.indx]))) / (n-length(learning.indx))
LR.accuracy_12var <- append(LR.accuracy_12var, accuracy)

#--------------------próba z 6 zmiennymi------------------------------
# dopasowujemy model (ang. multinomial logistic regression)  
model <- multinom(symboling~ make + wheel.base + num.of.doors +normalized.losses + height + length, data=learning.set, 
                  trace=FALSE)
# prognozowanie
pred.lebels <- predict(model, test.set)
# macierz pomyłek
table(pred.lebels, data_all_no2$symboling[-learning.indx])

accuracy <- sum(diag(table(pred.lebels, data_all_no2$symboling[-learning.indx]))) / (n-length(learning.indx))
LR.accuracy_6var <- append(LR.accuracy_6var, accuracy)
}

@
\par
Poniżej, na rysunk \ref{fig:klasyf_LR_wykres} za pomocą boxplotów zostały przedstawione wyniki naszej symulacji z użyciem wielomianowej regresji logistycznej, a odpowiednie czerwone punkty są równe wartościom średnim.
<<klasyf_LR_wykres, eval=TRUE, echo=FALSE, cache=TRUE, fig.cap="Dokładność klasyfikacji regresji logistycznej">>=
ggplot() + 
  geom_boxplot(aes(x="Wszystkie", y=LR.accuracy_allvar)) + 
  geom_boxplot(aes(x= "Ilościowe", y=LR.accuracy_numericvar)) +
  geom_boxplot(aes(x="12 zmiennych", y=LR.accuracy_12var)) + 
  geom_boxplot(aes(x= "6 zmiennych", y=LR.accuracy_6var)) +
  geom_point(aes(x="Wszystkie", y=mean(LR.accuracy_allvar) ), size=2.5, color="red"  )+
  geom_point(aes(x="Ilościowe", y=mean(LR.accuracy_numericvar) ), size=2.5, color="red"  )+
  geom_point(aes(x="12 zmiennych", y=mean(LR.accuracy_12var) ), size=2.5, color="red"  )+
  geom_point(aes(x="6 zmiennych", y=mean(LR.accuracy_6var) ), size=2.5, color="red"  )+
  ylab("Dokładność") + 
  xlab("")
@
Widzimy na rysunku powyżej, że zdecydowanie najgorzej poradził sobie model w ogólnie nie uwzględniający żadnych zmiennych jakościowych. Możemy przypuszczać, że to przez pominięcie bardzo istotnych zmiennych \texttt{make}, \texttt{num.of.doors}. Poza tym stwierdzamy, że dla "mieszanek" zmiennych jakościowych i ilościowych uwzględnionych w modelu, najlepiej poradził sobie model zawierający najmniej czyli $6$ zmiennych, a najgorzej model uwzględniający wszystkie zmienne. Dodatkowo zauważmy, że dla podzbiorów $6$ i $12$ zmiennych rozrzut jest mniejszy niż w~pozostałych dwóch przypadkach.

\subsection{KDA}

Następną metodą, której użyjemy do klasyfikacji będzie jądrowa analiza dyskryminacyjna czyli $KDA$. Do tworzenia takich modeli użyjemy funkcji \texttt{kda} z pakietu \textbf{ks}. Warto przypomnieć, że metody $KDA$ nie używa się w praktyce dla $p>6$, dlatego my też mocno okroimy nasze dane do $p=3$ oraz że będziemy używać tylko zmiennych ilościowych. Wybraliśmy $3$ następujące podzbiory zmiennych:

\begin{itemize}
\item  \texttt{wheel.base}, \texttt{height}, \texttt{length} ($WHL$)
\item  \texttt{wheel.base}, \texttt{height}, \texttt{normalized.losses} ($WHL$)
\item  \texttt{normalized.losses}, \texttt{curb.weight}, \texttt{bore} ($NCB$)
\end{itemize}

\par
Tak jak wcześniej, będziemy badać dokładność, a losowanie zbioru treningowe oraz obliczenia przeprowadzimy $100$ razy. 
\par Na rysunku \ref{fig:klasyf_KDA_wykres} przedstawione zostały boxploty dla naszych różnych wyborów cech. Czerwone kropki odpowiadają wartościom średnim.

<<klasyf_KDA_sym, eval=TRUE, echo=FALSE, cache=TRUE>>=

data_num_kda <- data_num[!(data_num$symboling==-2),]
data_num_kda$symboling <- droplevels(data_num_kda$symboling) #usunięcie z levela factora wartości -2

n <- dim(data_num_kda)[1]
prop <- 0.7

KDA.accuracy_whn <- vector()
KDA.accuracy_whl <- vector()
KDA.accuracy_ncb <- vector()

for (i in 1:100){

learning.indx <- sort(sample(1:n,prop*n))
learning.set <- data_num_kda[learning.indx,]
test.set <- data_num_kda[-learning.indx,]
n.test <- dim(test.set)[1]

klasy <- learning.set$symboling
kda.model3 <- kda(x=as.matrix(learning.set[,c("wheel.base","height","length")]), x.group=klasy)
# wykres
#plot(kda.model3)
# prognozowane etykietki
pred.labels3 <- predict(kda.model3, x=test.set[,c("wheel.base","height","length")])

# macierz pomyłek
(conf.mat.kda3 <- table(test.set$symboling, pred.labels3))
#conf.mat.kda3
(blad.kda3 <- (n.test-sum(diag(conf.mat.kda3)))/n.test)
accuracy.kda3 <- 1-blad.kda3
KDA.accuracy_whl <- append(KDA.accuracy_whl, accuracy.kda3)
#--------------------------------------------------------------------------------------------------------
kda.model3 <- kda(x=as.matrix(learning.set[,c("wheel.base","height","normalized.losses")]), x.group=klasy)
# wykres
#plot(kda.model3)
# prognozowane etykietki
pred.labels3 <- predict(kda.model3, x=test.set[,c("wheel.base","height","normalized.losses")])

# macierz pomyłek
(conf.mat.kda3 <- table(test.set$symboling, pred.labels3))
#conf.mat.kda3
(blad.kda3 <- (n.test-sum(diag(conf.mat.kda3)))/n.test)
accuracy.kda3 <- 1-blad.kda3
KDA.accuracy_whn <- append(KDA.accuracy_whn, accuracy.kda3)
#---------------------------------------------------------------------------------------------------------
kda.model3 <- kda(x=as.matrix(learning.set[,c("normalized.losses","curb.weight","bore")]), x.group=klasy)
# wykres
#plot(kda.model3)
# prognozowane etykietki
pred.labels3 <- predict(kda.model3, x=test.set[,c("normalized.losses","curb.weight","bore")])

# macierz pomyłek
(conf.mat.kda3 <- table(test.set$symboling, pred.labels3))
#conf.mat.kda3
(blad.kda3 <- (n.test-sum(diag(conf.mat.kda3)))/n.test)
accuracy.kda3 <- 1-blad.kda3
KDA.accuracy_ncb <- append(KDA.accuracy_ncb, accuracy.kda3)

}

@

<<klasyf_KDA_wykres, eval=TRUE, echo=FALSE, cache=TRUE, fig.cap="Porównanie dokładności klasyfikacji na podstawie KDA">>=

ggplot() + 
  geom_boxplot(aes(x= "WHN", y=KDA.accuracy_whn)) +
  geom_boxplot(aes(x="NCB", y=KDA.accuracy_ncb)) +
  geom_boxplot(aes(x="WHL", y=KDA.accuracy_whl)) +
  geom_point(aes(x="WHN", y=mean(KDA.accuracy_whn) ), size=2.5, color="red"  )+
  geom_point(aes(x="NCB", y=mean(KDA.accuracy_ncb) ), size=2.5, color="red"  )+
  geom_point(aes(x="WHL", y=mean(KDA.accuracy_whl) ), size=2.5, color="red"  )+
  ylab("Dokładność") + 
  xlab("")
@

Na rysunku powyżej widzimy, że najgorzej poradził sobie podzbiór ($NCB$), i jeśli chodzi o średnią dokładność, i jeśli chodzi o stabilność, co jest dość logiczne, ponieważ wybrane tam zmienne w naszej analizie nie były w czołówce najbardziej istotnych. Dwa pozostałe zbiory poradziły sobie dużo lepiej, w szczególności ($WHL$), który ma najlepszą dokładność oraz najmniejszy rozrzut otrzymanych wyników.


\subsection{Naive Bayes}

Ostatnią metodą zaimplementowaną dla naszych danych będzie naiwny klasyfikator bayesowski, który zakłada, 
że nasze zmienne objaśniające są niezależne. Oczywiście jest to faktycznie bardzo "naiwne" założenie, w rozdziale $1.5.5$ pokazaliśmy, że nasze zmienne są zależne. W tym przypadku również użyjemy danych z pominięciem \texttt{symboling} = $-2$.
Uwzględnimy tylko zmienne numeryczne.

\par

Do tworzenia modeli naiwnego klasyfikatora bayesowskiego będziemy posługiwać się funkcją \texttt{NaiveBayes} z pakietu \textbf{klaR}. Sprawdzimy modele dla:
\begin{itemize}
\item Wszystkich zmiennych numerycznych
\item $8$ zmiennych: \texttt{normalized.losses}, \texttt{height}, \texttt{length}, \texttt{wheel.base}, \texttt{curb.weight}, \texttt{bore}, \texttt{city.mpg}, \texttt{highway.mpg}
\item $4$ zmiennych: \texttt{normalized.losses}, \texttt{height}, \texttt{length}, \texttt{wheel.base}
\end{itemize}

Tak jak poprzednio, będziemy mierzyć dokładność, a symulacje przeprowadzimy $100$-krotnie dla każdego podzbioru.
<<klasyf_NB_sym, eval=TRUE, echo=FALSE, cache=TRUE, warning=FALSE>>=
NB.accuracy_allvar <- vector()
NB.accuracy_8var <- vector()
NB.accuracy_4var <- vector()

for (i in 1:100){
  # Uwaga
  # Ta implementacja rozszerza możliwości funkcji naiveBayes{e1071}.
  # Rozszerzenia:
  #   - możliwość stosowania jądrowej estymacji gęstości (usekernel=TRUE)
  #   - możliwość wykorzystania p-stw a-priori zadanych przez użytkownika (prior) 
  
  n <- dim(data_num_qda)[1]
  prop <- 0.7
  #data_num <- data[c("symboling", int_kol, num_kol)]
  learning.indx <- sort(sample(1:n,prop*n))
  learning.set <- data_num_qda[learning.indx,]
  test.set <- data_num_qda[-learning.indx,]
  
  
  model.nb.kernel <- NaiveBayes(symboling~ ., data=learning.set, usekernel=TRUE)

  # wykresy wyestymowanych gęstości
  #plot(model.nb.kernel)
  
  # prognozowane etykietki
  pred.labels.nb.kernel <- predict(model.nb.kernel, newdata = test.set)$class
  # macierz pomyłek
  conf.mat.nb.kernel <- table(test.set$symboling, pred.labels.nb.kernel)

  (blad.nb.kernel <- (n.test-sum(diag(conf.mat.nb.kernel)))/n.test)
  accuracy <- 1- blad.nb.kernel
  
  NB.accuracy_allvar <- append(NB.accuracy_allvar, accuracy)
  
  #--------------------------MNIEJ ZMIENNYCH------------------------------
  
  model.nb.kernel <- NaiveBayes(symboling~ wheel.base + height + length + normalized.losses + curb.weight+
                                  bore+city.mpg+highway.mpg, 
                                data=learning.set, usekernel=TRUE)
 
  # wykresy wyestymowanych gęstości
  #plot(model.nb.kernel)
  
  # prognozowane etykietki
  pred.labels.nb.kernel <- predict(model.nb.kernel, newdata = test.set)$class
  # macierz pomyłek
  conf.mat.nb.kernel <- table(test.set$symboling, pred.labels.nb.kernel)

  (blad.nb.kernel <- (n.test-sum(diag(conf.mat.nb.kernel)))/n.test)
  accuracy <- 1- blad.nb.kernel
  
  NB.accuracy_8var <- append(NB.accuracy_8var, accuracy)
  
  #--------------------------NAJMNIEJ ZMIENNYCH-------------------------
  
  
  model.nb.kernel <- NaiveBayes(symboling~ wheel.base + height + length + normalized.losses, 
                                data=learning.set, usekernel=TRUE)

  

  # prognozowane etykietki
  pred.labels.nb.kernel <- predict(model.nb.kernel, newdata = test.set)$class
  # macierz pomyłek
  conf.mat.nb.kernel <- table(test.set$symboling, pred.labels.nb.kernel)
 
  (blad.nb.kernel <- (n.test-sum(diag(conf.mat.nb.kernel)))/n.test)
  accuracy <- 1- blad.nb.kernel
  NB.accuracy_4var <- append(NB.accuracy_4var, accuracy)

}
@

\par
Poniżej na rysunku \ref{fig:klasyf_NB_wykres} na boxplotach przedstawione zostały wyniki uzyskyskane metodą naiwnego klasyfikatora bayesowskiego, a czerwone punkty sa równe odpowiadającym wartościom średnim.
<<klasyf_NB_wykres, eval=TRUE, echo=FALSE, cache=TRUE, fig.cap="Porównanie dokładności metodą Naive Bayes">>=
ggplot() + 
  geom_boxplot(aes(x= "wszystkie zmienne", y=NB.accuracy_allvar)) +
  geom_boxplot(aes(x="8 zmiennych", y=NB.accuracy_8var)) +
  geom_boxplot(aes(x="4 zmienne", y=NB.accuracy_4var)) +
  geom_point(aes(x="wszystkie zmienne", y=mean(NB.accuracy_allvar) ), size=2.5, color="red"  )+
  geom_point(aes(x="8 zmiennych", y=mean(NB.accuracy_8var )), size=2.5, color="red"  )+
  geom_point(aes(x="4 zmienne", y=mean(NB.accuracy_4var) ), size=2.5, color="red"  )+
  ylab("Dokładność") +  xlab("")
@

Na rysunkach powyżej widzimy, że dokładność naiwnego klasyfikatora bayesowskiego jest tym większa, im mniejsza liczba wybranych cech, a jeśli chodzi o stabilność, to rozrzuty w~poszczególnych grupach są porównywalne.

\section{Podsumowanie I części projektu}
Podsumowując, na samym początku, przy wdrażaniu metod klasyfikacyjnych do konkretnego zagadnienia trzeba pamiętać o ich założeniach, o tym, że niektóre metody takie jak $KNN$ czy $LDA$ obsługują zmienne numeryczne lub o tym że różne metody jak np. $QDA$ czy lasy losowe moga mieć problem jeśli jedna z klas naszej zmiennej objaśnianej występuje w niezwykle małej liczbie. Dodatkowo metody mogą mieć inne różne uwarunkowania np. metoda jądrowej analizy dyskryminacyjne w praktyce może być użyta tylko dla małych wymiarów, dla powiedzmy $p<7$.
\par
Po drugie, przy implementacji każdej metody trzeba pamiętać o tym, że dla każdej metody trzeba rozważyć różne parametry (np. $k$ w metodzie k-najbliższych sąsiadów) lub różne podzbiory zmiennych, ponieważ wyniki dla różnych wersji wdrożenia każdej metody mogą być znacząco różne. Dodatkowo, oczywiście należy pamiętać, że dla różnych zbiorów danych o różnej charakterystyce, wyniki tych samych metod moga się różnić.
\par
Po trzecie, trzeba pamiętać o różnorakich miarach oceny naszych algorytmów. W naszej ocenie kierowaliśmy się tylko oceną dokładności, ale w różnych sytuacjach wybraną miarą porównawczą może być np. czułość czy swoistość. Dodatkowo trzeba pamiętać o stabilności otrzymanego rozwiązania - która jest coraz ważniejszym czynnikiem w ocenie metod z zakresu data mining - czyli sprawdzeniu tego jak różne wyniki daje nasza metoda przy niewielkiej zmianie danych.


Na rysunku \ref{fig:klasyf_podsumowanie_wykres} zilustrowane zostało porównanie boxplotów dla wszystkich metod. Analizując średnie dokładności oraz stabilności metod, z każdej z nich wybraliśmy jej najlepszą wersję implementacji tj:
\begin{itemize}
\item KNN - Wszystkie zmienne, $k=5$
\item Lasy losowe - $120$ drzewek, $11$ zmiennych
\item LDA - $4$ zmienne
\item LR - $6$ zmiennych
\item KDA - zmienne $WHL$
\item NB $4$ zmienne
\end{itemize}



<<klasyf_podsumowanie_wykres, eval=TRUE, echo=FALSE, cache=TRUE, fig.width=6 ,fig.cap="Porównanie dokładności różnych metod">>=
ggplot() + 
  geom_boxplot(aes(x="KNN", y=KNN.accuracy_all_k5)) + 
  geom_boxplot(aes(x= "Lasy losowe", y=RF.accuracy_120_11_5)) +
  geom_boxplot(aes(x= "LDA", y=LDA.accuracy4)) +
  geom_boxplot(aes(x= "LR", y=LR.accuracy_6var)) +
  geom_boxplot(aes(x="KDA", y=KDA.accuracy_whl)) +
  geom_boxplot(aes(x="NB", y=NB.accuracy_4var)) + 
  geom_point(aes(x="KNN", y=mean(KNN.accuracy_all_k5) ), size=2.5, color="red"  )+
  geom_point(aes(x="Lasy losowe", y=mean(RF.accuracy_120_11_5) ), size=2.5, color="red"  )+
  geom_point(aes(x="LDA", y=mean(LDA.accuracy4) ), size=2.5, color="red"  )+
  geom_point(aes(x="LR", y=mean(LR.accuracy_6var) ), size=2.5, color="red"  )+
  geom_point(aes(x="KDA", y=mean(KDA.accuracy_whl) ), size=2.5, color="red"  )+
  geom_point(aes(x="NB", y=mean(NB.accuracy_4var) ), size=2.5, color="red"  )+
  ylab("Dokładność") + 
  xlab("")


@
Powyżej widzimy, że w naszej analizie porównawczej kilku metod, wyniki jeśli chodzi o~średnie i mediany dokładności są bardzo podobne. Spośród wybranych algorytmów wyraźnie najlepiej poradziły sobie lasy losowe, które jako jedyne uzyskały ponad wartości większe niż $0.8$ jeśli chodzi o średnie i mediany. Kolejnymi najlepszymi metodami były $KDA$ oraz wielomianowa regresja logistyczna, które moga się poszczycić medianami i średnimi większymi od $0.7$, przy czym $KDA$ obie te wartości ma większe. Kolejne metody - $KNN$ oraz naiwny klasyfikator bayesowski mają średnie oraz mediany ponad $0.6$, jednakże naiwny klasyfikator bayesowski obie te metryki miał na lepszym poziomie. Najgorzej w naszym zestawieniu wypadła metoda $LDA$, której nawet najlepsza wersja implementacji nie zdołała uzysać rezultatów na poziomie $0.6$ (dokładniej średnia oraz mediana z zakresu $(0.55, 0.6)$, jednakże trzeba pamiętać, że to i tak dość dobry rezultat przy zagadnieniu klasyfikacji dla $5$ klas (w przypadku $LDA$, w przypadku niektórych innych metod - $6$ klas), gdzie dokładność przy losowaniu klasy zmiennej objaśnianej powinno dawać rezultaty w przybliżeniu $0.16$.




\section{Analiza skupień, klasteryzacja}  

\subsection{Wstęp}
Analiza skupień jest ważnym zagadnieniem w obszarze data mining. Jest narzędziem służącym do eksploaracji danych, jej celem jest ułożenie obiektów w klastry w taki sposób, aby stopień powiązania obiektów z obiektami należącymi do tego samego klastra był jak największy, a z obiektami z innych klastrów jak najmniejszy. Dodatkowo warto wspomnieć, że analiza skupień często jedynie wykrywa struktury w danych, ale nie wyjaśnia dlaczego takie struktury występują.

<<DATA_LOAD_FOR_CLUSTERING, eval=TRUE, echo=FALSE>>=
#JESZCZE RAZ WGRYWAMY DANE, BEZ USUWAANIA ŻANYCH KOLUMN

data2 <- read.csv("C:/STUDIA/Matematyka ( II stopień )/II semestr/Data mining/ProjektDM/Automobile_data.csv")
data2[data2=="?"]<-NA
factor_kol <- c('symboling','make',
                'fuel.type','aspiration','num.of.doors',
                'body.style','drive.wheels','engine.location',
                'engine.type','num.of.cylinders',
                'fuel.system')
int_kol <- c('normalized.losses','horsepower','peak.rpm','city.mpg','highway.mpg',
             'price','curb.weight','engine.size')

num_kol <- c('bore','stroke','compression.ratio','wheel.base','length','width','height')

data2 <- data2 %>% mutate_at(factor_kol, factor) %>% 
  mutate_at(int_kol, as.integer) %>% mutate_at(num_kol, as.numeric)

data2[is.na(data2$normalized.losses),]$normalized.losses <- round(mean(data2[!is.na(data2$normalized.losses),]$normalized.losses))
data2[is.na(data2$horsepower),]$horsepower <- round(mean(data[!is.na(data2$horsepower),]$horsepower))
data2[is.na(data2$bore),]$bore <- round(mean(data2[!is.na(data2$bore),]$bore), digits=2)
data2[is.na(data2$stroke),]$stroke <- round(mean(data2[!is.na(data2$stroke),]$stroke), digits=2)
data2[is.na(data2$peak.rpm),]$peak.rpm <- round(mean(data2[!is.na(data2$peak.rpm),]$peak.rpm), digits=2)
data2[is.na(data2$price),]$price <- round(mean(data2[!is.na(data2$price),]$price), digits=2)
data2[is.na(data2$num.of.doors),]$num.of.doors <- "four"

data_num <- data2[c("symboling", int_kol, num_kol)]
@

\par

Jeśli chodzi o nasz zbiór danych, na start usuwamy z niego wiersze, gdzie wartości zmiennej \texttt{symboling} są równe $-2$, robimy tak z powodu zbyt małej liczności takich obserwacji - jest ich zaledwie $3$. (Dodatkowo usuwamy tą wartość z leveli zmiennej typu factor). W analizie skupień nie używa się kategorii zmiennej objaśnianej, dlatego tworzymy dwa podzbiory danych, jeden zawierający wszystkie zmienne poza zmienną \texttt{symboling}, a drugi zawierający wszystkie zmienne ilościowe (tym samym również bez zmiennej objaśnianej \texttt{symboling}). Zbiór danych ze zmiennymi numerycznymi standaryzujemy. Poniżej fragment kodu przedstawiający te transformacje.

<<data_transform_clustering, eval=TRUE, echo=TRUE>>=
data_clust <- data2[!(data$symboling==-2),]
data_clust$symboling <- droplevels(data_clust$symboling)
data_clust_features <- data_clust[, 2:26] 
data_num_clust <- data_clust[c("symboling", int_kol, num_kol)]
data_num_clust_features <- data_num_clust[, 2:16]
data_num_clust_features <- as.data.frame( scale(data_num_clust_features) )
data_clust_symboling_real <- data_clust[,1]
data_num_clust_features_UNSCALED <- data_num_clust[, 2:16]

@

Ponadto, korzystając z faktu, że zmienna \texttt{symboling} jest zmienną porządkową, tworzymy nowy wektor gdzie grupujemy jej wartości: w jednej grupie znajdują się wartości mniejsze, czyli $-1$ i $0$, a w drugiej większe wartości: $1$, $2$ i $3$. Taka konstrukcja przyda nam się w późniejszej części analizy. Poniżej zamieszczony został fragment kodu przedstawiający stworzenie tego wektora.
<<symboling_custom, eval=TRUE, echo=TRUE, cache=TRUE>>=
symboling_custom<- as.numeric(data_clust$symboling)
symboling_custom[which(symboling_custom %in% c(1,2))] <- "-1 or 0"
symboling_custom[which(symboling_custom %in% c(3,4,5))] <- "1 , 2 or 3"
@

Tworzymy jeszcze jedną zmiennej na bazie istniejącej. Mianowicie faktoryzujemy zmienną ciągłą \texttt{price} w następujący sposób: tworzymy $4$ przedziały, które są oddzielane przez liczby $8000$, $12000$ i $18000$. Taka konstrukcja również nam się przyda w późniejszej fazie. Poniżej na rysunku \ref{fig:price_factor} przedstawiony został wykres słupkowy owej zmiennej po takiej transformacji.
<<price_factor, eval=TRUE, echo=FALSE, fig.width=8, cache=TRUE, fig.height=4, fig.cap="Częstotliwość występowania poszczególnych grup zmiennej \\texttt{price}" >>=
price_factor<- as.data.frame (cut(data_num_clust$price, breaks=c(0,8000,12000,18000,max(data_num_clust$price)), 
                 labels=c("Cheap (x<8000)", "Medium (8000<x<12000)", "Expensive (12000<x<18000)", 
                          "Very expensive (x>18000)")))
colnames(price_factor) <- "Kategoria cenowa"
ggplot(price_factor, aes(x=`Kategoria cenowa`, fill=as.factor(`Kategoria cenowa`) )) + 
  geom_bar( ) +
  scale_fill_brewer(palette = "Set1") +
  theme(legend.position="none")+
  theme(axis.text.x = element_text(angle = 0, size=8.5, hjust = 0.5))
@




\subsection{Metody grupujace}

\subsubsection{Metoda k -średnich}
Pierwszą metodą grupującą jakiej użyjemy będzie metoda $k$-średnich ($k-means$). Jest to metoda której na wejściu dostarczamy dane liczbowe (czyli można uwzględnić tylko zmienne numeryczne!), a także $K$ - liczbę klastrów na jaką chcemy podzielić zbiór danych. W inicjalizacji wybieramy $K$ wartości początkowych będących średnimi (centrami skupień). Następnie przyporządkowujemy każdy obiekt do najbliższej mu średniej. Z tak powstałego przyporządkowania wyznaczamy nowe centra skupień (średnie wektorowe). Kroki przyporządkowania i liczenia nowych średnich powtarzamy do spełnienia warunku zbieżności.

\par

Do implementacji metody $k$-means w \textbf{R} posłuży nam funkcja \texttt{kmeans} \cite{kmeans} z pakietu \textbf{stats}. Na rysunku \ref{fig:Plot_kmeans2vars_1} przedstawiona została wizualizacja zastosowania metody $k-means$ na przykładzie zmiennych \texttt{horsepower} i \texttt{highway.mpg} (skrótowo: $HH$) z rozdzieleniem na $K=5$ klastrów z maksymalną liczbą iteracji równą $15$. Liczba klastrów podyktowana jest oczywiście liczbą kategorii objaśnianej zmiennej \texttt{symboling} (po usunięciu z niej kategorii wartości $-2$). Na rysunku zaznaczone sa także większymi, wypełnionymi kwadratami końcowe centra skupień. Ponadto, każda z obserwacji oprócz koloru, ma także przypisany kształt odpowiadający rzeczywistej wartości zmiennej \texttt{symboling}. 


<<Plot_kmeans2vars_1, eval=TRUE, echo=FALSE,fig.width=10, cache=TRUE, fig.height=5.7 ,fig.cap="Metoda k-means na dwóch zmiennych: horsepower i highway.mpg oraz z podziałem na 5 klastrów">>=
k <- 5

kmeans.k5 <- kmeans(data_num_clust_features[,c("horsepower", "highway.mpg")],centers=k,iter.max=15, nstart=10)
# Etykietki grup
data_num_clust_features.kmeans <- kmeans.k5$cluster
x <- as.data.frame(kmeans.k5$centers[,c("horsepower", "highway.mpg")])
ggplot()+
  geom_point(data_num_clust_features, mapping=aes(x=horsepower, y=highway.mpg), color=data_num_clust_features.kmeans, 
             pch=as.numeric(data_clust_symboling_real))+
  ggtitle("Klastrowanie z wykorzystaniem k-means:\nkolor -  etykietki z k-means, symbol - etykietki rzeczywiste")+
  geom_point(x, mapping = aes(x=horsepower, y=highway.mpg), pch=15, color=1:5, size=3.4)
@

Na rysunku \ref{fig:Plot_kmeans2vars_2} umieszczony został analogiczny wykres, tylko że dla zmiennych \texttt{wheel.base} i \texttt{price} (skrótowo: $WP$).

<<Plot_kmeans2vars_2, eval=TRUE, echo=FALSE, cache=TRUE, fig.width=10, fig.height=5.7 ,fig.cap="Metoda k-means na dwóch zmiennych: wheel.base i price oraz z podziałem na 5 klastrów">>=
k<-5
kmeans.k5 <- kmeans(data_num_clust_features[,c("wheel.base","price" )],centers=k,iter.max=15, nstart=10)
data_num_clust_features.kmeans <- kmeans.k5$cluster

x <- as.data.frame(kmeans.k5$centers[,c("wheel.base","price")])

ggplot()+
  geom_point(data_num_clust_features, mapping=aes(x=wheel.base, y=price), color=data_num_clust_features.kmeans, 
             pch=as.numeric(data_clust_symboling_real), size=1.3)+
  ggtitle("Klastrowanie z wykorzystaniem k-means:\nkolor -  etykietki z k-means, symbol - etykietki rzeczywiste")+
  geom_point(x, mapping = aes(x=wheel.base, y=price), pch=15, color=1:5, size=3.6)
@

Na obu rysunkach powyżej widzimy jak algorytm $k-means$ stworzył podziały na $5$ grup. Widzimy, że te podziały wyglądaja na sensowne tzn. obszary odpowiadające wszystkim klastrom są rozłączne. W przypadku zmiennych $HH$ klastry są bardziej równoliczne. Co ciekawe, dla tej pary zmiennych widzimy, że obserwacje rozproszone są na wykresie punktowym bardziej równomiernie, niż dla zmiennych $WP$, gdzie punkty są bardziej skoncentrowane w okolicach \texttt{wheel.base}$=-0.3$, \texttt{price}$=-0.7$ niż w obszarach bardziej odległych od tego miejsca. Dlatego też skupienia dla tych zmiennych można ocenić jako mniej zwarte, w przypadku zmiennych $HH$ skupienia są dużo bardziej zwarte dla wszystkich grup, z wyjątkiem $2$ punktów odstających w klastrze o kolorze czerwonym.
\par
Żeby formalniej ocenić lub porównać jakość klasteryzacji, możemy użyć w tym celu różnych wskaźników. Przykładami takich miar są rozrzut wewnątrz skupień (ang. within-cluster scatter) czy rozrzut pomiędzy skupieniami (ang. between-cluster scatter). Tak jak wskazują nazwy, pierwsza z tych miar wskazuje jak duży jest rozrzut między obiektami z tych samych klastrów, a druga ocenia rozrzut między obiektami z różnych klastrów. Poniżej na rysunkach \ref{fig:rozrzut_HH}, \ref{fig:rozrzut_WP} przedstawione zostały porównania obu tych miar oraz totalnego rozrzutu (który jest sumą tych dwóch miar) dla różnych wartości $k$- klastrów w zakresie od $1$ do $10$ dla zmiennych $HH$ oraz $WP$.
<<rozrzut_HH, eval=TRUE, echo=FALSE, cache=TRUE, fig.width=6 ,fig.cap="Porównanie różnych rozrzutów dla różnch liczb klastrów">>=
#Ocena jakości  HH
# rozrzut wewnątrz skupień i rozrzut między skupieniami dla różnej liczby skupień (K)
Within   <- c()
Between  <- c()
Total    <- c()

K.range <- 1:10

for (k in K.range)
{
  kmeans.k  <- kmeans(data_num_clust_features[,c("horsepower", "highway.mpg")],centers=k,iter.max=15, nstart=10)
  Within  <- c(Within, kmeans.k$tot.withinss)	# total within-cluster sum of squares =  sum(withinss))
  Between <- c(Between, kmeans.k$betweenss)     # between-cluster sum of squares
  Total   <- c(Total,kmeans.k$totss) 	        # total sum of squares.
  # Uwaga: Total == Within + Between
}
x <- rbind.data.frame(Within, Between, Total)

x <- cbind.data.frame(rep(K.range,3), c( rep("Rozrzut wewnątrz skupień", 10), 
                              rep("Rozrzut pomiędzy skupieniami", 10), 
                              rep("Rozrzut całkowity", 10) ), c(Within, Between, Total))
colnames(x) <- c("K.range", "Rodzaj rozrzutu", "Rozrzut")

ggplot(x, aes(x=K.range, y=Rozrzut, color =`Rodzaj rozrzutu`))+
  geom_point()+
  geom_line()+
  scale_x_continuous( breaks = c(2,4,6,8,10))+
  theme(legend.position="bottom")+
  ggtitle("Zmienne horsepower i highway.mpg")+
  guides(color=guide_legend(nrow=2))
@

<<rozrzut_WP, eval=TRUE, echo=FALSE, cache=TRUE,fig.width=6 ,fig.cap="Porównanie różnych rozrzutów dla różnch liczb klastrów">>=
#Ocena jakości WP

Within   <- c()
Between  <- c()
Total    <- c()

K.range <- 1:10

for (k in K.range)
{
  kmeans.k  <- kmeans(data_num_clust_features[,c("wheel.base","price" )],centers=k,iter.max=15, nstart=10)
  Within  <- c(Within, kmeans.k$tot.withinss)	# total within-cluster sum of squares =  sum(withinss))
  Between <- c(Between, kmeans.k$betweenss)     # between-cluster sum of squares
  Total   <- c(Total,kmeans.k$totss) 	        # total sum of squares.
  # Uwaga: Total == Within + Between
}

x <- rbind.data.frame(Within, Between, Total)

x <- cbind.data.frame(rep(K.range,3), c( rep("Rozrzut wewnątrz skupień", 10), 
                                         rep("Rozrzut pomiędzy skupieniami", 10), 
                                         rep("Rozrzut całkowity", 10) ), c(Within, Between, Total))
colnames(x) <- c("K.range", "Rodzaj rozrzutu", "Rozrzut")

ggplot(x, aes(x=K.range, y=Rozrzut, color =`Rodzaj rozrzutu`))+
  geom_point()+
  geom_line()+
  scale_x_continuous( breaks = c(2,4,6,8,10))+
  theme(legend.position="bottom")+
  ggtitle("Zmienne wheel.base i price")+
  guides(color=guide_legend(nrow=2))
@
Możemy zauważyć, że oba wykresy są do siebie bardzo podobne. Co oczywiste wraz ze wzrostem parametru $k$, maleje rozrzut wewnątrz skupień - są bardziej zwarte, a rośnie rzorzut między skupieniami. Widzimy, że dla $k=5$, dla którego zwizualizowane zostały wyżej oba rozrzuty, dla zmiennych $HH$ rozrzut wewnątrz skupień jest równy ok. $50$, a dla zmiennych $WP$ ta wartość jest równa ok. $70$, co potwierdza nasze wnioski z analizy wizualnej, że skupienia w przypadku $HH$ są bardziej zwarte.  

\par
Innym wskaźnikiem służącym do oceny klasteryzacji jest indeks Silhoutte'a \cite{silhoutette}. Wskaźnik ten ocenia każdy obiekt w skali $[-1,1]$, przy czym wartości im bliżej $1$, tym większe prawdopodobieństwo, że obiekt został poprawnie przyporządkowany, a im bliżej $-1$, tym większa szansa, że został on przyporządkowany błędnie. Wartości w okolicach $0$ świadczą o tym, że obiekt lezy pomiędzy klastrami $A$ i $B$. Poniżej na rysunkach \ref{fig:Silhouette_kmeans1} i \ref{fig:Silhouette_kmeans2} widzimy wykresy Silhouette dla metody $k$-means dla odpowiednio zmiennych \texttt{horsepower} i \texttt{highway.mpg} oraz \texttt{wheel.base} i \texttt{price}. Przed każdym wykresem zamieszczony został fragment kodu z wypisanymi indeksami Silhouette'a dla poszczególnych klastrów grupowania.

<<Silhouette_kmeans1, eval=TRUE, echo=FALSE, fig.width=6, cache=TRUE,fig.cap="Wykres Silhouette zmiennych HH i metody k-means">>=
k<-5
kmeans.k5 <- kmeans(data_num_clust_features[,c("horsepower", "highway.mpg")],centers=k,iter.max=15, nstart=10)
sil.kmeans <- silhouette(kmeans.k5$cluster, dist(data_num_clust_features[,c("horsepower", "highway.mpg")]))
x<-fviz_silhouette(sil.kmeans, xlab="K-means dla HH", print.summary = FALSE)

#AVerage Silhouette in Cluster
ASC_clust_HH.Kmeans <-  round(as.numeric(x$plot_env$ave), 3)
ASC_HH.Kmeans<- round(mean(as.numeric(x$data$sil_width)), 3)

#zmiana koloru kreski oznaczającej średnią
x$layers[[2]]$aes_params$colour <- "black"
x + theme(plot.title = element_text(hjust = 0.5))
@

<<Silhouette_1, eval=TRUE, echo=FALSE, cache=TRUE>>=
print("Średnie wartości indeksów Silhouette dla każdego z klastrów:") 
print(ASC_clust_HH.Kmeans)
print(paste("Średnia wartość indeksu Silhouette ogółem:", ASC_HH.Kmeans))
@

<<Silhouette_kmeans2, eval=TRUE, echo=FALSE, fig.width=6 ,cache=TRUE,fig.cap="Wykres Silhouette dla zmiennych WP i metody k-means">>=
k<-5
kmeans.k5 <- kmeans(data_num_clust_features[,c("wheel.base","price" )],centers=k,iter.max=15, nstart=10)
data_num_clust_features.kmeans <- kmeans.k5$cluster

sil.kmeans <- silhouette(kmeans.k5$cluster, dist(data_num_clust_features[,c("wheel.base","price" )]))
x<-fviz_silhouette(sil.kmeans, xlab="K-means dla zmiennych WP", print.summary = FALSE)
#AVerage Silhouette in Cluster
ASC_clust_WP.Kmeans <-  round(as.numeric(x$plot_env$ave), 3)
ASC_WP.Kmeans<- round(mean(as.numeric(x$data$sil_width)), 3)
x$layers[[2]]$aes_params$colour <- "black"
x + theme(plot.title = element_text(hjust = 0.5))

@

<<Silhouette_2, eval=TRUE, echo=FALSE, cache=TRUE>>=
print("Średnie wartości indeksów Silhouette dla każdego z klastrów:") 
print(ASC_clust_WP.Kmeans)
print(paste("Średnia wartość indeksu Silhouette ogółem:", ASC_WP.Kmeans))
@ 

Z rysunków oraz przedstawionych wartości liczbowych średnich indeksów dla poszczególnych klastrów powyżej, możemy wyciągnąć kilka wniosków. Po pierwsze i najważniejsze, widzimy, że średnia wartość indeksu Silhouette'a dla zmiennych $HH$ jest większa niż dla zmiennych $WP$. Co więcej, widzimy także, że wartości indeksów dla poszczególnych klastrów dla $HH$ mają mniejszy rozrzut np. średnia wartość w tylko jednym klastrze jest mniejsza niż $0.45$. Co więcej, potwierdzają się nasze obserwacje dotyczące tego, że klastry dla przypadku $HH$ są bardziej "równoliczne", mimo jednej mniejszej grupy. Ponadto widzimy, że w przeciwieństwie do zmiennych $WP$, dla $HH$ nie istnieją żadne obiekty, dla których indeks Silhouette'a byłby ujemmy. 

\par
Teraz porównamy średnie indeksy Silhouette'a dla różnych liczb klastrów $k$ oraz dla następujących podzbiorów zmiennych ilościowych:
\begin{itemize}
\item zmienne \texttt{horsepower} i \texttt{highway.mpg} ($HH$)
\item zmienne \texttt{wheel.base} i \texttt{price} ($WP$) 
\item zmienne \texttt{wheel.base}, \texttt{height}, \texttt{length}, \texttt{normalized.losses}, \texttt{curb.weight} ($5$ zmiennych)
\item zmienne \texttt{wheel.base}, \texttt{height}, \texttt{length}, \texttt{normalized.losses}, \texttt{curb.weight}, \texttt{bore}, \texttt{highway.mpg}, \texttt{city.mpg}, \texttt{horsepower} ($9$ zmiennych)
\item wszystkie zmienne numeryczne
\end{itemize}

Wyniki zostały zilustrowane na rysunku \ref{fig:Silhouette_features_kmeans}. Użyliśmy funkcji \texttt{fviz nbclust} \cite{nbclust} z pakietu \textbf{factoextra} z parametrem "FUNcluster = kmeans".
<<Silhouette_features_kmeans, eval=TRUE, echo=FALSE, fig.width=6 ,cache=TRUE,fig.cap="Wykres Silhouette dla różnych podzbiorów zmiennych ilościowych i metody k-means">>=
plot1_kmeans <- fviz_nbclust(data_num_clust_features[,c("horsepower", "highway.mpg")], FUNcluster = kmeans, method = "silhouette")
plot2_kmeans <- fviz_nbclust(data_num_clust_features[,c("wheel.base","price")], FUNcluster = kmeans, method = "silhouette")
plot3_kmeans <- fviz_nbclust(data_num_clust_features[,c("wheel.base","height", "length", "normalized.losses", "curb.weight")], 
                      FUNcluster = kmeans, method = "silhouette")
plot4_kmeans <- fviz_nbclust(data_num_clust_features[,c("wheel.base","height", "length", "normalized.losses", "curb.weight", "bore",
                                              "highway.mpg", "city.mpg", "horsepower")], FUNcluster = kmeans, method = "silhouette")
plot5_kmeans <- fviz_nbclust(data_num_clust_features, FUNcluster = kmeans, method = "silhouette")

x <- cbind.data.frame(c(rep("HH", 10), rep("WP", 10), rep("5 zmiennych(num)",10), rep("9 zmiennych(num)", 10), rep("Zmienne numeryczne", 10)),
                 rep(c(1:10),5),  c(as.numeric(plot1_kmeans$data$y), as.numeric(plot2_kmeans$data$y), as.numeric(plot3_kmeans$data$y), 
                                    as.numeric(plot4_kmeans$data$y), as.numeric(plot5_kmeans$data$y) ))
                 
colnames(x) <- c("Zmienne", "Number of clusters k", "Silhouette")

ggplot(x, aes(x=`Number of clusters k`, y=Silhouette, color =`Zmienne`))+
  geom_point()+
  geom_line()+
  scale_x_continuous( breaks = c(2,4,6,8,10))+
  ggtitle("k-means")+
  theme(plot.title = element_text(hjust = 0.5))  #wyśrodkowanie głównego tytułu

@

Na podstawie rysunku powyżej możemy wysunąć hipotezę, że dla wszystkich wartości $k$, indeksy Silhouette'a są tym większe, im mniej zmiennych jest branych pod uwagę. Widzimy także, że niezależnie od podzbioru, optymalną liczbą klastrów jest $k=5$. Ponadto, największe wartości indeksu Silhouette'a dla $k=2$ lub $k=3$ osiąga podzbiór zmiennych złożony z \texttt{wheel.base} i \texttt{price}, a dla $k>3$ zmienne \texttt{horsepower}, \texttt{highway.mpg}.

\newpage
 
\subsection{PAM (partition about medoids)}
W tej części porównamy metody $k-means$ i $PAM$, ale najpierw kilka słów wstępu o tym drugim algorytmie. Metoda $PAM$ polega na wybraniu $k$ obiektów będących centrami poszczególnych skupień (tzw. medoidami). $PAM$ tak samo jak metoda $k-means$ potrzebuje mieć z góry podaną liczbę $K$ partycji na ile ma być podzieloby zbiór obiektów, ale w przeciwieństwie do $k-means$, na wejściu dostarczamy nie na dane liczbowe, a dowolną macierz odmienności między obiektami. Co z kolei implikuje, że metody $PAM$ możemy użyć nie tylko dla zmiennych ilościowych, ale także dla zmiennych jakościowych, a także danych mieszanego typu. Wadą może być fakt, że $PAM$ ma większą złożoność obliczeniową - proporcjonalną do $n^2$ ($n$-liczba obiektów) niż $k-means$, gdzie złożonośc jest liniowa. Z tego powodu dla dużych $n$ czas obliczeń algorytmu $PAM$ może być problemem, dlatego dla większych zbiorów danych zaleca się używanie algorytmu $CLARA$ (Clustering LARge Applications). Jednakże w przypadku naszych danych, gdzie $n=205$ (po usunięciu wierszy z \texttt{symboling}$=-2$, $n=202$) będziemy używać zwykłej wersji algorytmu $PAM$.

\par
Jeśli chodzi o implementacje algorytmu $PAM$ w \textbf{R}, zaczniemy od przedstawienia macierzy odmienności dla zmiennych ilościowych, oraz dla wszystkich zmiennych. Możemy ja zauważyć na rysunkach \ref{fig:DM_num} i \ref{fig:DM}. Macierze obliczone są za pomocą funkcji \texttt{daisy} \cite{daisy} z pakietu \textbf{cluster}. Domyślną metryką stosowaną w tej funkcji jest metryka euklidesowa. Jednakże jeśli zostaną wykryte zmienne jakościowe, funkcja \texttt{daisy} automatycznie stosuje miarę odmienności Gowera \cite{Gower}. Wizualizacja macierzy została stworzona z użyciem funkcji \texttt{fviz dist} z pakietu \textbf{factoextra} \cite{factoextra}.

<<DM_num, eval=TRUE, echo=FALSE,fig.width=5.7, fig.height=3.5,cache=TRUE,fig.cap="Macierz odmienności dla zmiennych numerycznych">>=
DM_num <- daisy(data_num_clust_features)
DM_num_matrix <- as.matrix(DM_num)
fviz_dist(DM_num, order=TRUE)
@

Poniżej przedstawiona została wizualizacja macierzy odmienności dla wszystkich zmiennych.

<<DM, eval=TRUE, echo=FALSE ,fig.width=5.7, fig.height=3.5 ,cache=TRUE,fig.cap="Macierz odmienności dla wszystkich zmiennych">>=
data_clust_features <- data_clust[, 2:26]
DM <- daisy(data_clust_features)  #odległość Gowera wybrane automatycznie, jeśli wykryje kolumny nienumeryczne
DM_matrix <- as.matrix(DM)
fviz_dist(DM, order=TRUE)
@

\par

Poniżej przedstawiony został wykres dla $PAM$, analogiczny do rysunku \ref{fig:Silhouette_features_kmeans} dotyczącego metody $k-means$. Zobrazowane zostałow porównanie indeksów Silhouette'a dla różnych wartości $k$ z przedziału $[1,10]$ oraz dla różnych podzbiorów zmiennych. 

\begin{itemize}
\item zmienne \texttt{horsepower} i \texttt{highway.mpg} ($HH$)
\item zmienne \texttt{wheel.base} i \texttt{price} ($WP$) 
\item zmienne \texttt{wheel.base}, \texttt{height}, \texttt{length}, \texttt{normalized.losses}, \texttt{curb.weight} ($5$ zmiennych)
\item zmienne \texttt{wheel.base}, \texttt{height}, \texttt{length}, \texttt{normalized.losses}, \texttt{curb.weight}, \texttt{bore}, \texttt{highway.mpg}, \texttt{city.mpg}, \texttt{horsepower} ($9$ zmiennych)
\item wszystkie zmienne numeryczne
\item \texttt{normalized.losses}, \texttt{fuel.system}, \texttt{num.of.doors}, \texttt{length} ($4$ zmienne mix)
\item \texttt{price}, \texttt{city.mpg}, \texttt{curb.weight}, \texttt{body.style}, \texttt{drive.wheels} ($5$ zmiennych mix)
\item \texttt{make}, \texttt{fuel.system}, \texttt{num.of.doors}, \texttt{body.style} ($4$ zmienne factors)
\item \texttt{make}, \texttt{num.of.doors} ($2$ zmienne factors)
\item wszystkie zmienne

\end{itemize}


$5$ podzbiorów, bazujących na zmiennych ilościowych, jest takie samo jak w przypadku metody $k-means$. Kolejne $5$ podzbiorów uwzględnia zmienne jakościowe czy dane mieszanego typu. Ponownie użyliśmy funkcji \texttt{fviz nbclust} \cite{nbclust} z pakietu \textbf{factoextra}, tym razem z parametrem "FUNcluster = cluster::pam", a rezultaty zilustrowane zostały na rysunku \ref{fig:Silhouette_features_PAM}.

<<Silhouette_features_PAM, eval=TRUE, echo=FALSE, fig.width=6 ,cache=TRUE,fig.cap="Wykres Silhouette dla różnych podzbiorów zmiennych i metody PAM">>=

k <- 5
plot1_pam <- fviz_nbclust(data_num_clust_features[,c("horsepower", "highway.mpg")], FUNcluster = cluster::pam, method = "silhouette")
plot2_pam <- fviz_nbclust(data_num_clust_features[,c("wheel.base","price")], FUNcluster = cluster::pam, method = "silhouette")
plot3_pam <- fviz_nbclust(data_num_clust_features[,c("wheel.base","height", "length", "normalized.losses", "curb.weight")], 
                      FUNcluster = cluster::pam, method = "silhouette")
plot4_pam <- fviz_nbclust(data_num_clust_features[,c("wheel.base","height", "length", "normalized.losses", "curb.weight", "bore",
                                                 "highway.mpg", "city.mpg", "horsepower")], FUNcluster = cluster::pam, method = "silhouette")
plot5_pam <- fviz_nbclust(data_num_clust_features, FUNcluster = cluster::pam, method = "silhouette")
plot6_pam <- fviz_nbclust(DM_matrix, FUNcluster = cluster::pam, method = "silhouette")

DM_test <- daisy(data_clust_features[, c("normalized.losses", "fuel.system", "num.of.doors", "length")])
DM_test_matrix <- as.matrix(DM_test)  
plot7_pam <- fviz_nbclust(DM_test_matrix, FUNcluster = cluster::pam, method = "silhouette")

DM_test <- daisy(data_clust_features[, c("price", "city.mpg", "curb.weight", "body.style", "drive.wheels")])
DM_test_matrix <- as.matrix(DM_test) 
plot8_pam <- fviz_nbclust(DM_test_matrix, FUNcluster = cluster::pam, method = "silhouette")
  
DM_test <- daisy(data_clust_features[, c("make", "fuel.system", "num.of.doors", "body.style")])
DM_test_matrix <- as.matrix(DM_test) 
plot9_pam <- fviz_nbclust(DM_test_matrix, FUNcluster = cluster::pam, method = "silhouette")
  
DM_test <- daisy(data_clust_features[, c("make", "num.of.doors")])
DM_test_matrix <- as.matrix(DM_test)   
plot10_pam <- fviz_nbclust(DM_test_matrix, FUNcluster = cluster::pam, method = "silhouette")

#----------------------WYKRES DLA PAM------------------------------
x <- cbind.data.frame(c(rep("HH", 10), rep("WP", 10), rep("5 zmiennych(num)",10), rep("9 zmiennych(num)", 10), 
                    rep("Zmienne numeryczne", 10), rep("Wszystkie zmienne", 10), rep("4 zmienne(mix)", 10),
                    rep("5 zmiennych(mix)", 10), rep("4 zmienne(factors)", 10), rep("2 zmienne(factors)", 10)),
                      rep(c(1:10),10),  c(as.numeric(plot1_pam$data$y), as.numeric(plot2_pam$data$y), as.numeric(plot3_pam$data$y), as.numeric(plot4_pam$data$y), as.numeric(plot5_pam$data$y), as.numeric(plot6_pam$data$y),
as.numeric(plot7_pam$data$y), as.numeric(plot8_pam$data$y), as.numeric(plot9_pam$data$y), as.numeric(plot10_pam$data$y)))

colnames(x) <- c("Zmienne", "Liczba klastrów k", "Silhouette")
x$Zmienne <- factor(x$Zmienne, levels = c("5 zmiennych(num)", "9 zmiennych(num)", "HH", "WP", "Zmienne numeryczne",  "Wszystkie zmienne", "4 zmienne(mix)", "5 zmiennych(mix)", "4 zmienne(factors)", "2 zmienne(factors)"))

ggplot(x, aes(x=`Liczba klastrów k`, y=Silhouette, color =`Zmienne`))+
  geom_point()+
  geom_line()+
  scale_x_continuous( breaks = c(2,4,6,8,10))+
  ggtitle("PAM")+
  theme(plot.title = element_text(hjust = 0.5)) 
@

Po pierwsze, na rysunku powyżej widzimy, że $4$ podzbiory zmiennych mają mniejsze indeksy Silhouette'a od pozostałych, są to: "wszystkie zmienne", "zmienne numeryczne", "$5$ zmiennych(num)" i "$9$ zmiennych(num)". Po drugie, w tym przypadku widzimy, że nie zawsze $k=2$ jest optymalną liczbą klastrów. Podzbiory "$4$ zmienne(mix)", "$5$ zmiennych(mix)", "$4$ zmienne(factors)" mają największe wartości indeksów dla odpowiednio $k=6$, $k-7$ i $k=10$. I po trzecie, możemu zauważyć, że największe wartości indeksów dla $k=2$, $k=3$ i $k=10$ są dla podzbioru "$2$ zmienne (factors)".

\par 
Poniżej na rysunku \ref{fig:Silhouette_vs_kmeans_PAM} przedstawione zostało porównanie metod $k-means$ i $PAM$ dla $5$ podzbiorów uwzględniających tylko zmienne ilościowe. Oczywiście odpowiednie dane są te same co na rysunkach \ref{fig:Silhouette_features_kmeans} i \ref{fig:Silhouette_features_PAM}.


<<Silhouette_vs_kmeans_PAM, eval=TRUE, echo=FALSE,fig.width=6 ,cache=TRUE,fig.cap="Porównanie indeksów Silhouette'a dla zmiennych WP i metody k-means">>=
x <- cbind.data.frame( c(rep("Kmeans", 10), rep("PAM", 10)), rep(c(1:10),2), c(as.numeric(plot1_kmeans$data$y) , 
                                                          as.numeric(plot1_pam$data$y)) )

colnames(x) <- c("Metoda", "Liczba klastrów k", "Silhouette")

pplotKMPAM1 <- ggplot(x, aes(x=`Liczba klastrów k`, y=Silhouette, color =`Metoda`))+
  geom_point()+
  geom_line()+
  scale_x_continuous( breaks = c(2,4,6,8,10))+
  ggtitle("Zmienne HH")+
  theme(plot.title = element_text(hjust = 0.5)) 
#----------------------------------------------------------------------------------
x <- cbind.data.frame( c(rep("Kmeans", 10), rep("PAM", 10)), rep(c(1:10),2), c(as.numeric(plot2_kmeans$data$y) , 
                                                                               as.numeric(plot2_pam$data$y)) )

colnames(x) <- c("Metoda", "Liczba klastrów k", "Silhouette")

pplotKMPAM2 <- ggplot(x, aes(x=`Liczba klastrów k`, y=Silhouette, color =`Metoda`))+
  geom_point()+
  geom_line()+
  scale_x_continuous( breaks = c(2,4,6,8,10))+
  ggtitle("Zmienne WP")+
  theme(plot.title = element_text(hjust = 0.5)) 
#----------------------------------------------------------------------------------
x <- cbind.data.frame( c(rep("Kmeans", 10), rep("PAM", 10)), rep(c(1:10),2), c(as.numeric(plot3_kmeans$data$y) , 
                                                                               as.numeric(plot3_pam$data$y)) )

colnames(x) <- c("Metoda", "Liczba klastrów k", "Silhouette")

pplotKMPAM3 <- ggplot(x, aes(x=`Liczba klastrów k`, y=Silhouette, color =`Metoda`))+
  geom_point()+
  geom_line()+
  scale_x_continuous( breaks = c(2,4,6,8,10))+
  ggtitle("5 zmiennych")+
  theme(plot.title = element_text(hjust = 0.5)) 
#----------------------------------------------------------------------------------
x <- cbind.data.frame( c(rep("Kmeans", 10), rep("PAM", 10)), rep(c(1:10),2), c(as.numeric(plot4_kmeans$data$y) , 
                                                                               as.numeric(plot4_pam$data$y)) )

colnames(x) <- c("Metoda", "Liczba klastrów k", "Silhouette")

pplotKMPAM4 <- ggplot(x, aes(x=`Liczba klastrów k`, y=Silhouette, color =`Metoda`))+
  geom_point()+
  geom_line()+
  scale_x_continuous( breaks = c(2,4,6,8,10))+
  ggtitle("9 zmiennych")+
  theme(plot.title = element_text(hjust = 0.5)) 
#----------------------------------------------------------------------------------
x <- cbind.data.frame( c(rep("Kmeans", 10), rep("PAM", 10)), rep(c(1:10),2), c(as.numeric(plot5_kmeans$data$y) , 
                                                                               as.numeric(plot5_pam$data$y)) )

colnames(x) <- c("Metoda", "Liczba klastrów k", "Silhouette")

pplotKMPAM5 <- ggplot(x, aes(x=`Liczba klastrów k`, y=Silhouette, color =`Metoda`))+
  geom_point()+
  geom_line()+
  scale_x_continuous( breaks = c(2,4,6,8,10))+
  ggtitle("Zmienne numeryczne")+
  theme(plot.title = element_text(hjust = 0.5)) 

grid.arrange(pplotKMPAM1,pplotKMPAM2, pplotKMPAM3, pplotKMPAM4,pplotKMPAM5 , ncol=2)
@

Na rysunku powyżej, że obie metody zwracają podobne rezultaty jeśli chodzi o indeksy Silhouette'a, niezależnie od wyboru cech czy liczby klastrów. Jednakże widzimy, że dla zdecydowanej większości wypadków lepiej radzi sobie metoda $k-means$ lub obie metody zwracają prawie te same wyniki.

\par
Innymi miarami służącymi do oceny pogrupowania obiektów są wskaźnik Dunn'a \cite{Dunn} i wskaźnik Connectivity. Oba wskaźniki zawsze są nieujemne, różnica polega na tym, że dla wskaźnika Dunn'a im większa wartość, tym lepiej, a dla Connectivity, im mniejsza wartość tym lepiej. W celu obliczeń tych wskaźników posłużyliśmy się funkcjami \texttt{dunn} oraz \texttt{connectivity} z pakietu \textbf{clValid}. Ponadto, w przypadku wskaźnika Connectivity trzeba określić liczbę najbliższych sąsiadów, którą chcemy uwzględnić. W naszym wypadku będzie to $L=10$. Na rysunkach \ref{fig:DI_plot} i \ref{fig:Conn_plot} przedstawione zostały porównania odpowiednio wskaźników Dunn'a oraz Connectivity dla metod $k-means$ i $PAM$ dla podzbiorów zmiennych numerycznych. Więcej o algorytmie $DBSCAN$ tutaj: \cite{DBSCAN}.

<<DI_Conn_loop, eval=TRUE, echo=FALSE, cache=TRUE>>=
#macierze odmienności dla PAM
DM_feat_1 <- daisy(data_num_clust_features[,c("horsepower", "highway.mpg")])
DM_feat_2 <- daisy(data_num_clust_features[,c("wheel.base","price")])
DM_feat_3 <- daisy(data_num_clust_features[,c("wheel.base","height", "length", "normalized.losses", "curb.weight")])
DM_feat_4 <- daisy(data_num_clust_features[,c("wheel.base","height", "length", "normalized.losses", "curb.weight", "bore",
                                              "highway.mpg", "city.mpg", "horsepower")])
DM_feat_5 <- daisy(data_num_clust_features)


DI_km_feat_1<-c()
DI_PAM_feat_1<-c()
conn_km_feat_1<-c()
conn_PAM_feat_1<-c()

DI_km_feat_2<-c()
DI_PAM_feat_2<-c()
conn_km_feat_2<-c()
conn_PAM_feat_2<-c()

DI_km_feat_3<-c()
DI_PAM_feat_3<-c()
conn_km_feat_3<-c()
conn_PAM_feat_3<-c()

DI_km_feat_4<-c()
DI_PAM_feat_4<-c()
conn_km_feat_4<-c()
conn_PAM_feat_4<-c()

DI_km_feat_5<-c()
DI_PAM_feat_5<-c()
conn_km_feat_5<-c()
conn_PAM_feat_5<-c()

for (k in 2:10){
  
#PAM ma stałe rezultaty
  pam.k <- pam(x=DM_feat_1, diss=TRUE,k=k)
  DI <- dunn(clusters=pam.k$clustering , Data = data_num_clust_features[,c("horsepower", "highway.mpg")], method = "euclidean")
  conn <- clValid::connectivity(clusters=pam.k$clustering , Data = data_num_clust_features[,c("horsepower", "highway.mpg")], 
                                method = "euclidean")
  
  DI_PAM_feat_1 <- c(DI_PAM_feat_1, DI)
  conn_PAM_feat_1 <- c(conn_PAM_feat_1, conn)
  
  pam.k <- pam(x=DM_feat_2, diss=TRUE,k=k)
  DI <- dunn(clusters=pam.k$clustering , Data = data_num_clust_features[,c("wheel.base","price")], method = "euclidean")
  conn <- clValid::connectivity(clusters=pam.k$clustering , Data = data_num_clust_features[,c("wheel.base","price")], 
                                method = "euclidean")
  
  DI_PAM_feat_2 <- c(DI_PAM_feat_2, DI)
  conn_PAM_feat_2 <- c(conn_PAM_feat_2, conn)
  
  pam.k <- pam(x=DM_feat_3, diss=TRUE,k=k)
  DI <- dunn(clusters=pam.k$clustering , Data = data_num_clust_features[,c("wheel.base","height", "length", "normalized.losses", "curb.weight")], method = "euclidean")
  conn <- clValid::connectivity(clusters=pam.k$clustering , Data = data_num_clust_features[,c("wheel.base","height", "length", "normalized.losses", "curb.weight")], 
                                method = "euclidean")
  
  DI_PAM_feat_3 <- c(DI_PAM_feat_3, DI)
  conn_PAM_feat_3 <- c(conn_PAM_feat_3, conn)
  
  pam.k <- pam(x=DM_feat_4, diss=TRUE,k=k)
  DI <- dunn(clusters=pam.k$clustering , Data = data_num_clust_features[,c("wheel.base","height", "length", "normalized.losses", "curb.weight", "bore",
                                                                           "highway.mpg", "city.mpg", "horsepower")], method = "euclidean")
  conn <- clValid::connectivity(clusters=pam.k$clustering , Data = data_num_clust_features[,c("wheel.base","height", "length", "normalized.losses", "curb.weight", "bore",
                                                                                    "highway.mpg", "city.mpg", "horsepower")], 
                                method = "euclidean")
  
  DI_PAM_feat_4 <- c(DI_PAM_feat_4, DI)
  conn_PAM_feat_4 <- c(conn_PAM_feat_4, conn)
  
  pam.k <- pam(x=DM_feat_5, diss=TRUE,k=k)
  DI <- dunn(clusters=pam.k$clustering , Data = data_num_clust_features, method = "euclidean")
  conn <- clValid::connectivity(clusters=pam.k$clustering , Data = data_num_clust_features, 
                                method = "euclidean")
  
  DI_PAM_feat_5 <- c(DI_PAM_feat_5, DI)
  conn_PAM_feat_5 <- c(conn_PAM_feat_5, conn)
  
  #kmeans uśredniamy, ponieważ wyniki zależą od punktów startowych
  DI_vec_km_feat_1<-c()
  conn_vec_km_feat_1<-c()
  DI_vec_km_feat_2<-c()
  conn_vec_km_feat_2<-c()
  DI_vec_km_feat_3<-c()
  conn_vec_km_feat_3<-c()
  DI_vec_km_feat_4<-c()
  conn_vec_km_feat_4<-c()
  DI_vec_km_feat_5<-c()
  conn_vec_km_feat_5<-c()
  for (i in 1:10){
    kmeans.k <- kmeans(data_num_clust_features[,c("horsepower", "highway.mpg")],centers=k,iter.max=15, nstart=10)
    DI <- dunn(clusters=kmeans.k$cluster , Data = data_num_clust_features[,c("horsepower", "highway.mpg")], method = "euclidean")

    conn <- clValid::connectivity(clusters=kmeans.k$cluster , Data = data_num_clust_features[,c("horsepower", "highway.mpg")], 
                method = "euclidean")
    
    DI_vec_km_feat_1 <- append(DI_vec_km_feat_1, DI)
    conn_vec_km_feat_1 <- append(conn_vec_km_feat_1, conn)
    
    kmeans.k <- kmeans(data_num_clust_features[,c("wheel.base","price")],centers=k,iter.max=15, nstart=10)
    DI <- dunn(clusters=kmeans.k$cluster , Data = data_num_clust_features[,c("wheel.base","price")], method = "euclidean")
    
    conn <- clValid::connectivity(clusters=kmeans.k$cluster , Data = data_num_clust_features[,c("wheel.base","price")], 
                                  method = "euclidean")
    
    DI_vec_km_feat_2 <- append(DI_vec_km_feat_2, DI)
    conn_vec_km_feat_2 <- append(conn_vec_km_feat_2, conn)
    
    kmeans.k <- kmeans(data_num_clust_features[,c("wheel.base","height", "length", "normalized.losses", "curb.weight", "bore",
                                                  "highway.mpg", "city.mpg", "horsepower")],centers=k,iter.max=15, nstart=10)
    DI <- dunn(clusters=kmeans.k$cluster , Data = data_num_clust_features[,c("wheel.base","height", "length", "normalized.losses", "curb.weight", "bore",
                                                                             "highway.mpg", "city.mpg", "horsepower")], method = "euclidean")
    
    conn <- clValid::connectivity(clusters=kmeans.k$cluster , Data = data_num_clust_features[,c("wheel.base","height", "length", "normalized.losses", "curb.weight", "bore",
                                                                                                "highway.mpg", "city.mpg", "horsepower")], 
                                  method = "euclidean")
    
    DI_vec_km_feat_3 <- append(DI_vec_km_feat_3, DI)
    conn_vec_km_feat_3 <- append(conn_vec_km_feat_3, conn)
    
    kmeans.k <- kmeans(data_num_clust_features[,c("wheel.base","height", "length", "normalized.losses", "curb.weight", "bore",
                                                  "highway.mpg", "city.mpg", "horsepower")],centers=k,iter.max=15, nstart=10)
    DI <- dunn(clusters=kmeans.k$cluster , Data = data_num_clust_features[,c("wheel.base","height", "length", "normalized.losses", "curb.weight", "bore",
                                                                             "highway.mpg", "city.mpg", "horsepower")], method = "euclidean")
    
    conn <- clValid::connectivity(clusters=kmeans.k$cluster , Data = data_num_clust_features[,c("wheel.base","height", "length", "normalized.losses", "curb.weight", "bore",
                                                                                                "highway.mpg", "city.mpg", "horsepower")], 
                                  method = "euclidean")
    
    DI_vec_km_feat_4 <- append(DI_vec_km_feat_4, DI)
    conn_vec_km_feat_4 <- append(conn_vec_km_feat_4, conn)
    
    kmeans.k <- kmeans(data_num_clust_features,centers=k,iter.max=15, nstart=10)
    DI <- dunn(clusters=kmeans.k$cluster , Data = data_num_clust_features, method = "euclidean")
    
    conn <- clValid::connectivity(clusters=kmeans.k$cluster , Data = data_num_clust_features, 
                                  method = "euclidean")
    
    DI_vec_km_feat_5 <- append(DI_vec_km_feat_5, DI)
    conn_vec_km_feat_5 <- append(conn_vec_km_feat_5, conn)
    
    
    
}
  DI_km_feat_1 <- c(DI_km_feat_1, mean(DI_vec_km_feat_1))
  conn_km_feat_1 <- c(conn_km_feat_1, mean(conn_vec_km_feat_1))
  
  DI_km_feat_2 <- c(DI_km_feat_2, mean(DI_vec_km_feat_2))
  conn_km_feat_2 <- c(conn_km_feat_2, mean(conn_vec_km_feat_2))
  
  DI_km_feat_3 <- c(DI_km_feat_3, mean(DI_vec_km_feat_3))
  conn_km_feat_3 <- c(conn_km_feat_3, mean(conn_vec_km_feat_3))
  
  DI_km_feat_4 <- c(DI_km_feat_4, mean(DI_vec_km_feat_4))
  conn_km_feat_4 <- c(conn_km_feat_4, mean(conn_vec_km_feat_4))
  
  DI_km_feat_5 <- c(DI_km_feat_5, mean(DI_vec_km_feat_5))
  conn_km_feat_5 <- c(conn_km_feat_5, mean(conn_vec_km_feat_5))
}
@

<<DI_plot, eval=TRUE, echo=FALSE,fig.width=6 ,cache=TRUE,fig.cap="Porównanie wartości indeksu Dunna">>=
y_min <- min(c(DI_km_feat_1, DI_km_feat_2,DI_km_feat_3, DI_km_feat_4,DI_km_feat_5,DI_PAM_feat_1, DI_PAM_feat_2,
              DI_PAM_feat_3, DI_PAM_feat_4,DI_PAM_feat_5))
y_max <- max(c(DI_km_feat_1, DI_km_feat_2,DI_km_feat_3, DI_km_feat_4,DI_km_feat_5,DI_PAM_feat_1, DI_PAM_feat_2,
               DI_PAM_feat_3, DI_PAM_feat_4,DI_PAM_feat_5))

x<-cbind.data.frame( rep(2:10,5), c(rep("HH", 9), rep("WP", 9), rep("5 zmiennych", 9),
                                    rep("9 zmiennych", 9), rep("Zmienne ilościowe", 9)), c(DI_km_feat_1, DI_km_feat_2,
                                                                                 DI_km_feat_3, DI_km_feat_4,DI_km_feat_5)  )
colnames(x) <- c( "Liczba klastrów k", "Podzbiór cech","Indeks Dunna")

plot_DI_km <- ggplot(x, aes(x=`Liczba klastrów k`, y=`Indeks Dunna`, color =`Podzbiór cech`))+
  geom_point()+
  geom_line()+
  scale_x_continuous( breaks = c(2,4,6,8,10))+
  ggtitle("Porównanie indeksów Dunna \n dla k-means")+
  theme(plot.title = element_text(hjust = 0.5),legend.position="bottom")+  #wyśrodkowanie głównego tytułu
  ylim(y_min, y_max)+
  guides(color = guide_legend(nrow = 5))


x<-cbind.data.frame( rep(2:10,5), c(rep("HH", 9), rep("WP", 9), rep("5 zmiennych", 9),
                                    rep("9 zmiennych", 9), rep("Zmienne ilościowe", 9)), c(DI_PAM_feat_1, DI_PAM_feat_2,
                                                                                            DI_PAM_feat_3, DI_PAM_feat_4,DI_PAM_feat_5)  )
colnames(x) <- c( "Liczba klastrów k", "Podzbiór cech","Indeks Dunna")

plot_DI_PAM <- ggplot(x, aes(x=`Liczba klastrów k`, y=`Indeks Dunna`, color =`Podzbiór cech`))+
  geom_point()+
  geom_line()+
  scale_x_continuous( breaks = c(2,4,6,8,10))+
  ggtitle("Porównanie indeksów Dunna \n dla PAM")+
  theme(plot.title = element_text(hjust = 0.5),legend.position="bottom")+  #wyśrodkowanie głównego tytułu
  ylim(y_min, y_max)+
  guides(color = guide_legend(nrow = 5))

grid.arrange(plot_DI_km, plot_DI_PAM, ncol=2)

@

<<Conn_plot, eval=TRUE, echo=FALSE,fig.width=6 ,cache=TRUE,fig.cap="Porównanie wartości wskaźnika connectivity">>=
y_min <- min(c(conn_km_feat_1, conn_km_feat_2, conn_km_feat_3, conn_km_feat_4,conn_km_feat_5, conn_PAM_feat_1, conn_PAM_feat_2,
               conn_PAM_feat_3, conn_PAM_feat_4,conn_PAM_feat_5) )
y_max <- max(c(conn_km_feat_1, conn_km_feat_2, conn_km_feat_3, conn_km_feat_4,conn_km_feat_5, conn_PAM_feat_1, conn_PAM_feat_2,
               conn_PAM_feat_3, conn_PAM_feat_4,conn_PAM_feat_5) )

x<-cbind.data.frame( rep(2:10,5), c(rep("HH", 9), rep("WP", 9), rep("5 zmiennych", 9),
                                    rep("9 zmiennych", 9), rep("Zmienne ilościowe", 9)), c(conn_km_feat_1, conn_km_feat_2,
                                                                                            conn_km_feat_3, conn_km_feat_4,conn_km_feat_5)  )
colnames(x) <- c( "Liczba klastrów k", "Podzbiór cech","Connectivity")

plot_conn_km <- ggplot(x, aes(x=`Liczba klastrów k`, y=`Connectivity`, color =`Podzbiór cech`))+
  geom_point()+
  geom_line()+
  scale_x_continuous( breaks = c(2,4,6,8,10))+
  ggtitle("Porównanie connectivity \n dla k-means")+
  theme(plot.title = element_text(hjust = 0.5),legend.position="bottom")+  #wyśrodkowanie głównego tytułu
  ylim(y_min, y_max)+
  guides(color = guide_legend(nrow = 5))


x<-cbind.data.frame( rep(2:10,5), c(rep("HH", 9), rep("WP", 9), rep("5 zmiennych", 9),
                                    rep("9 zmiennych", 9), rep("Zmienne ilościowe", 9)), c(conn_PAM_feat_1, conn_PAM_feat_2,
                                                                                            conn_PAM_feat_3, conn_PAM_feat_4,conn_PAM_feat_5)  )
colnames(x) <- c( "Liczba klastrów k", "Podzbiór cech","Connectivity")

plot_conn_PAM <- ggplot(x, aes(x=`Liczba klastrów k`, y=`Connectivity`, color =`Podzbiór cech`))+
  geom_point()+
  geom_line()+
  scale_x_continuous( breaks = c(2,4,6,8,10))+
  ggtitle("Porównanie connectivity \n dla PAM")+
  theme(plot.title = element_text(hjust = 0.5),legend.position="bottom")+  #wyśrodkowanie głównego tytułu
  ylim(y_min, y_max)+
  guides(color = guide_legend(nrow = 5))

grid.arrange(plot_conn_km, plot_conn_PAM, ncol=2)

@

Z rysunków powyżej najważniejszym wnioskiem, niezależnie od interpretacji wartości liczbowych obu wskaźników, które moga się różnić, jest to, że obie metody wypadają kiepsko biorąc pod uwagę te wskaźniki. Widzimy, że dla wskaźnika Dunn'a największą możliwą wartością, którą otrzymaliśmy jest nieco ponad $0.15$, a przypomnijmy, że im większe wartości tym lepiej. Z kolei dla wskaźnika Connectivity otrzymaliśmy duże wartości z minimalną wartością na poziomie ok. $5$, a zdecydowana większośc wartości jest większa od $30$. Ponadto, przy wskaźniku Connectivity możemy jednoznacznie roztrzygnąć, że najlepiej wypadł podzbiór $HH$ czyli zmienne \texttt{horsepower} i \texttt{highway.mpg}.

\subsection{Algorytm DBSCAN}

Kolejną metodą klastrowania, której użyliśmy, jest algorytm $DBSCAN$ (ang. Density-Based Spatial Clustering of Applications with Noise). Jest to jedna z metod grupowania gęstościowego, które nieco różnią się od metod grupujących. Przede wszystkim metody grupowania gęstościowego nie potrzebują mieć z góry nadanej liczby klastrów $k$. Poza tym, są bardziej efektywne w przypadku identyfikacji wartości odstających. Warto dodać, że z racji charakteru algorytmu, oczywiście możemy używać tylko zmiennych ilościowych.
\par
Dla algorytmu $DBSCAN$ musimy ustalić $2$ wejściowe wartości: $\epsilon$ oraz $MinPts$. Należy podkreślić, że jedną z wad metody jest duża wrażliwość na wybór $\epsilon$, szczególnosci w przypadku, gdy poszczególne skupienia maja różną gęstość. Do implementacji algorytmu w \textbf{R} użyliśmy funkcji \texttt{dbscan} z pakietu
\textbf{dbscan}. Poniżej na rysunkach \ref{fig:plot_DBSCAN_CE}, \ref{fig:plot_DBSCAN_WL}, \ref{fig:plot_DBSCAN_CH} i \ref{fig:plot_DBSCAN_CC} przedstawiliśmy wykresy punktowe dla różnych par zmiennych numerycznych z zaimplementowanym algorytmem $DBSCAN$ dla różnych wartości parametrów $\epsilon$ oraz $MinPts$.

<<plot_DBSCAN_CE, eval=TRUE, echo=FALSE,fig.width=7 ,cache=TRUE,fig.cap="Porównanie działania algorytmu DBSCAN dla różnych parametrów eps oraz minPts dla zmiennych city.mpg i enginze.size">>=
part.dbscan <- dbscan::dbscan(data_num_clust_features[, c("city.mpg", "engine.size")], 
                              eps = 0.25, minPts = 5)
plot_DBSCAN_CE_1 <- ggplot()+
  geom_point(data_num_clust_features, mapping=aes(x=city.mpg, y=engine.size), colour=part.dbscan$cluster+1)+
  ggtitle("eps = 0.25, minPts = 5")


part.dbscan <- dbscan::dbscan(data_num_clust_features[, c("city.mpg", "engine.size")], 
                              eps = 0.25, minPts = 10)
plot_DBSCAN_CE_2 <- ggplot()+
  geom_point(data_num_clust_features, mapping=aes(x=city.mpg, y=engine.size), colour=part.dbscan$cluster+1)+
  ggtitle("eps = 0.25, minPts = 10")


part.dbscan <- dbscan::dbscan(data_num_clust_features[, c("city.mpg", "engine.size")], 
                              eps = 0.45, minPts = 10)
plot_DBSCAN_CE_3 <- ggplot()+
  geom_point(data_num_clust_features, mapping=aes(x=city.mpg, y=engine.size), colour=part.dbscan$cluster+1)+
  ggtitle("eps = 0.45, minPts = 10")

part.dbscan <- dbscan::dbscan(data_num_clust_features[, c("city.mpg", "engine.size")], 
                              eps = 0.45, minPts = 5)
plot_DBSCAN_CE_4 <- ggplot()+
  geom_point(data_num_clust_features, mapping=aes(x=city.mpg, y=engine.size), colour=part.dbscan$cluster+1)+
  ggtitle("eps = 0.45, minPts = 5")
grid.arrange(plot_DBSCAN_CE_1, plot_DBSCAN_CE_2, plot_DBSCAN_CE_4, plot_DBSCAN_CE_3 , nrow=2, ncol=2)
@

<<plot_DBSCAN_WL, eval=TRUE, echo=FALSE,fig.width=7 ,cache=TRUE,fig.cap="Porównanie działania algorytmu DBSCAN dla różnych parametrów eps oraz minPts dla zmiennych wheel.base, length">>=
part.dbscan <- dbscan::dbscan(data_num_clust_features[, c("wheel.base", "length")], 
                              eps = 0.13, minPts = 5)
plot_DBSCAN_WL_1 <- ggplot()+
  geom_point(data_num_clust_features, mapping=aes(x=wheel.base, y=length), colour=part.dbscan$cluster+1)+
  ggtitle("eps = 0.13, minPts = 5")

part.dbscan <- dbscan::dbscan(data_num_clust_features[, c("wheel.base", "length")], 
                              eps = 0.13, minPts = 10)
plot_DBSCAN_WL_2 <- ggplot()+
  geom_point(data_num_clust_features, mapping=aes(x=wheel.base, y=length), colour=part.dbscan$cluster+1)+
  ggtitle("eps = 0.13, minPts = 10")


part.dbscan <- dbscan::dbscan(data_num_clust_features[, c("wheel.base", "length")], 
                              eps = 0.25, minPts = 10)
plot_DBSCAN_WL_3 <- ggplot()+
  geom_point(data_num_clust_features, mapping=aes(x=wheel.base, y=length), colour=part.dbscan$cluster+1)+
  ggtitle("eps = 0.23, minPts = 10")


part.dbscan <- dbscan::dbscan(data_num_clust_features[, c("wheel.base", "length")], 
                              eps = 0.45, minPts = 10)
plot_DBSCAN_WL_4 <- ggplot()+
  geom_point(data_num_clust_features, mapping=aes(x=wheel.base, y=length), colour=part.dbscan$cluster+1)+
  ggtitle("eps = 0.45, minPts = 10")
grid.arrange(plot_DBSCAN_WL_1, plot_DBSCAN_WL_2, plot_DBSCAN_WL_3, plot_DBSCAN_WL_4 , nrow=2, ncol=2)
@

<<plot_DBSCAN_CH, eval=TRUE, echo=FALSE,fig.width=7 ,cache=TRUE,fig.cap="Porównanie działania algorytmu DBSCAN dla różnych parametrów eps oraz minPts dla zmiennych compression.ratio, horsepower">>=
part.dbscan <- dbscan::dbscan(data_num_clust_features[, c("compression.ratio", "horsepower")], 
                              eps = 0.13, minPts = 10)
plot_DBSCAN_CH_1 <- ggplot()+
  geom_point(data_num_clust_features, mapping=aes(x=compression.ratio, y=horsepower), colour=part.dbscan$cluster+1)+
  ggtitle("eps = 0.13, minPts = 10")


part.dbscan <- dbscan::dbscan(data_num_clust_features[, c("compression.ratio", "horsepower")], 
                              eps = 0.13, minPts = 5)
plot_DBSCAN_CH_2 <- ggplot()+
  geom_point(data_num_clust_features, mapping=aes(x=compression.ratio, y=horsepower), colour=part.dbscan$cluster+1)+
  ggtitle("eps = 0.13, minPts = 5")

part.dbscan <- dbscan::dbscan(data_num_clust_features[, c("compression.ratio", "horsepower")], 
                              eps = 0.23, minPts = 5)
plot_DBSCAN_CH_3 <- ggplot()+
  geom_point(data_num_clust_features, mapping=aes(x=compression.ratio, y=horsepower), colour=part.dbscan$cluster+1)+
  ggtitle("eps = 0.23, minPts = 5")


part.dbscan <- dbscan::dbscan(data_num_clust_features[, c("compression.ratio", "horsepower")], 
                              eps = 0.5, minPts = 5)
plot_DBSCAN_CH_4 <- ggplot()+
  geom_point(data_num_clust_features, mapping=aes(x=compression.ratio, y=horsepower), colour=part.dbscan$cluster+1)+
  ggtitle("eps = 0.5, minPts = 5")
grid.arrange(plot_DBSCAN_CH_1, plot_DBSCAN_CH_2, plot_DBSCAN_CH_3, plot_DBSCAN_CH_4 , nrow=2, ncol=2)
@

<<plot_DBSCAN_CC, eval=TRUE, echo=FALSE,fig.width=7 ,cache=TRUE,fig.cap="Porównanie działania algorytmu DBSCAN dla różnych parametrów eps oraz minPts dla zmiennych compression.ratio, curb.weight">>=
part.dbscan <- dbscan::dbscan(data_num_clust_features[, c("compression.ratio", "curb.weight")], 
                              eps = 0.13, minPts = 10)

plot_DBSCAN_CC_1 <- ggplot()+
  geom_point(data_num_clust_features, mapping=aes(x=compression.ratio, y=curb.weight), colour=part.dbscan$cluster+1)+
  ggtitle("eps = 0.13, minPts = 10")

part.dbscan <- dbscan::dbscan(data_num_clust_features[, c("compression.ratio", "curb.weight")], 
                              eps = 0.13, minPts = 5)

plot_DBSCAN_CC_2 <- ggplot()+
  geom_point(data_num_clust_features, mapping=aes(x=compression.ratio, y=curb.weight), colour=part.dbscan$cluster+1)+
  ggtitle("eps = 0.13, minPts = 5")

part.dbscan <- dbscan::dbscan(data_num_clust_features[, c("compression.ratio", "curb.weight")], 
                              eps = 0.21, minPts = 5)

plot_DBSCAN_CC_3 <- ggplot()+
  geom_point(data_num_clust_features, mapping=aes(x=compression.ratio, y=curb.weight), colour=part.dbscan$cluster+1)+
  ggtitle("eps = 0.21, minPts = 5")


part.dbscan <- dbscan::dbscan(data_num_clust_features[, c("compression.ratio", "curb.weight")], 
                              eps = 0.5, minPts = 5)

plot_DBSCAN_CC_4 <- ggplot()+
  geom_point(data_num_clust_features, mapping=aes(x=compression.ratio, y=curb.weight), colour=part.dbscan$cluster+1)+
  ggtitle("eps = 0.5, minPts = 5")

grid.arrange(plot_DBSCAN_CC_1, plot_DBSCAN_CC_2, plot_DBSCAN_CC_3, plot_DBSCAN_CC_4 , nrow=2, ncol=2)

@

Jak możemy zaobserwować na rysunkach powyżej, nie otrzymaliśmy satysfakcjonujących rezultatów dla algorytmu $DBSCAN$ dla wybranych par zmiennych, niezależnie od wybranych wartości $\epsilon$ i $minPts$. Prawdopobnie przez bardzo niejednorodną gęstość obserwacji. Oceniając tylko wizualnie, najlepsze wyniki otrzymaliśmy na ostatnim rysunku dla zmiennych \texttt{compression.ratio} i \texttt{curb.weight} dla $\epsilon = 0.5$ i $minPts = 5$.


\subsection{Metody hierarchiczne}

Następnym typem metod których użyliśmy, są metody hierarchiczne. Ich główną ideą jest przedstawienie rezultatów w postaci hierarchii zagnieżdżonych skupień czyli tzw. dendrogramów, podobnie jak w przypadku metod grupowania gęstościowego, tutaj również nie podajemy ustalonej z góry liczb klastrów $k$ na który dzielimy nasz zbiór obiektów, a wyboru dotyczącego tejże liczby dokonujemy po analizie wyników.


\subsubsection{AGNES}
Algorytm $AGNES$ jest przykładem metody aglomeracyjnej w których to na początku każdy obiekt stanowi osobne skupienie, a w następnych krokach najbliższe sobie skupienia są łączone, aż do momentu kiedy uzyskamy jedno skupienie zawierające wszystkie obiekty. Na wejściu algorytm $AGNES$ otrzymuje macierz odmienności, co z kolei sprawia, że możemy wziąć pod uwagę zarówno zmienne ilościowe jak i jakościowe, oraz oczywiście dane mieszanego typu.
\par I właśnie macierzami odmienności zajmiemy się na samym początku, a konkretnie ich wizualizacją. Co prawda, już wcześniej przy metodzie $PAM$ zostały dodane takie rysunki, ale tutaj do naszych heatmap dodamy także dendrogramy oraz faktyczne etykietki zmiennej objaśnianej \texttt{symboling} (warto dodać, że korzystamy w końcu z naszej kosntrukcji zmiennej \texttt{symboling} z $2$ kategoriami). Przedstawione zostały one na rysunkach \ref{fig:plot_Heatmap_1}, \ref{fig:plot_Heatmap_2}, \ref{fig:plot_Heatmap_3} i \ref{fig:plot_Heatmap_4}. Do ich stworzenia użyliśmy funkcji \texttt{heatmap.2} \cite{heatmap2} z pakietu \textbf{gplots}. 



<<AGNES_1, eval=TRUE, echo=FALSE,fig.width=7 ,cache=TRUE,fig.cap="Porównanie działania algorytmu DBSCAN dla różnych parametrów eps oraz minPts">>=
DM_num <- daisy(data_num_clust_features)
DM_num_matrix <- as.matrix(DM_num)

DM_num_UNSCALED <- daisy(data_num_clust_features_UNSCALED)
DM_num_matrix_UNSCALED <- as.matrix(DM_num_UNSCALED)

DM <- daisy(data_clust_features)  #odległość Gowera wybrane automatycznie, jeśli wykryje kolumny nienumeryczne
DM_matrix <- as.matrix(DM)

agnes.avg_num <- agnes(DM_num_matrix,diss=TRUE, method="average")
agnes.single_num <- agnes(DM_num_matrix,diss=TRUE, method="single")
agnes.complete_num <- agnes(DM_num_matrix,diss=TRUE, method="complete")

@

<<AGNES_all, eval=TRUE, echo=FALSE, cache=TRUE>>=
agnes.avg_all <- agnes(DM_matrix,diss=TRUE, method="average")
agnes.single_all <- agnes(DM_matrix,diss=TRUE, method="single")
agnes.complete_all <- agnes(DM_matrix,diss=TRUE, method="complete")
@


<<plot_Heatmap_1, eval=TRUE, echo=FALSE, cache=TRUE, fig.width=6, fig.height=3.5,  warning=FALSE,fig.cap="Heatmapa dla macierzy odmienności uwzględniającej zmienne numeryczne">>=
kolory.obiektow <- rainbow(5)
symboling <- as.numeric(data_clust$symboling)

heatmap.2(DM_num_matrix, 
          RowSideColors = kolory.obiektow[symboling],  
          col = greenred(20), # paleta kolorów
          density.info = "none", 
          trace = "none", 
          scale = "none",
          dendrogram = "row",
          srtCol = 45,         # kąt nachylenia etykietek kolumn
          margins = c(1.8, 8.5),   # marginesy (dolny i prawy)
          lhei = c(5, 8),      # względna wysokość wierszy
          main="symboling"
) 
legend("top", levels(data_clust$symboling), fill = kolory.obiektow, cex = 0.7, horiz =TRUE)
@

<<plot_Heatmap_2, eval=TRUE, echo=FALSE, cache=TRUE, fig.width=6, fig.height=3.5,  warning=FALSE,fig.cap="Heatmapa dla macierzy odmienności uwzględniającej wszystkie zmienne">>=
heatmap.2(DM_matrix, 
          RowSideColors = kolory.obiektow[symboling],  
          col = greenred(20), # paleta kolorów
          density.info = "none", 
          trace = "none", 
          scale = "none",
          dendrogram = "row",
          srtCol = 45,         # kąt nachylenia etykietek kolumn
          margins = c(1.8, 8.5),   # marginesy (dolny i prawy)
          lhei = c(5, 8),      # względna wysokość wierszy
          main="symboling"
) 
legend("top", levels(data_clust$symboling), fill = kolory.obiektow, cex = 0.7, horiz =TRUE)
@

<<plot_Heatmap_3, eval=TRUE, echo=FALSE, cache=TRUE, fig.width=6, fig.height=3.5,  warning=FALSE,fig.cap="Heatmapa dla macierzy odmienności uwzględniającej zmienne numeryczne (zmienna symboling sprowadzona do 2 kategorii)">>=
#________________________________
kolory.obiektow <- rainbow(2)

obiekty.kolory <- symboling_custom
obiekty.kolory[which(symboling_custom=="-1 or 0")] <- 1
obiekty.kolory[which(symboling_custom=="1 , 2 or 3")] <-2
obiekty.kolory <- as.numeric(obiekty.kolory)

symboling <- symboling_custom
heatmap.2(DM_num_matrix, 
          RowSideColors = kolory.obiektow[obiekty.kolory],  
          col = greenred(20), # paleta kolorów
          density.info = "none", 
          trace = "none", 
          scale = "none",
          dendrogram = "row",
          srtCol = 45,         # kąt nachylenia etykietek kolumn
          margins = c(1.8, 8.5),   # marginesy (dolny i prawy)
          lhei = c(5, 8),      # względna wysokość wierszy
          main="symboling"
) 
legend("top", levels(as.factor(symboling_custom)), fill = kolory.obiektow, cex = 0.7, horiz =TRUE)

@

<<plot_Heatmap_4, eval=TRUE, echo=FALSE, cache=TRUE, fig.width=6, fig.height=3.5,  warning=FALSE,fig.cap="Heatmapa dla macierzy odmienności uwzględniającej wszystkie zmienne (zmienna symboling sprowadzona do 2 kategorii)">>=
heatmap.2(DM_matrix, 
          RowSideColors = kolory.obiektow[obiekty.kolory],  
          col = greenred(20), # paleta kolorów
          density.info = "none", 
          trace = "none", 
          scale = "none",
          dendrogram = "row",
          srtCol = 45,         # kąt nachylenia etykietek kolumn
          margins = c(1.8, 8.5),   # marginesy (dolny i prawy)
          lhei = c(5, 8),      # względna wysokość wierszy
          main="symboling"
) 
legend("top", levels(as.factor(symboling_custom)), fill = kolory.obiektow, cex = 0.7, horiz =TRUE)
@

Na podstawie powyższych rysunków, możemy stwierdzić, że otrzymane hierachie zagnieżdżonych skupień kiepsko odwzorowują rzeczywiste kategorie zmiennej \texttt{symboling}.
\par Ważną informacją przy ocenie jakości otrzymanej struktury jest współczynnik aglomeracyjny ($AC$). Im bliżej wartość jest $1$, tym bardziej istotny jest otrzymany podział. Dla każdego obiektu $i$ wyznaczamy $m(i)$, czyli odmienność do pierwszego skupienia, z którym została połączona, a następnie dzielimy ją przed odmienność od skupienia dołączonego w ostatnim kroku algorytmu. Wartość $AC$ to średnia ze wszystkich wartości $1-m(i)$

\par Bardzo ważną sprawą dotyczącą metody $AGNES$ jest wybór metody łączenia klastrów. Istnieją $3$ różne typy takich łączeń:
\begin{itemize}
\item Odległość najbliższego sąsiada (ang. simple linkage)
\item Odległość najdalszego sąsiada (ang. complete linkage)
\item Odległość średnia (ang. average linkage)
\end{itemize}
Ale nie są to jedyne metody. Najpopularniejszą z pozostałych jest prawdopodobnie metoda Warda. Więcej o metodach łączenia klastrów możemy znaleźć tutaj \cite{linkage}.
\par Żeby zwizualizować jak ważny jest wybór metody łączenia klastrów poniżej na rysunkach \ref{fig:plot_AGNES_1.2}, \ref{fig:plot_AGNES_2}, \ref{fig:plot_AGNES_3} przedstawione zostały dentrogramy metody $AGNES$ uzytej na zmiennych ilościowych dla odpowiednio \texttt{average linkage}, \texttt{simple linkage} i \texttt{complete linkage}. Do ich stworzenia użyliśmy funckji \texttt{agnes} \cite{agnes} z pakietu \textbf{cluster}, a następnie funkcji \texttt{fviz dend} \cite{fvizdend} z pakietu \textbf{factoextra} Oprócz tego dla każdego z typów łączeń wyświetlony został także współczynnik $AC$.

<<plot_AGNES_1.2, eval=TRUE, echo=FALSE, cache=TRUE, fig.width=7, fig.height=4, warning=FALSE,fig.cap="dendrogram dla metody AGNES dla zmiennych ilościowych z wykorzystaniem average linkage">>=
print(paste("Współczynnik AC dla metody łączenia average linkage wynosi:", round(agnes.avg_num$ac,2)))
fviz_dend(agnes.avg_num, lwd = 0.3 ,cex = 0.2, ,main="AGNES - average linkage")+
  theme(plot.title = element_text(hjust = 0.5))
@

\newpage

<<plot_AGNES_2, eval=TRUE, echo=FALSE, fig.width=7, fig.height=4,cache=TRUE, warning=FALSE,fig.cap="dendrogram dla metody AGNES dla zmiennych ilościowych z wykorzystaniem single linkage">>=
print(paste("Współczynnik AC dla metody łączenia single linkage wynosi:", round(agnes.single_num$ac,2)))
fviz_dend(agnes.single_num, lwd = 0.3 ,cex = 0.2, ,main="AGNES - simple linkage")+
  theme(plot.title = element_text(hjust = 0.5))
@

<<plot_AGNES_3, eval=TRUE, echo=FALSE,fig.width=7, fig.height=4,cache=TRUE, warning=FALSE,fig.cap="dendrogram dla metody AGNES dla zmiennych ilościowych z wykorzystaniem complete linkage">>=
print(paste("Współczynnik AC dla metody łączenia complete linkage wynosi:", round(agnes.complete_num$ac,2)))
fviz_dend(agnes.complete_num, lwd = 0.3 ,cex = 0.2, ,main="AGNES - complete linkage")+
  theme(plot.title = element_text(hjust = 0.5))
@

Z $3$ powyższych rysunków, możemy wywnioskować, że najbardziej sensownym podziałem jest ten z pomocą metody łączenie \texttt{complete linkage}. Potwierdza to też najwyższa wartość współczynnika $AC$, właśnie dla tej metody, który jest równy $0.93$. I właśnie dendrogramów przy użyciu tej metody łączenia uzyjemy do porównania ze zmiennymi jakościowymi. Poniżej na rysunkach \ref{fig:plot_AGNES_Comparison_Symboling} i \ref{fig:plot_AGNES_Comparison_Symboling_2} przedstawione są dendrogramy dla metody AGNES ($complete linkage$) na podstawie zmiennych ilościowych z zaznaczonymi etykietkami zmiennej \texttt{symboling}.

<<plot_AGNES_Comparison_Symboling, eval=TRUE, echo=FALSE,fig.width=7, fig.height=4,cache=TRUE, warning=FALSE,fig.cap="dendrogram dla metody AGNES dla zmiennych ilościowych z zaznaczeniem różnych kategorii zmiennej symboling">>=
etykietki.kolory <- as.numeric(data_clust$symboling)  

obiekty.kolory <- etykietki.kolory[agnes.complete_num$order]
# dendrogram + kolory odpowiadające rzeczywistym klasom
fviz_dend(agnes.complete_num, cex=0.5, lwd = 0.4, label_cols=obiekty.kolory, main="AGNES z complete linkage - porównanie z kategoriami zmiennej symboling")
@

<<plot_AGNES_Comparison_Symboling_2, eval=TRUE, echo=FALSE,fig.width=7, fig.height=4,cache=TRUE, warning=FALSE,fig.cap="dendrogram dla metody AGNES dla zmiennych ilościowych z zaznaczeniem różnych kategorii zmiennej symboling (podział na 2 kategorie)">>=
obiekty.kolory <- symboling_custom
obiekty.kolory[which(symboling_custom=="-1 or 0")] <- 1
obiekty.kolory[which(symboling_custom=="1 , 2 or 3")] <-2
obiekty.kolory <- as.numeric(obiekty.kolory)

obiekty.kolory <- obiekty.kolory[agnes.complete_num$order]
# dendrogram + kolory odpowiadające rzeczywistym klasom
fviz_dend(agnes.complete_num, cex=0.5, lwd = 0.4, label_cols=obiekty.kolory, main="AGNES z complete linkage - \n porównanie z kategoriami zmiennej symboling (dwie kategorie)")
@

Poniżej na rysunkach \ref{fig:plot_AGNES_Comparison_Symboling_all} i \ref{fig:plot_AGNES_Comparison_Symboling_2_all} przedstawione są dendrogramy dla metody AGNES ($complete linkage$), tym razem na podstawie wszystkich zmiennych, także jakościowych (oczywiście oprócz zmiennej objaśnianej \texttt{symboling}) z zaznaczonymi etykietkami zmiennej \texttt{symboling}.

<<plot_AGNES_Comparison_Symboling_all, eval=TRUE, echo=FALSE, fig.width=7, fig.height=4, warning=FALSE, cache=TRUE,fig.cap="dendrogram dla metody AGNES dla wszystkich zmiennych z zaznaczeniem różnych kategorii zmiennej symboling">>=
etykietki.kolory <- as.numeric(data_clust$symboling)  

obiekty.kolory <- etykietki.kolory[agnes.complete_all$order]
# dendrogram + kolory odpowiadające rzeczywistym klasom
fviz_dend(agnes.complete_all, cex=0.5, lwd = 0.4, label_cols=obiekty.kolory, main="AGNES z complete linkage - porównanie z kategoriami zmiennej symboling")
@

<<plot_AGNES_Comparison_Symboling_2_all, eval=TRUE, echo=FALSE, cache=TRUE, fig.width=7, fig.height=4,warning=FALSE,fig.cap="dendrogram dla metody AGNES dla wszystkich zmiennych z zaznaczeniem różnych kategorii zmiennej symboling(podział na 2 kategorie)">>=
obiekty.kolory <- symboling_custom
obiekty.kolory[which(symboling_custom=="-1 or 0")] <- 1
obiekty.kolory[which(symboling_custom=="1 , 2 or 3")] <-2
obiekty.kolory <- as.numeric(obiekty.kolory)

obiekty.kolory <- obiekty.kolory[agnes.complete_all$order]
# dendrogram + kolory odpowiadające rzeczywistym klasom
fviz_dend(agnes.complete_all, cex=0.5, lwd = 0.4, label_cols=obiekty.kolory, main="AGNES z complete linkage - \n porównanie z kategoriami zmiennej symboling (dwie kategorie)")
@
Na $4$ powyższych rysunkach możemy zaobserwować, że niezależnie od użycia wszystkich zmiennych czy tylko ilościowych, zagnieżdżenia uzyskiwane metodą $AGNES$ nie odpowiadają wyraźnie jakiemuś podziałowi związanemu ze zmienną \texttt{symboling}


\par
Poniżej na rysunkach \ref{fig:plot_AGNES_Comparison_drive.wheels}, \ref{fig:plot_AGNES_Comparison_num.of.cylinders} i \ref{fig:plot_AGNES_Comparison_fuel.system}  przedstawione zostały dendrogramy uzyskane metodą $AGNES$ dla metody łączenia klastrów $complete linkage$, na podstawie zmiennych ilościowych, z porównaniem z różnymi innymi zmiennymi jakościowymi: \texttt{drive.wheels}, \texttt{num.of.cylinders} i \texttt{fuel.system}.

<<plot_AGNES_Comparison_drive.wheels, eval=TRUE, echo=FALSE,fig.width=7, fig.height=4,cache=TRUE, warning=FALSE,fig.cap="dendrogram dla metody AGNES dla zmiennych ilościowych z zaznaczeniem różnych kategorii zmiennej drive.wheels">>=

etykietki.kolory <- as.numeric(data_clust$drive.wheels)  
obiekty.kolory <- etykietki.kolory[agnes.complete_num$order]
fviz_dend(agnes.complete_num, cex=0.5, lwd = 0.4,label_cols=obiekty.kolory, main="Kolory = rzeczywiste klasy zmiennej drive.wheels")
@
<<plot_AGNES_Comparison_num.of.cylinders, eval=TRUE, echo=FALSE,fig.width=7, fig.height=4,cache=TRUE, warning=FALSE,fig.cap="dendrogram dla metody AGNES dla zmiennych ilościowych z zaznaczeniem różnych kategorii zmiennej num.of.cylinders">>=
etykietki.kolory <- as.numeric(data_clust$num.of.cylinders)  
obiekty.kolory <- etykietki.kolory[agnes.complete_num$order]
fviz_dend(agnes.complete_num, cex=0.5, lwd = 0.4,label_cols=obiekty.kolory, main="Kolory = rzeczywiste klasy zmiennej num.of.cylinders")
@
<<plot_AGNES_Comparison_fuel.system, eval=TRUE, echo=FALSE,fig.width=7, fig.height=4,cache=TRUE, warning=FALSE,fig.cap="dendrogram dla metody AGNES dla zmiennych ilościowych z zaznaczeniem różnych kategorii zmiennej fuel.system">>=
etykietki.kolory <- as.numeric(data_clust$fuel.system)  
obiekty.kolory <- etykietki.kolory[agnes.complete_num$order]
fviz_dend(agnes.complete_num, cex=0.5, lwd = 0.4,label_cols=obiekty.kolory, main="Kolory = rzeczywiste klasy zmiennej fuel.system")
@

Na powyższych rysunkach widzimy, że etykietki każdej ze zmiennych \texttt{drive.wheels}, \texttt{num.of.cylinders} i \texttt{fuel.system} w jakiś sposób 
lepiej odpowiadają strukturze klastrów niż dla zmiennej \texttt{symboling} np. dla zmiennej \texttt{num.of.cylinders} zdecydowana część lewej (z dwóch) gałęzi dendrogramu należy do kategorii oznaczonej kolorem zielonnym, z kolei da zmiennej \texttt{fuel.system}, zdecydowana większość prawej gałezi dendrogramu należy do etykietki oznaczonej kolorem różowym.
\par
Stworzone zostały one także dendrogramy porównujące z kategoriami pozostałych zmiennych jakościowych. Wykresy te umieszczone zostały w sekcji Dodatek. 

\par Dodatkowo, warto przypomnieć fakt, że wszystkie zmienne numeryczne były standaryzowane przed użyciem. Dlaczego tak zrobiliśmy? Poniżej odpowiedź na rysunkach \ref{fig:plot_AGNES_UNSCALED_1}, \ref{fig:plot_AGNES_UNSCALED_2} i \ref{fig:plot_AGNES_UNSCALED_3}. Przedstawione są tam porównawcze dendrogramy między użyciem ustandaryzowanych i oryginalnych danych liczbowych dla każdej z trzech wcześniej używanych przez nas metod łączenia.
<<AGNES_UNSCALED, eval=TRUE, echo=FALSE, warning=FALSE>>=
agnes.avg_num_UNSCALED <- agnes(DM_num_matrix_UNSCALED,diss=TRUE, method="average")
agnes.single_num_UNSCALED <- agnes(DM_num_matrix_UNSCALED,diss=TRUE, method="single")
agnes.complete_num_UNSCALED <- agnes(DM_num_matrix_UNSCALED,diss=TRUE, method="complete")
@

<<plot_AGNES_UNSCALED_1, eval=TRUE, echo=FALSE,fig.width=7, fig.height=4,cache=TRUE, warning=FALSE,fig.cap="dendrogram dla metody AGNES dla zmiennych ilościowych z wykorzystaniem complete linkage">>=
grid.arrange( fviz_dend(agnes.single_num, cex = 0.5, lwd = 0.3, main="Scaled") ,
              fviz_dend(agnes.single_num_UNSCALED, cex = 0.5, lwd = 0.3, main="Unscaled") ,ncol=2,
              top=textGrob("AGNES - single linkage")) 

@

<<plot_AGNES_UNSCALED_2, eval=TRUE, echo=FALSE,fig.width=7, fig.height=4,cache=TRUE, warning=FALSE,fig.cap="dendrogram dla metody AGNES dla zmiennych ilościowych z wykorzystaniem complete linkage">>=
grid.arrange( fviz_dend(agnes.avg_num, cex = 0.5, lwd = 0.3, main="Scaled") ,
              fviz_dend(agnes.avg_num_UNSCALED, cex = 0.5, lwd = 0.3, main="Unscaled"), ncol=2,
              top=textGrob("AGNES - average linkage"))
@

<<plot_AGNES_UNSCALED_3, eval=TRUE, echo=FALSE,fig.width=7, fig.height=4,cache=TRUE, warning=FALSE,fig.cap="dendrogram dla metody AGNES dla zmiennych ilościowych z wykorzystaniem complete linkage">>=
grid.arrange( fviz_dend(agnes.complete_num, cex = 0.5, lwd = 0.3, main="Scaled") ,
              fviz_dend(agnes.complete_num_UNSCALED, cex = 0.5, lwd = 0.3, main="Unscaled"), ncol=2,
              top=textGrob("AGNES - complete linkage")) 
@

Widzimy na powyższych $3$ rysunków, że dendrogramy uzyskane na podstawie macierzy odmienności uzsykanych na bazie danych niestandaryzowanych mają bardziej "niechlujne" struktury.



\subsubsection{DIANA}

Kolejną metodą, której użyjemy jest $DIANA$ (ang. DIviseve ANAlysis). Jest to przykład metody dzielącej, która działają niejako "odwrotnie" niż metody aglomeracyjne tzn. na początku wszystke obiekty tworzą jedno duże skupienie, które jest potem dzielone, tak aby otrzymać jednorodne klastry. $DIANA$, podobnie jak $AGNES$ potrzebuje na wejściu tylko macierz odmienności, więc oczywiście możemy używać zmiennych jakościowych jak i danych mieszanego typu.

\par Na początek porównamy metodę $DIANA$ dla wszystkich zmiennych i tylko dla zmiennych ilościowych. Na rysunkach \ref{fig:diana_all} i \ref{fig:diana_num} przedstawione zostały takie dendrogramy. 
<<legend_symboling, eval=TRUE, echo=FALSE, cache=TRUE>>=
x<- cbind.data.frame(data_clust$symboling, etykietki.kolory)
colnames(x) <- c("symboling", "color")
p_leg <- ggplot(x, aes(x=symboling, fill=symboling )) + 
  geom_bar( ) +
  scale_fill_manual(values=c("blue", "green", "yellow", "orange", "red"))

g_legend <- function(a.gplot){ 
  tmp <- ggplot_gtable(ggplot_build(a.gplot)) 
  leg <- which(sapply(tmp$grobs, function(x) x$name) == "guide-box") 
  legend <- tmp$grobs[[leg]] 
  legend
} 

legend <- g_legend(p_leg) 

legend$vp$x <- unit(.92, 'npc')
legend$vp$y <- unit(.8, 'npc')

x<- cbind.data.frame(symboling_custom, etykietki.kolory)
colnames(x) <- c("symboling", "color")
p_leg_2 <- ggplot(x, aes(x=symboling, fill=symboling )) + 
  geom_bar( ) +
  scale_fill_manual(values=c("green","red"))

legend2 <- g_legend(p_leg_2) 
legend2$vp$x <- unit(.87, 'npc')
legend2$vp$y <- unit(.8, 'npc')

x<- cbind.data.frame(price_factor, etykietki.kolory)
colnames(x) <- c("price_factor", "color")
p_leg_3 <- ggplot(x, aes(x=price_factor, fill=price_factor )) + 
  geom_bar( ) +
  scale_fill_manual(values=c("blue","green","gold","red"))

legend3 <- g_legend(p_leg_3) 
legend3$vp$x <- unit(.87, 'npc')
legend3$vp$y <- unit(.8, 'npc')
@

<<diana_all, eval=TRUE, echo=FALSE, cache=TRUE, fig.width=5.5, fig.height=3,cache=TRUE, warning=FALSE,fig.cap="dendrogram dla metody DIANA dla wszystkich zmiennych">>=
diana_all <- diana(DM_matrix,diss=TRUE)

fviz_dend(diana_all, lwd = 0.3 ,cex = 0.5)+
  ggtitle("DIANA - wszystkie zmienne")+
  theme(plot.title = element_text(hjust = 0.5))
@

<<diana_num, eval=TRUE, echo=FALSE, cache=TRUE, fig.width=5.5, fig.height=3,cache=TRUE, warning=FALSE,fig.cap="dendrogram dla metody DIANA dla zmiennych ilościowych">>=
diana_num <- diana(DM_num_matrix,diss=TRUE)

fviz_dend(diana_num, lwd = 0.3 ,cex = 0.5)+
  ggtitle("DIANA - zmienne ilościowe")+
  theme(plot.title = element_text(hjust = 0.5))
@

Widzimy na dwóch powyższych rysunkach, że otrzymane dendogramy znacząco się różnią strukturą. Najwżniejszą obserwacją jest fakt, że w przypadku użycia wszystkich zmiennych, najbardziej wyraźny jest podział na $k=3$ klastry, natomiast dla zmiennych numerycznych są $k=2$ klastry. Możemy także zauważyć, że  wobu przypadkach, metoda $DIANA$ zwraca rezultaty podobne do algorytmu $AGNES$ z metodą łączenia klastrów complete linkage. 

\par  Ciekawym graficznym sposobem, żeby porównać $2$ dendrogramy jest tzw. tanglegram, który umieszcza $2$ dendrogramy w pozycji na przeciwko siebie, a na środku umieszcza linie łączące te same obiekty między dwoma dendrogramami. Poniżej na rysunkach \ref{fig:tanglegram1} i \ref{fig:tanglegram2} umieszczone zostały tanglegramy dla metody $DIANA$ i $AGNES$ (complete linkage) dla wszystkich zmiennych i dla zmiennych numerycznych odpowiednio. Co więcej, na owich tanglegramach zilustrowany został podziała na klastry, gdzie $k=3$ w przypadku wszystkich zmiennych i $k=2$ dla zmiennych numerycznych. Tanglegramy zostały stworzone za pomocą funkcji \texttt{tanglegram} z pakietu \textbf{dendextend}.


<<tanglegram1, eval=TRUE, echo=FALSE,cache=TRUE,fig.width=7, fig.height=4, warning=FALSE,fig.cap="Tanglegram dla metod DIANA i AGNES dla wszystkich zmiennych">>=
dend1<- as.dendrogram (diana_all)
dend2<- as.dendrogram (agnes.complete_all)

dlist <- dendextend::dendlist(
  dend1 %>% 
    set("labels_col", value = c("skyblue", "orange", "purple"), k=3) %>%
    set("branches_lty", 1) %>%
    set("branches_k_color", value = c("skyblue", "orange", "purple"), k = 3),
  dend2 %>% 
    set("labels_col", value = c("skyblue", "orange", "purple"), k=3) %>%
    set("branches_lty", 1) %>%
    set("branches_k_color", value = c("skyblue", "orange", "purple"), k = 3)
)
#tanglegram(dend1, dend2, main_left = "DIANA", main_right = "AGNES", lwd=1,
#          margin_inner = 3.5, center = TRUE)

dendextend::tanglegram(dlist, main_left = "DIANA", main_right = "AGNES \n (complete linkage)", lwd=1, main = "Podział na \n k=3 klastry",
           margin_inner = 3.5, margin_outer=2, center = TRUE)
@

<<tanglegram2, eval=TRUE, echo=FALSE,cache=TRUE,fig.width=7, fig.height=4,cache=TRUE, warning=FALSE,fig.cap="Tanglegram dla metod DIANA i AGNES dla zmiennych ilościowych">>=
dend1<- as.dendrogram (diana_num)
dend2<- as.dendrogram (agnes.complete_num)

dlist <- dendextend::dendlist(
  dend1 %>% 
    set("labels_col", value = c("skyblue", "orange"), k=2) %>%
    set("branches_lty", 1) %>%
    set("branches_k_color", value = c("skyblue", "orange"), k = 2),
  dend2 %>% 
    set("labels_col", value = c("skyblue", "orange"), k=2) %>%
    set("branches_lty", 1) %>%
    set("branches_k_color", value = c("skyblue", "orange"), k = 2)
)
#tanglegram(dend1, dend2, main_left = "DIANA", main_right = "AGNES", lwd=1,
#          margin_inner = 3.5, center = TRUE)

dendextend::tanglegram(dlist, main_left = "DIANA", main_right = "AGNES \n (complete linkage)", lwd=1, main = "Podział na \n k=2 klastry",
           margin_inner = 3.5, margin_outer=2, center = TRUE)
@
Jak wyżymy powyżej, dla przypadku wszystkich zmiennych dendrogramy uzyskane metodami $DIANA$ i $AGNES$ są bliskie identyczności. Widzimy, że linie na środku tylko w pojedynczych przypadkach wychodzą z dendrogramu po lewej stronie z klastru o jednym kolorze, do dendrogramu po prawej stronie do klastra o kolorze innym. Dodatkowo, w obu przypadkach widzimy, że podział na $k=3$ klastry jest jak najbardziej optymalny. 
\par Nieco inaczej jest w przypadku zmiennych ilościowych, gdzie różnica między dendrogramami jest znacznie większa, ale wciąż otrzymane rezultaty możemy określić jako bardzo podobne.

\par W następnej części przeprowadzone zostały badania z różnymi niestandarowanymi podzbiorami cech, wybiórczo przez nas wybranymi. Poniżej na rysunkach \ref{fig:plot_DIANA_test_feat}, \ref{fig:plot_DIANA_symbo_2levels} przedstawione zostały dendrogramy uzyskane metodą $DIANA$ na bazie $4$ następujących zmiennych: \texttt{normalized.losses}, \texttt{fuel.system}, \texttt{num.of.doors}, \texttt{length}. Gałęzie dendrogramu zostały pokolorowane przyjmując podział na $k=2$ klastry, a na dole etykietki obiektów zostały pokolorowane zgodnie z etykietkami zmiennej \texttt{symboling}.

<<plot_DIANA_test_feat, eval=TRUE, echo=FALSE, cache=TRUE, fig.width=7, fig.height=4.2,cache=TRUE, warning=FALSE,fig.cap="Klasteryzacja na 2 grupy za pomocą metody DIANA, a 5 grup zmiennej objaśnianej dla zmiennych normalized.losses, fuel.system, num.of.doors, length">>=
DM_test <- daisy(data_clust_features[, c("normalized.losses", "fuel.system", "num.of.doors", "length")])
DM_test_matrix <- as.matrix(DM_test)
diana_test <- diana(DM_test,diss=TRUE, color_labels("green"))
etykietki.kolory <- as.numeric(data_clust$symboling)  

obiekty.kolory <- etykietki.kolory[diana_test$order]
# dendrogram + kolory odpowiadające rzeczywistym klasom

obiekty.kolory[which(obiekty.kolory==5)] <- "red"
obiekty.kolory[which(obiekty.kolory==4)] <- "orange"
obiekty.kolory[which(obiekty.kolory==3)] <- "yellow"
obiekty.kolory[which(obiekty.kolory==2)] <- "green"
obiekty.kolory[which(obiekty.kolory==1)] <- "blue"

fviz_dend(diana_test, k=2,cex=0.5, lwd=0.3, label_cols=obiekty.kolory, main="DIANA (4 zmienne)")+  theme(plot.title = element_text(hjust = 0.5))

grid.draw(legend)

@

<<plot_DIANA_symbo_2levels, eval=TRUE, echo=FALSE, cache=TRUE, fig.width=7, fig.height=4.2,warning=FALSE,fig.cap="Klasteryzacja na 2 grupy za pomocą metody DIANA, a 2 grupy zmiennej objaśnianej dla zmiennych normalized.losses, fuel.system, num.of.doors, length">>=
etykietki.kolory <- symboling_custom 

obiekty.kolory <- etykietki.kolory[diana_test$order]
# dendrogram + kolory odpowiadające rzeczywistym klasom

obiekty.kolory[which(obiekty.kolory == "1 , 2 or 3")] <- "red"
obiekty.kolory[which(obiekty.kolory == "-1 or 0")] <- "green"

fviz_dend(diana_test, k=2,cex=0.5, lwd=0.3, label_cols=obiekty.kolory, 
          main="DIANA (4 zmienne)")+
          theme(plot.title = element_text(hjust = 0.5))

grid.draw(legend2)
@

Jak możemy zaobserwować powyżej $DIANA$ użyta dla $4$ wybranych zmiennych zwróciła bardzo ciekawe rezultaty. Mianowicie widzimy, że optymalną liczbą klastrów jest $k=2$, i to własnie dla tego podziału widzimy, że $2$ rozdzielone partycje dobrze oddają podział na $2$ grupy zmiennej \texttt{symboling} odpowiadające za mniej oraz bardziej ryzykowne auta. Żeby potwierdzić tezę, że jest to kwestia wyboru cech, poniżej na rysunku \ref{fig:plot_DIANA_symbo_2levels_num_all} przedstawione zostały analogiczne dendrogramy dla odpowiednio zmiennych numerycznych oraz wszystkich zmiennych z zaznaczonymi etykietkami zmiennej objaśnianej \texttt{symboling} dla podziału na $2$ kategorie, a także z zaznaczonym podziałem na $2$ klastry w dendrogramie.

<<plot_DIANA_symbo_2levels_num_all, eval=TRUE, echo=FALSE, cache=TRUE, fig.width=7, fig.height=4, warning=FALSE,fig.cap="Klasteryzacja na 2 grupy za pomocą metody DIANA, a dwie grupy zmiennej objaśnianej dla zmiennych normalized.losses, fuel.system, num.of.doors, length">>=
etykietki.kolory <- symboling_custom 

obiekty.kolory <- etykietki.kolory[diana_num$order]
# dendrogram + kolory odpowiadające rzeczywistym klasom
obiekty.kolory[which(obiekty.kolory == "1 , 2 or 3")] <- "red"
obiekty.kolory[which(obiekty.kolory == "-1 or 0")] <- "green"

p1 <- fviz_dend(diana_num, k=2,cex=0.5, lwd=0.3, label_cols=obiekty.kolory, 
          main="DIANA num")+
          theme(plot.title = element_text(hjust = 0.5))
#________________________________________________________________________
etykietki.kolory <- symboling_custom 

obiekty.kolory <- etykietki.kolory[diana_all$order]
# dendrogram + kolory odpowiadające rzeczywistym klasom

obiekty.kolory[which(obiekty.kolory == "1 , 2 or 3")] <- "red"
obiekty.kolory[which(obiekty.kolory == "-1 or 0")] <- "green"

p2 <- fviz_dend(diana_all, k=2,cex=0.5, lwd=0.3, label_cols=obiekty.kolory, 
          main="DIANA all")+
          theme(plot.title = element_text(hjust = 0.5))
grid.arrange(p1,p2, ncol=2)
grid.draw(legend2)
@

Jasno widzimy, że podzbiory zawierające większą część zmiennych nie poradziły sobie tak dobrze z separacją wybranych grup zmiennej \texttt{symboling}.
\par Następnie porównamy czy algorytm $AGNES$ z metodą łączenia grup complete linkage działa równie dobrze biorąc pod uwagę tylko te same $4$ zmienne: \texttt{normalized.losses}, \texttt{fuel.system}, \texttt{num.of.doors}, \texttt{length}. Na rysunku \ref{fig:plot_AGNES_symbo_2levels} przedstawiony został dendrogram odpowiadający temu wyborowi cech.
<<plot_AGNES_symbo_2levels, eval=TRUE, echo=FALSE, cache=TRUE, fig.width=7, fig.height=4, warning=FALSE,fig.cap="Klasteryzacja na 2 grupy za pomocą metody AGNES, a dwie grupy zmiennej objaśnianej dla zmiennych normalized.losses, fuel.system, num.of.doors, length">>=
agnes_test <- agnes(DM_test,diss=TRUE, method="complete")
etykietki.kolory <- symboling_custom  

obiekty.kolory <- etykietki.kolory[agnes_test$order]
# dendrogram + kolory odpowiadające rzeczywistym klasom

obiekty.kolory[which(obiekty.kolory == "1 , 2 or 3")] <- "red"
obiekty.kolory[which(obiekty.kolory == "-1 or 0")] <- "green"

fviz_dend(agnes_test, k=2,cex=0.5, lwd=0.3, label_cols=obiekty.kolory, main="AGNES (complete linkage, 4 zmienne)")+
    theme(plot.title = element_text(hjust = 0.5))
  
grid.draw(legend2)
@

Jak widzimy powyżej, ten dendrogram jest dużo bardziej zbliżony do analogicznego dla metody $DIANA$. Widzimy, że $2$ grupy zmiennej \texttt{symboling} są dobrze uchwycone. Żeby dokładniej porównać te $2$ dendrogramy, ponownie użyliśmy tanglegramu. Wyniki przedstawione zostały na rysunku \ref{fig:tanglegram3}.

<<tanglegram3, eval=TRUE, echo=FALSE,fig.width=7, fig.height=4,cache=TRUE, warning=FALSE,fig.cap="Tanglegram dla metod DIANA i AGNES dla zmiennych normalized.losses, fuel.system, num.of.doors, length">>=
dend1<- as.dendrogram (diana_test)
dend2<- as.dendrogram (agnes_test)

dlist <- dendextend::dendlist(
  dend1 %>% 
    set("labels_col", value = c("skyblue", "orange"), k=2) %>%
    set("branches_lty", 1) %>%
    set("branches_k_color", value = c("skyblue", "orange"), k = 2),
  dend2 %>% 
    set("labels_col", value = c("skyblue", "orange"), k=2) %>%
    set("branches_lty", 1) %>%
    set("branches_k_color", value = c("skyblue", "orange"), k = 2)
)

dendextend::tanglegram(dlist, main_left = "DIANA", main_right = "AGNES \n (complete linkage)", lwd=1, main = "Podział na \n k=2 klastry",
           margin_inner = 3.5, margin_outer=2, center = TRUE)
@

Z rysunku powyżej możemy stwierdzić, że sprawdzają się nasze przypuszczenia dotyczące podobieństwa rezultatów metod $DIANA$ i $AGNES$. Widzimy, że podział na $2$ klastry jest bardzo podobny, prawie identyczny.

\par Już wcześniej wspomnieliśmy o współczynniku $AC$. Dodajmy, że dla metod dzielących istnieje analogiczny współczynnik - $DC$ (divisive coefficient). Podobnie, jak w wypadku $AC$, tutaj również wartość im bliższa $1$, tym bardziej istotny jest podział. Poniżej przedstawione zostały współczynniki $AC$ i $DC$ dla metod $AGNES$ i $DIANA$ odpowiednio.
<<agnes_diana_coeffs, eval=TRUE, echo=FALSE>>=
print(paste("Współczynnik AC wynosi:", round(agnes_test$ac,3)))
print(paste("Współczynnik DC wynosi:", round(diana_test$dc,3)))
@
I widzimy, że są one bardzo blisko $1$, co pozwala nam uznać oba podziały za istotne.
\par Poniżej załączone zostały także fragmenty kodu z czymś na wzór tabeli kontygencji. UWAGA: etykietki klastrów przypisane są "na odwrót" tzn. poprawnie zaklsyfikowane obiekty nie leżą na głównej diagonali, a na drugiej!

<<agnes_diana_tables, eval=TRUE, echo=TRUE>>=
#funkcja zwracająca etykiety klastrów
cutree(agnes_test, k=2)[1:15]
table(symboling_custom, cutree(agnes_test, k=2)) #klastry sa odwrotnie!!
#analogicznie dla Diany
cutree(diana_test, k=2)[1:15]
table(symboling_custom, cutree(diana_test, k=2)) 

@
Poniżej przedstawione zostały także wyniki dokładności dla obu tych metod:
<<agnes_diana_print, eval=TRUE, echo=TRUE>>=
print(paste("Dokładność klasyfikacji dla metody AGNES:", round( 1-sum(diag(table(symboling_custom, cutree(agnes_test, k=2))) )/sum(table(symboling_custom, cutree(agnes_test, k=2)) ),2 )))

print(paste("Dokładność klasyfikacji dla metody DIANA:", round( 1-sum(diag(table(symboling_custom, cutree(diana_test, k=2))) )/sum(table(symboling_custom, cutree(diana_test, k=2)) ),2 )))
@
jak widzimy, obie metody zwróciły dokładnie ten sam poziom dokładności $0.81$, który możemy uznać za wysoki.

\par Jak pamiętamy, na początku stworzyliśmy zmienną jakościową \texttt{price}, na bazie oryginalnej. Na rysunku \ref{fig:plot_DIANA_price_factor} przedstawione jest porównanie klasteryzacji na $4$ grupy za pomocą metody $DIANA$ z rzeczywistymi etykietkami naszej zmodyfikowanej zmiennej \texttt{price}.
<<plot_DIANA_price_factor, eval=TRUE, echo=FALSE, cache=TRUE, fig.width=7, fig.height=4, warning=FALSE,fig.cap="Klasteryzacja na 4 grupy za pomocą metody DIANA, a dwie grupy zmiennej price">>=

etykietki.kolory <- as.character(price_factor[,1])  

obiekty.kolory <- etykietki.kolory[diana_test$order]
# dendrogram + kolory odpowiadające rzeczywistym klasom

obiekty.kolory[which(obiekty.kolory == "Cheap (x<8000)")] <- "blue"
obiekty.kolory[which(obiekty.kolory == "Medium (8000<x<12000)")] <- "green"
obiekty.kolory[which(obiekty.kolory == "Expensive (12000<x<18000)")] <- "gold"
obiekty.kolory[which(obiekty.kolory == "Very expensive (x>18000)")] <- "red"

fviz_dend(diana_test, k=5,cex=0.5, lwd=0.3, label_cols=obiekty.kolory, main="DIANA (4 zmienne)")+
    theme(plot.title = element_text(hjust = 0.5))
grid.draw(legend3)
@
Widzimy, że wyniki naszego małego ekspetymentu nie są zbyt satysfakcjonujące. Nie możemy zauważyć, żadnego porządku i powiązania między otrzymanymi klastrami, a rzeczywistymi wartościami zmiennej \texttt{price}.

\par Sprawdzimy jeszcze działanie metody $DIANA$ dla podzbioru $4$ innych zmiennych. Przetestowanych zostało wiele podzbiorów zmiennych od $2$ do $5$ elementowych, mogę stwierdzić jedynie, że dla żadnego podzbioru nie uzyskaliśmy dokładności większej niż $0.81$, a przeważnie kończyło się na gorszych rezultatach. Dodatkowo wartym podkreślenia jest fakt, że przy testowaniu ręcznie "istotności" zmiennych, najważniejszą wydawała się \texttt{num.of.doors}, od której wystepowania lub jego braku w rozważanym podzbiorze cech zależało najwięcej. Poniżej na rysunkach \ref{fig:plot_DIANA_test_feat_2}, \ref{fig:plot_DIANA_test_feat_2_2levels} umieszczone zostały przykładowe dendrogramy dla zmiennych \texttt{price}, \texttt{height}, \texttt{curb.weight}, \texttt{wheel.base} i \texttt{peak.rpm}. 

<<plot_DIANA_test_feat_2, eval=TRUE, echo=FALSE, fig.width=7, fig.height=4,warning=FALSE,fig.cap="Klasteryzacja na 2 grupy za pomocą metody DIANA, a dwie grupy zmiennej objaśnianej dla zmiennych price, height, curb.weight, wheel.base i peak.rpm">>=
DM_test_2 <- daisy(data_clust_features[, c( "price", "height","curb.weight","wheel.base","peak.rpm")])
DM_test_2_matrix <- as.matrix(DM_test_2)
diana_test_2 <- diana(DM_test_2,diss=TRUE, color_labels("green"))
etykietki.kolory <- as.numeric(data_clust$symboling)  

obiekty.kolory <- etykietki.kolory[diana_test_2$order]
# dendrogram + kolory odpowiadające rzeczywistym klasom

obiekty.kolory[which(obiekty.kolory==5)] <- "red"
obiekty.kolory[which(obiekty.kolory==4)] <- "orange"
obiekty.kolory[which(obiekty.kolory==3)] <- "yellow"
obiekty.kolory[which(obiekty.kolory==2)] <- "green"
obiekty.kolory[which(obiekty.kolory==1)] <- "blue"

fviz_dend(diana_test_2, k=2,cex=0.5, lwd=0.3, label_cols=obiekty.kolory, main="DIANA")
grid.draw(legend)
print(paste("Dokładność dla zmiennej symboling przyjmującej tylko dwie wartości:", round( 1-sum(diag(table(symboling_custom, cutree(diana_test_2, k=2))) )/sum(table(symboling_custom, cutree(diana_test_2, k=2)) ),2 )))
@

<<plot_DIANA_symbo_test2_2levels, eval=TRUE, echo=FALSE, cache=TRUE, fig.width=7, fig.height=4,warning=FALSE,fig.cap="Klasteryzacja na 2 grupy za pomocą metody DIANA, a dwie grupy zmiennej objaśnianej dla zmiennych price, height, curb.weight, wheel.base i peak.rpm">>=
etykietki.kolory <- symboling_custom 

obiekty.kolory <- etykietki.kolory[diana_test_2$order]
# dendrogram + kolory odpowiadające rzeczywistym klasom

obiekty.kolory[which(obiekty.kolory == "1 , 2 or 3")] <- "red"
obiekty.kolory[which(obiekty.kolory == "-1 or 0")] <- "green"

fviz_dend(diana_test_2, k=2,cex=0.5, lwd=0.3, label_cols=obiekty.kolory, 
          main="DIANA")+
          theme(plot.title = element_text(hjust = 0.5))

grid.draw(legend2)

@

Z powyżych rysunków widzimy jednoznacznie, że dla tego podzbioru wyniki nie są już tak zadowalające. 

\section{Redukcja wymiaru}

Redukcja wymiaru jest bardzo ważną częścią procesu data mining. Umożliwia ona m.in wizualizacje wyników na wykresach (dzięki sprowadzeniu do danych dwuwymiarowych), eliminacje nadmiarowej informacji czy identyfikacje struktury zależności w danych. Metody redukcji wymiaru mogą należeć zarówno do uczenia nienadzorowanego jak i do uczenia nadzorowanego w zależności od konkretnej metody. Jednakże dwie wybrane przez nas metody: $PCA$ i $MDS$ są przykładami uczenia nienadzorowanego.

\subsection{PCA - analiza składowych głównych}
Pierwszą metodą redukcji wymiaru wybraną przez nas jest $PCA$. Streszczając, poszukuje ona zbioru złożonej z mniejszej liczby zmiennych, dzięki któremu uda się nam zachować najważniejsze własności wyjściowych danych. Metoda ta działa bardzo dobrze zwłaszcza, gdy w analizowanych danych występują silnie skorelowane zmiene. Dodać trzeba, że $PCA$ działa tylko na zmiennych ilościowych. Metoda ta działa w ten sposób, że wybieramy kilka pierwszych składowych głównych, które wyjasniają odpowiednio dużą część całkowitej zmienności danych. Więcej o $PCA$ tutaj: \cite{PCA}. 


<<plot_PCA1, eval=TRUE, echo=FALSE,fig.width=12, fig.height=7,cache=TRUE, warning=FALSE,fig.cap="Wizualizacja metody PCA">>=
pca1 <- PCA(X=data_num_clust_features, scale.unit = TRUE, ncp = 5, graph=FALSE)
@

Do implementacji metody $PCA$ w \textbf{R} będziemy używać funkcji \texttt{PCA} \cite{PCA_R} z pakietu \textbf{FactoMiner}. Poniżej przedstawiony został zbiór elementów zwracany przez tą funkcję. 

<<PCA_1, eval=TRUE, echo=FALSE, cache=TRUE>>=
print(pca1)
??PCA
@

Poniżej przedstawiony został fragment kodu z wartościami własnymi macierzy kowariancji oraz wariancje składowych głównych.

<<PCA_2, eval=TRUE, echo=FALSE, cache=TRUE>>=
(eigenvalues <- get_eigenvalue(pca1))
@

Poniżej na rysunku \ref{fig:plot_PCA2} zilustrowane zostały wariancje składowych głównych.

<<plot_PCA2, eval=TRUE, echo=FALSE,fig.width=5, fig.height=3.5,cache=TRUE, warning=FALSE,fig.cap="Wariancje składowych głównych w metodzie PCA">>=
fviz_eig(pca1, addlabels = TRUE)
@

Jednakże lepszym sposobem analizy jest porównanie skumulowanej wariancji pierwszych $k$ składowych głównych. Poniżej na rysunku \ref{fig:plot_PCA3} został przedstawiony własnie taki wykres, z dodaną linią przy wartości $80$ procent.
<<plot_PCA3, eval=TRUE, echo=FALSE,fig.width=5, fig.height=3.7,cache=TRUE, warning=FALSE,fig.cap="Skumulowana wariancja pierwszych k składowych głównych">>=
plot(eigenvalues[,3], type ='b', xlab="k", ylab="Skumulowany procent wariancji", lwd=2.8)
bar <- 80 # w procentach
abline(h=bar, lwd=2, col="red")
@
Widzimy, że pierwsze $4$ składowe główne odpowiadają za około $80$ procent całej wariancji.  
\par Poniżej przedstawione są ładunki poszczególnych zmiennych dla pierwszych $5$ składowych głównych. Jeszcze niżej, na rysunku \ref{fig:plot_PCA4} przedstawione zostały korelacje zmienne z poszczególnymi składowymi głównymi.
<<PCA_3, eval=TRUE, echo=FALSE, cache=TRUE>>=
loadings <- sweep(pca1$var$coord,2,sqrt(pca1$eig[1:ncol(pca1$var$coord),1]),FUN="/")
loadings
@

<<plot_PCA4, eval=TRUE, echo=FALSE,cache=TRUE,fig.width=6, fig.height=5, warning=FALSE,fig.cap="Skumulowana wariancja pierwszych k składowych głównych">>=
variables <- get_pca_var(pca1)
corrplot(variables$cor)
@

Widzimy, że aż $10$ na $15$ zmiennych numerycznych jest silnie skorelowanych już z pierwsza składową główną. 
\par Poniżej na rysunku \ref{fig:plot_PCA5} zobrazowane zostały wkłady poszczególnych zmiennych w pierwsze $3$ składowe główne.

<<plot_PCA5, eval=TRUE, echo=FALSE,cache=TRUE ,fig.width=10, fig.height=4, warning=FALSE,fig.cap="Skumulowana wariancja pierwszych k składowych głównych">>=
grid.arrange(fviz_contrib(pca1, choice="var", axes=1),
             
             # wkład zmiennych do PC2
             fviz_contrib(pca1, choice="var", axes=2),
             
             # wkład zmiennych do PC3
             fviz_contrib(pca1, choice="var", axes=3), ncol=3
)
@

Z kolei poniżej na rysunku \ref{figh:plot_PCA6}, zamieszczony został wykres punktowy, który przedstawia rozrzut poszczególnych obiektów w przestrzeni dwóch pierwszych składowych głównych.
<<plot_PCA6, eval=TRUE, echo=FALSE,cache=TRUE ,fig.width=6, fig.height=4, warning=FALSE,fig.cap="Wykres rozrzutu w przestrzeni dwóch pierwszych składowych głównych">>=
fviz_pca_ind(pca1, repel=FALSE)
@

Poniżej na rysunku \ref{figh:plot_PCA7}, zamieszczony został wykres, który przedstawia rozmieszczenie poszczególnych zmiennych w przestrzeni dwóch pierwszych składowych głównych.
<<plot_PCA7, eval=TRUE, echo=FALSE,cache=TRUE ,fig.width=6, fig.height=4, warning=FALSE,fig.cap="wpływ poszczególnych zmiennych na wartości dwóch pierwszych składowych głównych">>=
fviz_pca_var(pca1, col.var="black",labelsize = 4, repel=TRUE)
@

Teraz przejdziemy do porównania rezultatów otrzymanych metodą $PCA$ (konketnie pierwszych $2$ składowych) z rzeczywistymi wartościami zmiennych jakościowych. Na początek, na rysunkach \ref{fig:plot_PCA_symbo1}, \ref{fig:plot_PCA_symbo2} przedstawione zostało porównanie ze zmienną \texttt{symboling}.


<<plot_PCA_symbo1, eval=TRUE, echo=FALSE,cache=TRUE ,fig.width=8, fig.height=4.1, warning=FALSE,fig.cap="wpływ poszczególnych zmiennych na wartości dwóch pierwszych składowych głównych">>=
grid.arrange(fviz_pca_ind(pca1, col.ind = data_clust$symboling,repel=FALSE,geom.ind="point", 
                          palette = c("blue","green", "yellow", "orange", "red"), 
                          legend.title="symboling", pointshape=16)+theme(legend.position = "bottom"),
             fviz_pca_ind(pca1, col.ind = data_clust$symboling,repel=FALSE,geom.ind="point", 
                          palette = c("blue","green", "yellow", "orange", "red"), 
                          legend.title="symboling", pointshape=16, addEllipses = TRUE)+theme(legend.position = "bottom"), ncol=2
)
@

<<plot_PCA_symbo2, eval=TRUE, echo=FALSE,cache=TRUE ,fig.width=8, fig.height=4.1, warning=FALSE,fig.cap="wpływ poszczególnych zmiennych na wartości dwóch pierwszych składowych głównych">>=
grid.arrange(fviz_pca_ind(pca1,  col.ind = symboling_custom ,geom.ind="point",repel=FALSE, palette = c("blue","red"),
             legend.title="symboling", pointshape=16)+theme(legend.position = "bottom"),
fviz_pca_ind(pca1,  col.ind = symboling_custom ,geom.ind="point",repel=FALSE, palette = c("blue","red"),
             legend.title="symboling", pointshape=16, addEllipses = TRUE)+theme(legend.position = "bottom"), ncol=2)

@

Mimo że możemy dostrzec pewne wzorce na powyższych rysunkach, to możemy stwierdzić, że kategorie zmiennej \texttt{symboling} nie zostały prawidłowo wychwycone.
\par Poniżej, na rysunkach \ref{fig:plot_PCA_drive.wheels}, \ref{fig:plot_PCA_fuel.system}, \ref{fig:plot_PCA_num.of.doors} przedstawione zostały analogiczne wizualizacje dla innych zmiennych jakościowych: \texttt{drive.wheels}, \texttt{fuel.system} i \texttt{num.of.doors}.

<<plot_PCA_drive.wheels, eval=TRUE, echo=FALSE,cache=TRUE ,fig.width=8, fig.height=4.1, warning=FALSE,fig.cap="wpływ poszczególnych zmiennych na wartości dwóch pierwszych składowych głównych">>=
grid.arrange(fviz_pca_ind(pca1, col.ind = data_clust$drive.wheels,repel=FALSE,geom.ind="point", 
             palette = c("gold","darkblue", "brown"), 
             legend.title="drive.wheels", pointshape=16)+theme(legend.position = "bottom"),
fviz_pca_ind(pca1, col.ind = data_clust$drive.wheels,repel=FALSE,geom.ind="point", 
             palette = c("gold","darkblue", "brown"), 
             legend.title="drive.wheels", pointshape=16, addEllipses = TRUE)+theme(legend.position = "bottom"), ncol=2)
@

<<plot_PCA_fuel.system, eval=TRUE, echo=FALSE,cache=TRUE ,fig.width=8, fig.height=4.1, warning=FALSE,fig.cap="wpływ poszczególnych zmiennych na wartości dwóch pierwszych składowych głównych">>=
grid.arrange(fviz_pca_ind(pca1, col.ind = data_clust$fuel.system,repel=FALSE,geom.ind="point", 
             palette = c("blue","green", "yellow", "orange", "red", "purple", "darkgreen", "cyan"), 
             legend.title="fuel.system", pointshape=16)+theme(legend.position = "bottom"),
fviz_pca_ind(pca1, col.ind = data_clust$fuel.system,repel=FALSE,geom.ind="point", 
             palette = c("blue","green", "yellow", "orange", "red", "purple", "darkgreen", "cyan"), 
             legend.title="fuel.system", pointshape=16, addEllipses = TRUE)+theme(legend.position = "bottom"), ncol=2)
@

<<plot_PCA_num.of.doors, eval=TRUE, echo=FALSE,cache=TRUE ,fig.width=8, fig.height=4.1, warning=FALSE,fig.cap="wpływ poszczególnych zmiennych na wartości dwóch pierwszych składowych głównych">>=
grid.arrange(fviz_pca_ind(pca1, col.ind = data_clust$num.of.doors,repel=FALSE,geom.ind="point", 
                          palette = c("black", "red"), 
                          legend.title="num.of.doors", pointshape=16)+theme(legend.position = "bottom"),
             fviz_pca_ind(pca1, col.ind = data_clust$num.of.doors,repel=FALSE,geom.ind="point", 
                          palette = c("black", "red"), 
                          legend.title="num.of.doors", pointshape=16, addEllipses = TRUE)+theme(legend.position = "bottom"), ncol=2)
@
Z rysunków powyżej możemy wywnioskować, że żadna ze zmiennych jakościowych nie została odseparowana w bardzo dobry sposób. Możemy wychwycić pewne wzorce, jak np. dla \texttt{fuel.system}$=$"idi", ale to wszystko.

\par Ponadto, na rysunku \ref{fig:plot_PCA_price_highway.mpg} przedstawione zostały $2$ wykresy punktowe porównujące rozrzut zmiennych ilościowych \texttt{price} i \texttt{highway.mpg} tzn. wszystkie obiekty zaznaczone są kolorami zgodnymi z odpowiednimi wartościami tych zmiennych.


<<plot_PCA_price_highway.mpg, eval=TRUE, echo=FALSE,fig.width=8, fig.height=3.4, warning=FALSE,fig.cap="wpływ poszczególnych zmiennych na wartości dwóch pierwszych składowych głównych">>=
grid.arrange(fviz_pca_ind(pca1, geom.ind = "point",repel=FALSE, col.ind = data_clust$price, gradient.cols=c("blue", "yellow", "red"),
             legend.title="price", pointshape=20),
fviz_pca_ind(pca1, geom.ind = "point", repel=FALSE, col.ind = data_clust$highway.mpg, gradient.cols=c("blue", "yellow", "red"),
             legend.title="highway.mpg", pointshape=20), ncol=2)

@
Możemy zaobserwować, że zmienna \texttt{price} skorelowana jest dodatnio z pierwszą składową główną, a zmienna \texttt{highway.mpg} skorelowana jest ujemnie z tą samą składową.


Poniżej na rysunku \ref{fig:plot_PCA_compression.ratio_peak.rpm} analogiczne wykresy dla zmiennych \texttt{compression.ratio} i \texttt{peak.rpm}

<<plot_PCA_compression.ratio_peak.rpm, eval=TRUE, echo=FALSE,fig.width=8, fig.height=3.4, warning=FALSE,fig.cap="wpływ poszczególnych zmiennych na wartości dwóch pierwszych składowych głównych">>=
grid.arrange(fviz_pca_ind(pca1,geom.ind = "point", repel=FALSE, col.ind = data_clust$compression.ratio, gradient.cols= c("blue", "yellow", "red"),legend.title="compression.ratio", pointshape=20),
fviz_pca_ind(pca1, geom.ind = "point", repel=FALSE, col.ind = data_clust$peak.rpm, gradient.cols= c("blue", "yellow", "red"),
             legend.title="peak.rpm", pointshape=20), ncol=2)

@
Widzimy powyżej, że zmienna \texttt{compression.ratio} skorelowana jest dodatnio z drugą składową głowną, a zmienna \texttt{peak.rpm} skorelowana ujemnie. Wszystkie te wnioski są potwierdzeniem danych, które dostaliśmy na rysunku \ref{fig:plot_PCA7}. Uwaga: przy zmiennych ilościowych, które porównywaliśmy na $2$ powyższych wykresach, należy pamiętać, że nie usuwaliśmy ich z podzbioru wybranych cech, co mogło mieć duże znaczenie na rezultaty.


\subsection{MDS - skalowanie wielowymiarowe}

Drugą metodą redukcji wymiaru użytą przez nas będzie $MDS$ czyli skalowanie wielowymiarowe. Metoda ta polega na odtworzeniu odległości (lub ogólniej odmienności) między obiektami w nowej przestrzeni o mniejszym wymiarze. Główną zaletą metody $MDS$ jest właśnie fakt, że na wejściu możemy jej dostarczyć dowolną macierz odmienności, czyli działa ona także na zmiennych jakościowych. Więcej o metodzie $MDS$ tutaj: \cite{MDS}.
\par Na rysunku \ref{fig:plot_MDS_rozrzut} przedstawiony został wykres rozrzutu przy skalowaniu wielowymiarowym do wymiaru $k=2$ dla wszystkich zmiennych. Do implementacji $MDS$ w \textbf{R} użyliśmy funkcji \texttt{cmdscale} \cite{cmdscale} z pakietu \textbf{stats}.

<<MDS_1, eval=TRUE, echo=FALSE,cache=TRUE>>=
data.MDS_k2 <- cmdscale(DM_matrix, k = 2)
data.MDS_k2_num <- cmdscale(DM_num_matrix, k = 2)

                      
DM_test_matrix <- daisy(data_clust_features[, !names(data_clust_features) %in% c("drive.wheels")])
data.MDS_k2_drive.wheels <- cmdscale(DM_test_matrix, k = 2)

DM_test_matrix <- daisy(data_clust_features[, !names(data_clust_features) %in% c("num.of.doors")])
data.MDS_k2_num.of.doors <- cmdscale(DM_test_matrix, k = 2)

DM_test_matrix <- daisy(data_clust_features[, !names(data_clust_features) %in% c("body.style")])
data.MDS_k2_body.style<- cmdscale(DM_test_matrix, k = 2)

DM_test_matrix <- daisy(data_clust_features[, !names(data_clust_features) %in% c("fuel.system")])
data.MDS_k2_fuel.system <- cmdscale(DM_test_matrix, k = 2)

DM_test_matrix <- daisy(data_clust_features[, !names(data_clust_features) %in% c("price")])
data.MDS_k2_price <- cmdscale(DM_test_matrix, k = 2)

DM_test_matrix <- daisy(data_num_clust_features[, !names(data_num_clust_features) %in% c("price")])
data.MDS_k2_price_num <- cmdscale(DM_test_matrix, k = 2)

x <- cbind.data.frame(symboling_custom, data.MDS_k2, data.MDS_k2_num, data.MDS_k2_drive.wheels,
                      data.MDS_k2_num.of.doors, data.MDS_k2_body.style, data.MDS_k2_fuel.system, 
                      data.MDS_k2_price, data.MDS_k2_price_num, data_clust, price_factor)
colnames(x) <- c("symboling_custom","MDS1", "MDS2", "MDS1_num", "MDS2_num", "MDS1_noDW", "MDS2_noDW",
                 "MDS1_noNoD", "MDS2_noNoD", "MDS1_noBS", "MDS2_noBS","MDS1_noFS", "MDS2_noFS", "MDS1_noPR", "MDS2_noPR", 
                 "MDS1_num_noPR", "MDS2_num_noPR"  , colnames(x)[18:43], "price factor")


@

<<plot_MDS_rozrzut, eval=TRUE, echo=FALSE,cache=TRUE,fig.width=7, fig.height=5, warning=FALSE,fig.cap="Wykres rozrzutu przy skalowaniu wielowymiarowym dla k=2">>=
ggplot(x, aes(x=MDS1, y=MDS2))+
  geom_point()+
  ggtitle("Wykres rozrzutu przy skalowaniu wielowymiarowym dla k=2")+
  theme(plot.title = element_text(hjust = 0.5))
@

Poniżej na rysunku \ref{fig:plot_PCA_MDS_symbo} przedstawione zostało porównanie metod: $MDS$ dla wszystkich zmiennych, $MDS$ dla zmiennych numerycznych i metody $PCA$. 

<<plot_PCA_MDS_symbo, eval=TRUE, echo=FALSE,cache=TRUE,fig.width=14, fig.height=5.2, warning=FALSE,fig.cap="Porównanie metod MDS i PCA">>=
plot_PCA <- fviz_pca_ind(pca1, col.ind = data_clust$symboling,repel=FALSE, geom="point", label="none")+
  scale_color_manual(values=c("blue","green", "yellow", "orange", "red"))+
  scale_shape_manual(values=c(16,16,16, 16, 16))+
  theme_bw()+
  theme(plot.title = element_text(hjust = 0.5))+
  ggtitle("PCA")

plot_MDS_all <- ggplot(x, aes(x=MDS1, y=MDS2, colour=symboling))+
  geom_hline(yintercept=0, linetype="dashed", color = "black", size=0.05)+
  geom_vline(xintercept=0, linetype="dashed", color = "black", size=0.05)+
  geom_point()+
  ggtitle("Wykres rozrzutu przy skalowaniu wielowymiarowym dla k=2")+
  theme(plot.title = element_text(hjust = 0.5))+
  scale_color_manual(values=c("blue","green", "yellow", "orange", "red"))+
  theme_bw()+
  theme(plot.title = element_text(hjust = 0.5), legend.title = element_text(size=20),
        legend.text = element_text(size=20), legend.key.height= unit(2, 'cm'),
        legend.key.width= unit(2, 'cm'))+ 
  ggtitle("MDS")

plot_MDS_num <- ggplot(x, aes(x=MDS1_num, y=MDS2_num, colour=symboling))+
  geom_hline(yintercept=0, linetype="dashed", color = "black", size=0.05)+
  geom_vline(xintercept=0, linetype="dashed", color = "black", size=0.05)+
  geom_point()+
  ggtitle("Wykres rozrzutu przy skalowaniu wielowymiarowym dla k=2")+
  theme(plot.title = element_text(hjust = 0.5))+
  scale_color_manual(values=c("blue","green", "yellow", "orange", "red"))+
  theme_bw()+
  ggtitle("MDS numeryczne")

ggarrange(plot_MDS_all, plot_MDS_num, plot_PCA, ncol=3, common.legend = TRUE, legend = "bottom")
@

Warto zauważyć znany fakt, że dla wybranych zmiennych numerycznych metoda MDS z wymiarem $k=2$ odpowiada $2$ pierwszym składowym głównym z metody PCA. (Wykresy te są symetryczne względem osi $y$). Dla pozostałych zmiennych poniżej przedstawionie zostanie już tylko metoda $MDS$ na wszystkich zmiennych, oraz metoda $MDS$ dla zmiennych numerycznych, która odpowiada metodzie $PCA$.
\par Poniżej na rysunku \ref{fig:plot_PCA_MDS_symbo2} zostały przedstawione te same wykresy co powyżej, ale dodatkowo z zaznaczonymi faktycznymi kategoriami zmiennej \texttt{symboling} w wersji z jej dwoma etykietkami.

<<plot_PCA_MDS_symbo2, eval=TRUE, echo=FALSE,cache=TRUE,fig.width=14, fig.height=7,warning=FALSE,fig.cap="Porównanie metod MDS z rzeczywistymi wartościami zmiennej symboling">>=
plot_MDS_all <- ggplot(x, aes(x=MDS1, y=MDS2, colour=symboling_custom))+
  geom_hline(yintercept=0, linetype="dashed", color = "black", size=0.25)+
  geom_vline(xintercept=0, linetype="dashed", color = "black", size=0.25)+
  geom_point()+
  ggtitle("MDS")+
  theme(plot.title = element_text(hjust = 0.5))+
  scale_color_manual(values=c("green", "red"))+
  theme_bw()+
  theme(plot.title = element_text(hjust = 0.5), legend.title = element_text(size=20),
        legend.text = element_text(size=20), legend.key.height= unit(2, 'cm'),
        legend.key.width= unit(2, 'cm'))+
  guides(color = guide_legend(title = "symboling"))

plot_MDS_num <- ggplot(x, aes(x=MDS1_num, y=MDS2_num, colour=symboling_custom))+
  geom_hline(yintercept=0, linetype="dashed", color = "black", size=0.25)+
  geom_vline(xintercept=0, linetype="dashed", color = "black", size=0.25)+
  geom_point()+
  scale_color_manual(values=c("green", "red"))+
  ggtitle("MDS numeryczne")+
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5))+
  guides(color = guide_legend(title = "symboling"))

ggarrange(plot_MDS_all, plot_MDS_num, ncol=2, common.legend = TRUE, legend = "bottom")

@

NA podstawie rysunku powyżej możemy stwierdzić, że widać pewien wzorzec rozmieszczenia poszczególnych kategorii zmiennej \texttt{symboling}, jednakże z drugiej strony nie możemy mówić też o jednoznacznej bezbłędnej separacji obu obszarów.

\par Poniżej na rysunkach \ref{fig:plot_PCA_MDS_drive}, \ref{fig:plot_PCA_MDS_num.of.doors}, \ref{fig:plot_PCA_MDS_body.style}, \ref{fig:plot_PCA_MDS_fuel.system} i \ref{fig:plot_PCA_MDS_price_factor} przedstawione zostały analogiczne wykresy dla innych zmiennych jakościowych. Warto podkreślić, że dla każdej z nich stworzona została odpowiednia macierz odmienności nieuwzględniająca tej konkretnej zmiennej.

<<plot_PCA_MDS_drive, eval=TRUE, echo=FALSE,cache=TRUE,fig.width=14, fig.height=7,warning=FALSE,fig.cap="Porównanie metod MDS z rzeczywistymi wartościami zmiennej drive.wheels">>=
plot_MDS_all <- ggplot(x, aes(x=MDS1_noDW, y=MDS2_noDW, colour=`drive.wheels`))+
  geom_hline(yintercept=0, linetype="dashed", color = "black", size=0.25)+
  geom_vline(xintercept=0, linetype="dashed", color = "black", size=0.25)+  
  geom_point()+
  ggtitle("MDS")+
  scale_color_manual(values=c("orange", "purple", "cyan"))+
  theme_bw()+
  theme(plot.title = element_text(hjust = 0.5), legend.title = element_text(size=20),
        legend.text = element_text(size=20), legend.key.height= unit(2, 'cm'),
        legend.key.width= unit(2, 'cm'))+
  guides(color = guide_legend(title = "drive.wheels"))

plot_MDS_num <- ggplot(x, aes(x=MDS1_num, y=MDS2_num, colour=`drive.wheels`))+
  geom_hline(yintercept=0, linetype="dashed", color = "black", size=0.25)+
  geom_vline(xintercept=0, linetype="dashed", color = "black", size=0.25)+
  geom_point()+
  ggtitle("MDS numeryczne")+
  scale_color_manual(values=c("orange", "purple", "cyan"))+
  theme_bw()+
  theme(plot.title = element_text(hjust = 0.5))+
  guides(color = guide_legend(title = "drive.wheels"))
ggarrange(plot_MDS_all, plot_MDS_num, ncol=2, common.legend = TRUE, legend = "bottom")

@

<<plot_PCA_MDS_num.of.doors, eval=TRUE, echo=FALSE,cache=TRUE,fig.width=14, fig.height=7,warning=FALSE,fig.cap="Porównanie metod MDS z rzeczywistymi wartościami zmiennej num.of.doors">>=
plot_MDS_all <- ggplot(x, aes(x=MDS1_noNoD, y=MDS2_noNoD, colour=`num.of.doors`))+
  geom_hline(yintercept=0, linetype="dashed", color = "black", size=0.25)+
  geom_vline(xintercept=0, linetype="dashed", color = "black", size=0.25)+  
  geom_point()+
  ggtitle("MDS")+
  scale_color_manual(values=c("gold", "darkblue"))+
  theme_bw()+
  theme(plot.title = element_text(hjust = 0.5), legend.title = element_text(size=20),
        legend.text = element_text(size=20), legend.key.height= unit(2, 'cm'),
        legend.key.width= unit(2, 'cm'))+
  guides(color = guide_legend(title = "num.of.doors"))

plot_MDS_num <- ggplot(x, aes(x=MDS1_num, y=MDS2_num, colour=`num.of.doors`))+
  geom_hline(yintercept=0, linetype="dashed", color = "black", size=0.25)+
  geom_vline(xintercept=0, linetype="dashed", color = "black", size=0.25)+
  geom_point()+
  ggtitle("MDS numeryczne")+
  scale_color_manual(values=c("gold", "darkblue"))+
  theme_bw()+
  theme(plot.title = element_text(hjust = 0.5))+
  guides(color = guide_legend(title = "num.of.doors"))
ggarrange(plot_MDS_all, plot_MDS_num, ncol=2, common.legend = TRUE, legend = "bottom")
@

<<plot_PCA_MDS_body.style, eval=TRUE, echo=FALSE,cache=TRUE,fig.width=14, fig.height=7,warning=FALSE,fig.cap="Porównanie metod MDS z rzeczywistymi wartościami zmiennej body.style">>=

plot_MDS_all <- ggplot(x, aes(x=MDS1_noBS, y=MDS2_noBS, colour=`body.style`))+
  geom_hline(yintercept=0, linetype="dashed", color = "black", size=0.25)+
  geom_vline(xintercept=0, linetype="dashed", color = "black", size=0.25)+  
  geom_point()+
  ggtitle("MDS")+
  scale_color_manual(values=c("magenta", "darkred", "lightgreen", "blue", "orange"))+
  theme_bw()+
  theme(plot.title = element_text(hjust = 0.5), legend.title = element_text(size=20),
        legend.text = element_text(size=20), legend.key.height= unit(2, 'cm'),
        legend.key.width= unit(2, 'cm'))+
  guides(color = guide_legend(title = "body.style"))

plot_MDS_num <- ggplot(x, aes(x=MDS1_num, y=MDS2_num, colour=`body.style`))+
  geom_hline(yintercept=0, linetype="dashed", color = "black", size=0.25)+
  geom_vline(xintercept=0, linetype="dashed", color = "black", size=0.25)+
  geom_point()+
  ggtitle("MDS numeryczne")+
  scale_color_manual(values=c( "magenta", "darkred",  "lightgreen", "blue","orange"))+
  theme_bw()+
  theme(plot.title = element_text(hjust = 0.5))+
  guides(color = guide_legend(title = "body.style"))
ggarrange(plot_MDS_all, plot_MDS_num, ncol=2, common.legend = TRUE, legend = "bottom")
@

<<plot_PCA_MDS_fuel.system, eval=TRUE, echo=FALSE, cache=TRUE,fig.width=14, fig.height=7.8,warning=FALSE,fig.cap="Porównanie metod MDS z rzeczywistymi wartościami zmiennej fuel.system">>=

plot_MDS_all <- ggplot(x, aes(x=MDS1_noFS, y=MDS2_noFS, colour=`fuel.system`))+
  geom_hline(yintercept=0, linetype="dashed", color = "black", size=0.25)+
  geom_vline(xintercept=0, linetype="dashed", color = "black", size=0.25)+  
  geom_point()+
  ggtitle("MDS")+
  scale_color_manual(values=c("green", "purple", "brown", "black", "gold", "darkorange" , "red", "blue"))+
  theme_bw()+
  theme(plot.title = element_text(hjust = 0.5), legend.title = element_text(size=20),
        legend.text = element_text(size=20), legend.key.height= unit(2, 'cm'),
        legend.key.width= unit(2, 'cm'))+
  guides(color = guide_legend(title = "fuel.system"))

plot_MDS_num <- ggplot(x, aes(x=MDS1_num, y=MDS2_num, colour=`fuel.system`))+
  geom_hline(yintercept=0, linetype="dashed", color = "black", size=0.25)+
  geom_vline(xintercept=0, linetype="dashed", color = "black", size=0.25)+
  geom_point()+
  ggtitle("MDS numeryczne")+
  scale_color_manual(values=c("green", "purple", "brown", "black",  "gold", "darkorange" , "red", "blue"))+
  theme_bw()+
  theme(plot.title = element_text(hjust = 0.5))+
  guides(color = guide_legend(title = "fuel.system"))
ggarrange(plot_MDS_all, plot_MDS_num, ncol=2, common.legend = TRUE, legend = "bottom")
@

<<plot_PCA_MDS_price_factor, eval=TRUE, echo=FALSE,cache=TRUE,fig.width=14, fig.height=7.8,warning=FALSE,fig.cap="Porównanie metod MDS z rzeczywistymi wartościami zmiennej price (typu factor)">>=

plot_MDS_all <- ggplot(x, aes(x=MDS1_noPR, y=MDS2_noPR, colour=`price factor`))+
  geom_hline(yintercept=0, linetype="dashed", color = "black", size=0.25)+
  geom_vline(xintercept=0, linetype="dashed", color = "black", size=0.25)+  
  geom_point()+
  ggtitle("MDS")+
  scale_color_manual(values=c("blue", "green", "gold", "red"))+
  theme_bw()+
  theme(plot.title = element_text(hjust = 0.5), legend.title = element_text(size=20),
        legend.text = element_text(size=20), legend.key.height= unit(2, 'cm'),
        legend.key.width= unit(2, 'cm'))+
  guides(color = guide_legend(title = "Price", nrow=2))

plot_MDS_num <- ggplot(x, aes(x=MDS1_num_noPR, y=MDS2_num_noPR, colour=`price factor`))+
  geom_hline(yintercept=0, linetype="dashed", color = "black", size=0.25)+
  geom_vline(xintercept=0, linetype="dashed", color = "black", size=0.25)+
  geom_point()+
  ggtitle("MDS numeryczne")+
  scale_color_manual(values=c("blue", "green", "gold", "red"))+
  theme_bw()+
  theme(plot.title = element_text(hjust = 0.5))+
  guides(color = guide_legend(title = "fuel.system"))
ggarrange(plot_MDS_all, plot_MDS_num, common.legend = TRUE, legend = "bottom")
@

Na powyższych wykresach, widzimy, że dla wszystkich wybranych zmiennych widać pewne wzorce na wykresach rozrzutu, odnośnie odseparowania ich poszczeólnych kategorii, najgorzej prawdopodobnie dla zmiennej \texttt{body.style}. Innym wnioskiem może być to, że dla wszystkich zmiennych metoda $MDS$ użyta na bazie wszystkich zmiennych zwraca lepsze rezultaty, potencjalne partycje są bardziej widoczne niż w przypadku tylko zmiennych ilościowych.

\subsection{Zastosowanie metod redukcji wymiaru przy klasteryzacji}

Oczywiście, ważnym zastosowaniem metod redukcji wymiaru, jest po prostu użycie ich w celu klasyfikacji czy klasteryzacji.
\par Poniżej na rysunku \ref{fig:PAM_MDS_Silhouette} przedstawione został wykres Silhouette'a dla metody PAM użytej na oryginalnych danych.

<<PAM_MDS_Silhouette, eval=TRUE, echo=FALSE,cache=TRUE,fig.width=14, fig.height=7.8,warning=FALSE,fig.cap="PAM na bazie MDS z k=2">>=

pam.all <- pam(x=DM_matrix, diss=T, k=2)
medoidy <- data_clust_features[pam.all$medoids,]
fviz_silhouette(pam.all)
@

Następnie, na rysunku \ref{fig:PAM_MDS_wizualizacja} przedstawiona została Wizualizacja wyników grupowania metodą PAM po użyciu metody $MDS$ dla wymiaru $k=2$. 

<<PAM_MDS_wizualizacja, eval=TRUE, echo=FALSE,cache=TRUE,fig.width=14, fig.height=7.8,warning=FALSE,fig.cap="Wizualizacja wyników grupowania - metoda PAM po użyciu metody MDS">>=
data.MDS <- cmdscale(d = DM_matrix, k = 2)
plot(data.MDS, col=pam.all$clustering, pch=16, xlab="MDS1", ylab="MDS2")
legend("topleft", legend=unique(pam.all$clustering), title="skupienia", col=1:2, pch=16, bg="azure2")
title("Wizualizacja wyników grupowania - metoda PAM")
@
Powyżej widzimy dwa dobrze odseparowane skupienia, z małymi wyjątkami. Jednakże to jeszcze nam nic nie mówi, postaramy się zbadać charakterystykę obu tych skupień pod kątem innych zmiennych.
\par Na początku, na rysunku \ref{fig:PAM_MDS_tabelki} przedstawione zostały wykresy słupkowe dla zmiennych jakościowych, pogrupowane ze względu na oba klastry uzyskane przy użyciu $PAM$.


<<PAM_MDS_tabelki, eval=TRUE, echo=FALSE, cache=TRUE, fig.width=7,fig.height=9.1,warning=FALSE,fig.cap="Porównanie występowania zmiennych jakościowych w dwóch klastrach po użyciu metod PAM i MDS">>=
etykietki.skupien.PAM <- pam.all$clustering

x <- cbind.data.frame(data_clust, etykietki.skupien.PAM)

bp1 <- ggplot(data=x[which(x$etykietki.skupien.PAM==1),],  aes( symboling))+
  geom_bar()+
  ggtitle("Pam klaster pierwszy")+
  theme(plot.title = element_text(hjust = 0.5))

bp2 <-ggplot(data=x[which(x$etykietki.skupien.PAM==2),],  aes( symboling))+
  geom_bar()+
  ggtitle("Pam klaster drugi")+
  theme(plot.title = element_text(hjust = 0.5))

bp3 <- ggplot(data=x[which(x$etykietki.skupien.PAM==1),],  aes(fuel.system))+
  geom_bar()+
  ggtitle("Pam klaster pierwszy")+
  theme(plot.title = element_text(hjust = 0.5))

bp4 <-ggplot(data=x[which(x$etykietki.skupien.PAM==2),],  aes(fuel.system))+
  geom_bar()+
  ggtitle("Pam klaster drugi")+
  theme(plot.title = element_text(hjust = 0.5))


bp5 <- ggplot(data=x[which(x$etykietki.skupien.PAM==1),],  aes(drive.wheels))+
  geom_bar()+
  ggtitle("Pam klaster pierwszy")+
  theme(plot.title = element_text(hjust = 0.5))

bp6 <-ggplot(data=x[which(x$etykietki.skupien.PAM==2),],  aes(drive.wheels))+
  geom_bar()+
  ggtitle("Pam klaster drugi")+
  theme(plot.title = element_text(hjust = 0.5))


bp7 <- ggplot(data=x[which(x$etykietki.skupien.PAM==1),],  aes(body.style))+
  geom_bar()+
  ggtitle("Pam klaster pierwszy")+
  theme(plot.title = element_text(hjust = 0.5))

bp8 <-ggplot(data=x[which(x$etykietki.skupien.PAM==2),],  aes(body.style))+
  geom_bar()+
  ggtitle("Pam klaster drugi")+
  theme(plot.title = element_text(hjust = 0.5))


bp9 <- ggplot(data=x[which(x$etykietki.skupien.PAM==1),],  aes(num.of.doors))+
  geom_bar()+
  ggtitle("Pam klaster pierwszy")+
  theme(plot.title = element_text(hjust = 0.5))

bp10 <-ggplot(data=x[which(x$etykietki.skupien.PAM==2),],  aes(num.of.doors))+
  geom_bar()+
  ggtitle("Pam klaster drugi")+
  theme(plot.title = element_text(hjust = 0.5))

bp11 <- ggplot(data=x[which(x$etykietki.skupien.PAM==1),],  aes(num.of.cylinders))+
  geom_bar()+
  ggtitle("Pam klaster pierwszy")+
  theme(plot.title = element_text(hjust = 0.5))

bp12 <-ggplot(data=x[which(x$etykietki.skupien.PAM==2),],  aes(num.of.cylinders))+
  geom_bar()+
  ggtitle("Pam klaster drugi")+
  theme(plot.title = element_text(hjust = 0.5))




grid.arrange(bp1, bp2, bp3, bp4, bp5, bp6, bp7, bp8, bp9, bp10, bp11, bp12, ncol=2)

@

Jak możemy zaobserwować powyżej, rozkłady występowań poszczególnych zmiennych jakościowych różnią się w zależności od klastrów. Najbardziej widać to dla zmiennych \texttt{fuel.system}, \texttt{drive.wheels}, \texttt{body.style} i \texttt{num.of.doors}.

\par Poniżej na rysunku \ref{fig:PAM_MDS_boxploty} przedstawione zostały boxploty dla zmiennych ilościowych pogrupowane ze względu na klastry uzyskane metodą $PAM$.

<<PAM_MDS_boxploty, eval=TRUE, echo=FALSE,cache=TRUE,fig.width=14, fig.height=14.5,warning=FALSE,fig.cap="Porównanie zmiennych ilościowych dla dwóch klastrów po użyciu metod PAM i MDS">>=
x <- cbind.data.frame(data_clust, etykietki.skupien.PAM)

plot1_MDS <- ggplot()+
  geom_boxplot(data=x, aes(etykietki.skupien.PAM, price, group=etykietki.skupien.PAM))

plot2_MDS <- ggplot()+
  geom_boxplot(data=x, aes(etykietki.skupien.PAM, wheel.base, group=etykietki.skupien.PAM))

plot3_MDS <- ggplot()+
  geom_boxplot(data=x, aes(etykietki.skupien.PAM, length, group=etykietki.skupien.PAM))

plot4_MDS <- ggplot()+
  geom_boxplot(data=x, aes(etykietki.skupien.PAM, height, group=etykietki.skupien.PAM))

plot5_MDS <- ggplot()+
  geom_boxplot(data=x, aes(etykietki.skupien.PAM, compression.ratio, group=etykietki.skupien.PAM))

plot6_MDS <- ggplot()+
  geom_boxplot(data=x, aes(etykietki.skupien.PAM, horsepower, group=etykietki.skupien.PAM))

plot7_MDS <- ggplot()+
  geom_boxplot(data=x, aes(etykietki.skupien.PAM, engine.size, group=etykietki.skupien.PAM))

plot8_MDS <- ggplot()+
  geom_boxplot(data=x, aes(etykietki.skupien.PAM, stroke, group=etykietki.skupien.PAM))

plot9_MDS <- ggplot()+
  geom_boxplot(data=x, aes(etykietki.skupien.PAM, bore, group=etykietki.skupien.PAM))

plot10_MDS <- ggplot()+
  geom_boxplot(data=x, aes(etykietki.skupien.PAM, city.mpg, group=etykietki.skupien.PAM))

plot11_MDS <- ggplot()+
  geom_boxplot(data=x, aes(etykietki.skupien.PAM, highway.mpg, group=etykietki.skupien.PAM))

plot12_MDS <-ggplot()+
  geom_boxplot(data=x, aes(etykietki.skupien.PAM, curb.weight, group=etykietki.skupien.PAM))

grid.arrange(plot1_MDS, plot2_MDS, plot3_MDS, 
             plot4_MDS, plot5_MDS, plot6_MDS,
             plot7_MDS, plot8_MDS, plot9_MDS,
             plot10_MDS, plot11_MDS, plot12_MDS, ncol=3)

@
Na rysunkach powyżej widzimy wyraźne różnice dla wszystkich zmiennych ilościowych oprócz \texttt{stroke} i \texttt{compression.ratio} ze względu na klastry uzyskane metodą $PAM$.

\subsection{Zastosowanie metod redukcji wymiaru przy klasyfikacji}

Metod redukcji wymiaru możemy także użyć w celu poprawy klasyfikacji. W szczególności, bardzo ciekawym zastosowaniem jest użycie metody $MDS$ na danych mieszanego typu, która zwraca nam dane liczbowe po to, żeby następnie użyć otrzymanych wyników do implementacji metod, które na wejściu przyjmują tylko zmienne ilościowe.
\par Przeprowadzliśmy symulacje dla metody $k$-najbliższych sąsiadów dla $k=5$ oraz $k=9$, dla metody $LDA$, oraz dla metody $KDA$. Użyliśmy skalowania wielowymiarowego do różnych wartości wymiarów, a nastepnie obliczyliśmy dokładność dla klasyfikacji zmiennej \texttt{symboling} i wyniki zostały przedstawione w boxplotach na rysunkach \ref{fig:MDS_knn_boxploty1}, \ref{fig:MDS_knn_boxploty2}, \ref{fig:MDS_lda_boxplot} oraz \ref{fig:MDS_kda_boxplot}. UWAGA:redukcję wymiaru stosujemy dla całych danych (zbiór tereningowy + zbiór testowy)!
<<MDS_dane, eval=TRUE, echo=FALSE >>=
# Uwaga: stosujemy redukcję wymiaru dla pełnych danych (zbiór uczący + zbiór testowy)
dim <- 4 # ustalamy wymiar po redukcji 
data.MDS_feat <- cmdscale(d = DM_matrix, k = dim)
data_MDS <- cbind.data.frame(data.MDS_feat, data_clust$symboling)
colnames(data_MDS)<- c(paste0("MDS",1:dim), "symboling")

dim <- 2 # ustalamy wymiar po redukcji 
data.MDS2_feat <- cmdscale(d = DM_matrix, k = dim)
data_MDS2 <- cbind.data.frame(data.MDS2_feat, data_clust$symboling)
colnames(data_MDS2)<- c(paste0("MDS",1:dim), "symboling")

dim <- 3 # ustalamy wymiar po redukcji 
data.MDS3_feat <- cmdscale(d = DM_matrix, k = dim)
data_MDS3 <- cbind.data.frame(data.MDS3_feat, data_clust$symboling)
colnames(data_MDS3)<- c(paste0("MDS",1:dim), "symboling")

dim <- 4 # ustalamy wymiar po redukcji 
data.MDS4_feat <- cmdscale(d = DM_matrix, k = dim)
data_MDS4 <- cbind.data.frame(data.MDS4_feat, data_clust$symboling)
colnames(data_MDS4)<- c(paste0("MDS",1:dim), "symboling")

dim <- 5 # ustalamy wymiar po redukcji 
data.MDS5_feat <- cmdscale(d = DM_matrix, k = dim)
data_MDS5 <- cbind.data.frame(data.MDS5_feat, data_clust$symboling)
colnames(data_MDS5)<- c(paste0("MDS",1:dim), "symboling")

dim <- 6 # ustalamy wymiar po redukcji 
data.MDS6_feat <- cmdscale(d = DM_matrix, k = dim)
data_MDS6 <- cbind.data.frame(data.MDS6_feat, data_clust$symboling)
colnames(data_MDS6)<- c(paste0("MDS",1:dim), "symboling")
@

<<MDS_knnk5_sym, eval=TRUE, cache=TRUE,echo=FALSE >>=
n <- nrow(data_MDS2)
prop <- 0.7 #  wielkość zbioru uczącego
# k-NN
acc2<-c()
acc3<-c()
acc4<-c()
acc5<-c()
acc6<-c()
for(i in 1:100){
learn.ind <- sample(1:n, prop*n)

learning.set <- data_MDS2[learn.ind,]
test.set <- data_MDS2[-learn.ind,]
etykietki.rzeczywiste <- test.set$symboling


  knn.model <- ipredknn(symboling~., learning.set, k=5)
  etykietki.prognozowane.knn <- predict(knn.model, test.set,  type="class")
  (confusion.matrix.knn <- table(etykietki.prognozowane.knn, etykietki.rzeczywiste))
  (dokladnosc.klasyfikacji.knn <- sum(diag(confusion.matrix.knn))/sum(confusion.matrix.knn))
  acc2 <- c(acc2, dokladnosc.klasyfikacji.knn)
  
  learning.set <- data_MDS3[learn.ind,]
  test.set <- data_MDS3[-learn.ind,]
  etykietki.rzeczywiste <- test.set$symboling


  knn.model <- ipredknn(symboling~., learning.set, k=5)
  etykietki.prognozowane.knn <- predict(knn.model, test.set,  type="class")
  (confusion.matrix.knn <- table(etykietki.prognozowane.knn, etykietki.rzeczywiste))
  (dokladnosc.klasyfikacji.knn <- sum(diag(confusion.matrix.knn))/sum(confusion.matrix.knn))
  acc3 <- c(acc3, dokladnosc.klasyfikacji.knn)  
  
  learning.set <- data_MDS4[learn.ind,]
  test.set <- data_MDS4[-learn.ind,]
  etykietki.rzeczywiste <- test.set$symboling
  
  
  knn.model <- ipredknn(symboling~., learning.set, k=5)
  etykietki.prognozowane.knn <- predict(knn.model, test.set,  type="class")
  (confusion.matrix.knn <- table(etykietki.prognozowane.knn, etykietki.rzeczywiste))
  (dokladnosc.klasyfikacji.knn <- sum(diag(confusion.matrix.knn))/sum(confusion.matrix.knn))
  acc4 <- c(acc4, dokladnosc.klasyfikacji.knn)
  
  learning.set <- data_MDS5[learn.ind,]
  test.set <- data_MDS5[-learn.ind,]
  etykietki.rzeczywiste <- test.set$symboling
  
  
  knn.model <- ipredknn(symboling~., learning.set, k=5)
  etykietki.prognozowane.knn <- predict(knn.model, test.set,  type="class")
  (confusion.matrix.knn <- table(etykietki.prognozowane.knn, etykietki.rzeczywiste))
  (dokladnosc.klasyfikacji.knn <- sum(diag(confusion.matrix.knn))/sum(confusion.matrix.knn))
  acc5 <- c(acc5, dokladnosc.klasyfikacji.knn)
  
  learning.set <- data_MDS6[learn.ind,]
  test.set <- data_MDS6[-learn.ind,]
  etykietki.rzeczywiste <- test.set$symboling
  
  
  knn.model <- ipredknn(symboling~., learning.set, k=5)
  etykietki.prognozowane.knn <- predict(knn.model, test.set,  type="class")
  (confusion.matrix.knn <- table(etykietki.prognozowane.knn, etykietki.rzeczywiste))
  (dokladnosc.klasyfikacji.knn <- sum(diag(confusion.matrix.knn))/sum(confusion.matrix.knn))
  acc6 <- c(acc6, dokladnosc.klasyfikacji.knn)
}

@

<<MDS_knn_boxploty1, eval=TRUE, echo=FALSE, cache=TRUE,fig.width=5, fig.height=4,warning=FALSE,fig.cap="Porównanie metody MDS dla różnych wymiarów dla KNN z k=5">>=
boxplot(acc2,acc3,acc4,acc5,acc6, main="KNN, k=5", xlab="MDS 2dim,MDS 3dim,MDS 4dim,MDS 5dim,MDS 6dim")

@

<<MDS_knnk9_sym, eval=TRUE, echo=FALSE, cache=TRUE>>=
acc2<-c()
acc3<-c()
acc4<-c()
acc5<-c()
acc6<-c()


for(i in 1:100){
  learn.ind <- sample(1:n, prop*n)
  
  learning.set <- data_MDS2[learn.ind,]
  test.set <- data_MDS2[-learn.ind,]
  etykietki.rzeczywiste <- test.set$symboling
  
  
  knn.model <- ipredknn(symboling~., learning.set, k=9)
  etykietki.prognozowane.knn <- predict(knn.model, test.set,  type="class")
  (confusion.matrix.knn <- table(etykietki.prognozowane.knn, etykietki.rzeczywiste))
  (dokladnosc.klasyfikacji.knn <- sum(diag(confusion.matrix.knn))/sum(confusion.matrix.knn))
  acc2 <- c(acc2, dokladnosc.klasyfikacji.knn)
  
  learning.set <- data_MDS3[learn.ind,]
  test.set <- data_MDS3[-learn.ind,]
  etykietki.rzeczywiste <- test.set$symboling
  
  
  knn.model <- ipredknn(symboling~., learning.set, k=9)
  etykietki.prognozowane.knn <- predict(knn.model, test.set,  type="class")
  (confusion.matrix.knn <- table(etykietki.prognozowane.knn, etykietki.rzeczywiste))
  (dokladnosc.klasyfikacji.knn <- sum(diag(confusion.matrix.knn))/sum(confusion.matrix.knn))
  acc3 <- c(acc3, dokladnosc.klasyfikacji.knn)  
  
  learning.set <- data_MDS4[learn.ind,]
  test.set <- data_MDS4[-learn.ind,]
  etykietki.rzeczywiste <- test.set$symboling
  
  
  knn.model <- ipredknn(symboling~., learning.set, k=9)
  etykietki.prognozowane.knn <- predict(knn.model, test.set,  type="class")
  (confusion.matrix.knn <- table(etykietki.prognozowane.knn, etykietki.rzeczywiste))
  (dokladnosc.klasyfikacji.knn <- sum(diag(confusion.matrix.knn))/sum(confusion.matrix.knn))
  acc4 <- c(acc4, dokladnosc.klasyfikacji.knn)
  
  learning.set <- data_MDS5[learn.ind,]
  test.set <- data_MDS5[-learn.ind,]
  etykietki.rzeczywiste <- test.set$symboling
  
  
  knn.model <- ipredknn(symboling~., learning.set, k=9)
  etykietki.prognozowane.knn <- predict(knn.model, test.set,  type="class")
  (confusion.matrix.knn <- table(etykietki.prognozowane.knn, etykietki.rzeczywiste))
  (dokladnosc.klasyfikacji.knn <- sum(diag(confusion.matrix.knn))/sum(confusion.matrix.knn))
  acc5 <- c(acc5, dokladnosc.klasyfikacji.knn)
  
  learning.set <- data_MDS6[learn.ind,]
  test.set <- data_MDS6[-learn.ind,]
  etykietki.rzeczywiste <- test.set$symboling
  
  
  knn.model <- ipredknn(symboling~., learning.set, k=9)
  etykietki.prognozowane.knn <- predict(knn.model, test.set,  type="class")
  (confusion.matrix.knn <- table(etykietki.prognozowane.knn, etykietki.rzeczywiste))
  (dokladnosc.klasyfikacji.knn <- sum(diag(confusion.matrix.knn))/sum(confusion.matrix.knn))
  acc6 <- c(acc6, dokladnosc.klasyfikacji.knn)
}
@

<<MDS_knn_boxploty2, eval=TRUE, echo=FALSE,fig.width=5, cache=TRUE, fig.height=4,warning=FALSE,fig.cap="Porównanie metody MDS dla różnych wymiarów dla KNN z k=9">>=
boxplot(acc2,acc3,acc4,acc5,acc6, main="knn, k=9", xlab="MDS 2dim,MDS 3dim,MDS 4dim,MDS 5dim,MDS 6dim")
@


<<MDS_lda_sym, eval=TRUE, echo=FALSE, cache=TRUE>>=
acc<-c()
for(i in 1:100){
  learn.ind <- sample(1:n, prop*n)
  learning.set <- data_MDS[learn.ind,]
  test.set <- data_MDS[-learn.ind,]
  etykietki.rzeczywiste <- test.set$symboling
  
lda.model <- lda(symboling~., learning.set)
etykietki.prognozowane.lda <- predict(lda.model, test.set)$class
(confusion.matrix.lda <- table(etykietki.prognozowane.lda, etykietki.rzeczywiste))
(dokladnosc.klasyfikacji.lda <- sum(diag(confusion.matrix.lda))/sum(confusion.matrix.lda))
acc <- c(acc, dokladnosc.klasyfikacji.lda)
}
<<MDS_lda_boxplot, eval=TRUE, echo=FALSE,cache=TRUE,fig.width=4, fig.height=3,warning=FALSE,fig.cap="Metoda MDS dla LDA">>=
boxplot(acc, main="lda")
@

<<MDS_kda_sym, eval=TRUE, echo=FALSE, cache=TRUE>>=

acc2<-c()
acc3<-c()
for(i in 1:100){
  learn.ind <- sample(1:n, prop*n)
  
  learning.set <- data_MDS2[learn.ind,]
  test.set <- data_MDS2[-learn.ind,]
  etykietki.rzeczywiste <- test.set$symboling
  
  
  klasy <- learning.set$symboling
  kda.model3 <- kda(x=as.matrix(learning.set[1:2]), x.group=klasy)
  etykietki.prognozowane.kda <- predict(kda.model3, x=test.set[1:2])
  (confusion.matrix.kda <- table(etykietki.prognozowane.kda, etykietki.rzeczywiste))
  (dokladnosc.klasyfikacji.kda <- sum(diag(confusion.matrix.kda))/sum(confusion.matrix.kda))
  
  acc2 <- c(acc2, dokladnosc.klasyfikacji.kda)
  
  learning.set <- data_MDS3[learn.ind,]
  test.set <- data_MDS3[-learn.ind,]
  etykietki.rzeczywiste <- test.set$symboling
  
  
  klasy <- learning.set$symboling
  kda.model3 <- kda(x=as.matrix(learning.set[1:3]), x.group=klasy)
  etykietki.prognozowane.kda <- predict(kda.model3, x=test.set[1:3])
  (confusion.matrix.kda <- table(etykietki.prognozowane.kda, etykietki.rzeczywiste))
  (dokladnosc.klasyfikacji.kda <- sum(diag(confusion.matrix.kda))/sum(confusion.matrix.kda))
  
  acc3 <- c(acc3, dokladnosc.klasyfikacji.kda)  

}

@

<<MDS_kda_boxplot, eval=TRUE, echo=FALSE,cache=TRUE,fig.width=4.5, fig.height=3.5,warning=FALSE,fig.cap="Metoda MDS dla KDA">>=
boxplot(acc2,acc3, xlab="KDA_MDS_2dim       KDA_MDS_3dim")
@
Niestety, wyniki naszych symmulacji nie wypadły pomyślnie, na wszystkich wykresach powyżej widzimy, że wartości dokładności nie są zbyt dobre, wahają się one między $0.45$, a $0.6$, co daje gorsze rezultaty niż w przypadku użycia tych samych metod, bez wcześniejszego użycia metody redukcji wymiaru.


\section{Podsumowanie drugiej części projektu}

Na początku drugiej części projektu, w celu klasteryzacji użyliśmy metod grupujących $k-means$ i $PAM$, które zwracały sensowne podziały na partycje, jednakże nie miały one prawie nic wspólnego ze zmienną objaśnianą \texttt{symboling}. Algorytm $DBSCAN$ wypadł w naszym porównaniu prawdpodobnie najgorzej, przez niejednorodną gęstość punktów, albo nie umiał wychwycić różnych skupien, albo złączał je w jedną (za) dużą całość. Nie było nawet sensu porównywać ze zmienną \texttt{symboling}. Najlepsze rezultaty otrzymaliśmy za pomocą metod hierarchicznych, zwłaszcza tych wprowadzonych na $4$-elementowym podzbiorze cech składających się ze zmiennych \texttt{normalized.losses}, \texttt{fuel.system}, \texttt{num.of.doors} i \texttt{length}. 
\par Później zajeliśmy się redukcją wymiaru, która również dała nam kilka ciekawych wyników, przede wszystkim mogliśmy zwizualizować dużo więcej rzeczy przez zwinięcie wielu cech do wymiaru $k=2$, w szczególności ciekawe rezultaty widzieliśmy porównując $MDS$ dla wymiaru $k=2$ z etykietkami różnych zmiennych jakościowych, w tym dla nas najważniejszej - \texttt{symboling}. 
\par Następnie postaraliśmy się o wprowadzenie metod redukcji przy klasteryzacji oraz klasyfikacji. W przypadku grupowania, powiedzmy, że uzyskaliśmy jakies sensowne wyniki, $2$ otrzymane klastry różniły się pod względem charakterystyki, patrząc na różnice w rozkładach różnych zmiennych między partycjami. Natomiast w przypadku klasyfikacji, możemy mówić o rozczarowaniu, ponieważ wprowadzenie metod redukcji wymiaru, tylko pogorszyło dokładność klasyfikacji zmiennej \texttt{symboling}.

@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\section{Dodatek}

\subsection{AGNES complete linkage - porównania z pozostałymi zmiennymi jakościowymi}
<<plot_AGNES_Comparison_make, eval=TRUE, echo=FALSE, fig.width=7, fig.height=4,cache=TRUE, warning=FALSE,fig.cap="dendrogram dla metody AGNES dla zmiennych ilościowych z zaznaczeniem różnych kategorii zmiennej make">>=
etykietki.kolory <- as.numeric(data_clust$make)  
obiekty.kolory <- etykietki.kolory[agnes.complete_num$order]
fviz_dend(agnes.complete_num, cex=0.5, lwd = 0.4,label_cols=obiekty.kolory, main="Kolory = rzeczywiste klasy zmiennej make")
@

<<plot_AGNES_Comparison_fuel.type, eval=TRUE, echo=FALSE,fig.width=7, fig.height=4,cache=TRUE, warning=FALSE,fig.cap="dendrogram dla metody AGNES dla zmiennych ilościowych z zaznaczeniem różnych kategorii zmiennej fuel.type">>=
etykietki.kolory <- as.numeric(data_clust$fuel.type)  
obiekty.kolory <- etykietki.kolory[agnes.complete_num$order]
fviz_dend(agnes.complete_num, cex=0.5, lwd = 0.4,label_cols=obiekty.kolory, main="Kolory = rzeczywiste klasy zmiennej fuel type")
@
<<plot_AGNES_Comparison_Aspiration, eval=TRUE, echo=FALSE,fig.width=7, fig.height=4,cache=TRUE, warning=FALSE,fig.cap="dendrogram dla metody AGNES dla zmiennych ilościowych z zaznaczeniem różnych kategorii zmiennej aspiration">>=
etykietki.kolory <- as.numeric(data_clust$aspiration)  
obiekty.kolory <- etykietki.kolory[agnes.complete_num$order]
fviz_dend(agnes.complete_num, cex=0.5, lwd = 0.4,label_cols=obiekty.kolory, main="Kolory = rzeczywiste klasy zmiennej aspiration")
@

<<plot_AGNES_Comparison_num.of.doors, eval=TRUE, echo=FALSE,fig.width=7, fig.height=4,cache=TRUE, warning=FALSE,fig.cap="dendrogram dla metody AGNES dla zmiennych ilościowych z zaznaczeniem różnych kategorii zmiennej num.of.doors">>=
etykietki.kolory <- as.numeric(data_clust$num.of.doors)  
obiekty.kolory <- etykietki.kolory[agnes.complete_num$order]
fviz_dend(agnes.complete_num, cex=0.5, lwd = 0.4,label_cols=obiekty.kolory, main="Kolory = rzeczywiste klasy zmiennej num.of.doors")
@
<<plot_AGNES_Comparison_body.style, eval=TRUE, echo=FALSE,fig.width=7, fig.height=4,cache=TRUE, warning=FALSE,fig.cap="dendrogram dla metody AGNES dla zmiennych ilościowych z zaznaczeniem różnych kategorii zmiennej body.style">>=
etykietki.kolory <- as.numeric(data_clust$body.style)  
obiekty.kolory <- etykietki.kolory[agnes.complete_num$order]
fviz_dend(agnes.complete_num, cex=0.5, lwd = 0.4,label_cols=obiekty.kolory, main="Kolory = rzeczywiste klasy zmiennej body.style")
@


<<plot_AGNES_Comparison_engine.location, eval=TRUE, echo=FALSE,fig.width=7, fig.height=4,cache=TRUE, warning=FALSE,fig.cap="dendrogram dla metody AGNES dla zmiennych ilościowych z zaznaczeniem różnych kategorii zmiennej engine.location">>=
etykietki.kolory <- as.numeric(data_clust$engine.location)  
obiekty.kolory <- etykietki.kolory[agnes.complete_num$order]
fviz_dend(agnes.complete_num, cex=0.5, lwd = 0.4,label_cols=obiekty.kolory, main="Kolory = rzeczywiste klasy zmiennej engine.location")
@

<<plot_AGNES_Comparison_engine.type, eval=TRUE, echo=FALSE,fig.width=7, fig.height=4,cache=TRUE, warning=FALSE,fig.cap="dendrogram dla metody AGNES dla zmiennych ilościowych z zaznaczeniem różnych kategorii zmiennej engine.type">>=
etykietki.kolory <- as.numeric(data_clust$engine.type)  
obiekty.kolory <- etykietki.kolory[agnes.complete_num$order]
fviz_dend(agnes.complete_num, cex=0.5, lwd = 0.4,label_cols=obiekty.kolory, main="Kolory = rzeczywiste klasy zmiennej engine.type")
@

\subsection{dendrogramy AGNES - wszystkie zmienne}

<<plots_AGNES_all, eval=TRUE, echo=FALSE,cache=TRUE,fig.width=12, fig.height=14,fig.cap="Porównanie wartości wskaźnika connectivity">>=
grid.arrange(fviz_dend(agnes.single_all, k=2, lwd = 0.4 ,cex = 0.5, main="single linkage,2 klastry"),
fviz_dend(agnes.single_all, k=6, lwd = 0.4 ,cex = 0.5, main="single linkage, 6 klastrów"),
fviz_dend(agnes.single_all, k=10, lwd = 0.4 ,cex = 0.5, main="single linkage, 10 klastów"),
fviz_dend(agnes.avg_all, k=2, lwd = 0.4 ,cex = 0.5, main="average linkage, 2 klastry"),
fviz_dend(agnes.avg_all, k=6, lwd = 0.4 ,cex = 0.5, main="average linkage, 6 klastrów"),
fviz_dend(agnes.avg_all, k=10, lwd = 0.4 ,cex = 0.5, main="average linkage, 10 klastrów"),
fviz_dend(agnes.complete_all, k=2, lwd = 0.4 ,cex = 0.5, main="complete linkage, 2 klastry"),
fviz_dend(agnes.complete_all, k=6, lwd = 0.4 ,cex = 0.5, main="complete linkage, 6 klastrów "),
fviz_dend(agnes.complete_all, k=10, lwd = 0.4 ,cex = 0.5, main="complete linkage, 10 klastrów"), ncol=3, nrow=3)

@

%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{thebibliography}{9}
\bibitem{cramerV}
\begin{verbatim}https://en.wikipedia.org/wiki/Cram%C3%A9r%27s_V\end{verbatim}
\bibitem{cramerVR}
https://www.rdocumentation.org/packages/rcompanion/versions/2.3.26/topics/cramerV
\bibitem{lmR}
https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/lm
\bibitem{anovaR}
https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/anova
\bibitem{KruskalR}
https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/kruskal.test
\bibitem{wiki}
\begin{verbatim}https://en.wikipedia.org/wiki/Effect_size\end{verbatim}
\bibitem{eta}
https://resources.nu.edu/statsresources/eta
\bibitem{omega}
https://cran.r-project.org/web/packages/effectsize/vignettes/interpret.html
\bibitem{Kruskal}
https://support.minitab.com/en-us/minitab/21/help-and-how-to/statistics/nonparametrics/how-to/kruskal-wallis-test/interpret-the-results/key-results/
%\beg
\bibitem{Gini}
https://stats.stackexchange.com/questions/197827/how-to-interpret-mean-decrease-in-accuracy-and-mean-decrease-gini-in-random-fore
\bibitem{kmeans}
https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/kmeans
\bibitem{silhoutette}
\begin{verbatim}https://en.wikipedia.org/wiki/Silhouette_(clustering)\end{verbatim}
\bibitem{nbclust}
\begin{verbatim}https://www.rdocumentation.org/packages/factoextra/versions/1.0.7/topics/fviz_nbclust\end{verbatim}
\bibitem{daisy}
https://www.rdocumentation.org/packages/cluster/versions/2.1.4/topics/daisy
\bibitem{Gower}
https://medium.com/analytics-vidhya/gowers-distance-899f9c4bd553
\bibitem{factoextra}
https://cran.r-project.org/web/packages/factoextra/factoextra.pdf
\bibitem{Dunn}
\begin{verbatim}https://en.wikipedia.org/wiki/Dunn_index\end{verbatim}
\bibitem{DBSCAN}
https://en.wikipedia.org/wiki/DBSCAN
\bibitem{heatmap2}
https://www.rdocumentation.org/packages/gplots/versions/3.1.3/topics/heatmap.2
\bibitem{linkage}
\begin{verbatim}https://en.wikipedia.org/wiki/Hierarchical_clustering\end{verbatim}
\bibitem{agnes}
https://www.rdocumentation.org/packages/cluster/versions/2.1.4/topics/agnes
\bibitem{vizdend}
\begin{verbatim}https://www.rdocumentation.org/packages/factoextra/versions/1.0.7/topics/fviz_dend\end{verbatim}
\bibitem{PCA}
\begin{verbatim}https://pl.wikipedia.org/wiki/Analiza_g%C5%82%C3%B3wnych_sk%C5%82adowych\end{verbatim}
\bibitem{PCA_R}
https://www.rdocumentation.org/packages/FactoMineR/versions/2.8/topics/PCA
\bibitem{MDS}
\begin{verbatim}https://en.wikipedia.org/wiki/Multidimensional_scaling\end{verbatim}
\bibitem{cmdscale}
https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/cmdscale
\end{thebibliography}



\end{document}
